{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23d549b7-2b71-4ab9-b310-0189531d2dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data\n",
    "from neuralforecast.utils import AirPassengersDF\n",
    "\n",
    "# models\n",
    "from neuralforecast.auto import AutoNHITS\n",
    "\n",
    "# forecast\n",
    "from neuralforecast.core import NeuralForecast\n",
    "\n",
    "# loss\n",
    "from neuralforecast.losses.pytorch import MAE\n",
    "\n",
    "# hyperparameter optim\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)  # disable training prints\n",
    "from ray import tune\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82a2bd7-83eb-462a-afb5-186a77b7de35",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "708e77db-e7f9-401e-aacc-2b2b49f901cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   unique_id         ds      y\n",
      "0        1.0 1949-01-31  112.0\n",
      "1        1.0 1949-02-28  118.0\n",
      "2        1.0 1949-03-31  132.0\n",
      "3        1.0 1949-04-30  129.0\n",
      "4        1.0 1949-05-31  121.0 \n",
      "\n",
      "     unique_id         ds      y\n",
      "139        1.0 1960-08-31  606.0\n",
      "140        1.0 1960-09-30  508.0\n",
      "141        1.0 1960-10-31  461.0\n",
      "142        1.0 1960-11-30  390.0\n",
      "143        1.0 1960-12-31  432.0 \n",
      "\n",
      "(144, 3) \n",
      "\n",
      "unique_id\n",
      "1.0    144\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Y_df = AirPassengersDF\n",
    "print(Y_df.head(), \"\\n\")\n",
    "print(Y_df.tail(), \"\\n\")\n",
    "print(Y_df.shape, \"\\n\")\n",
    "print(Y_df[\"unique_id\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e00bee-9755-4461-85c1-caf15def09c3",
   "metadata": {},
   "source": [
    "# Ray tune hyperparameter grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb27b3c4-17ba-433f-8af4-9e67e9d73a9b",
   "metadata": {},
   "source": [
    "## 默认超参数网格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9c283c6-e00f-4d9f-9cb0-fea1ef6627aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the default hyperparameter settings\n",
    "nhits_config = AutoNHITS.get_default_config(h = 12, backend = \"ray\")\n",
    "\n",
    "nhits_config[\"random_seed\"] = tune.randint(1, 10)  # Random seed\n",
    "nhits_config[\"n_pool_kernel_size\"] = tune.choice([[2, 2, 2], [16, 8, 1]])  # MaxPool's Kernelsize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732f2d3f-1a46-409d-83ea-49b4aecb8114",
   "metadata": {},
   "source": [
    "## 自定义超参数网格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "012622ba-3704-4699-a46d-09d07e102206",
   "metadata": {},
   "outputs": [],
   "source": [
    "nhits_config = {\n",
    "    \"max_steps\": 100,  # Number of SGD steps\n",
    "    \"input_size\": 24,  # Size of input window\n",
    "    \"learning_rate\": tune.loguniform(1e-5, 1e-1),                              # Initial Learning rate\n",
    "    \"n_pool_kernel_size\": tune.choice([[2, 2, 2], [16, 8, 1]]),                # MaxPool's Kernelsize\n",
    "    \"n_freq_downsample\": tune.choice([[168, 24, 1], [24, 12, 1], [1, 1, 1]]),  # Interpolation expressivity ratios\n",
    "    \"val_check_steps\": 50,  # Compute validation every 50 steps\n",
    "    \"random_seed\": tune.randint(1, 10),  # Random seed\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475297c3-bd2d-45cf-8d3b-c776cdd8ff91",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b51a485f-0b59-46b5-87e0-e25fb9d3f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoNHITS(\n",
    "    h = 12,\n",
    "    loss = MAE(),\n",
    "    config = nhits_config,\n",
    "    search_alg = HyperOptSearch(),\n",
    "    backend = \"ray\",\n",
    "    num_samples = 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcf7439-5822-4ead-8b08-62ae7fd0a24a",
   "metadata": {},
   "source": [
    "## model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "025e8971-d4bf-4914-bd46-8d2d0b42e133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=28316)\u001b[0m D:\\software\\miniconda3\\envs\\ts\\lib\\site-packages\\torch\\storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m D:\\software\\miniconda3\\envs\\ts\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:194: UserWarning: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m Global seed set to 9\n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 4070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m Missing logger folder: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\ray\\session_2024-12-07_21-58-08_639308_21512\\artifacts\\2024-12-07_21-58-13\\_train_tune_2024-12-07_21-58-07\\working_dirs\\_train_tune_d3dad1d8\\lightning_logs\n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m   | Name         | Type          | Params\n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m -----------------------------------------------\n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m 0 | loss         | MAE           | 0     \n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m 1 | padder_train | ConstantPad1d | 0     \n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m 2 | scaler       | TemporalNorm  | 0     \n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m 3 | blocks       | ModuleList    | 2.4 M \n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m -----------------------------------------------\n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m 2.4 M     Trainable params\n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m 2.4 M     Total params\n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m 9.698     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=44.30, train_loss_epoch=44.30]         \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=41.60, train_loss_epoch=41.60]         \n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 181.73it/s, v_num=0, train_loss_step=41.90, train_loss_epoch=41.90]\n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=41.90, train_loss_epoch=41.90]         \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=42.10, train_loss_epoch=42.10]        \n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 195.30it/s, v_num=0, train_loss_step=26.00, train_loss_epoch=26.00]\n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.50, train_loss_epoch=25.50]         \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.30, train_loss_epoch=24.30]         \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.50, train_loss_epoch=22.50]         \n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.30, train_loss_epoch=23.30]         \n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 166.69it/s, v_num=0, train_loss_step=22.30, train_loss_epoch=22.30]\n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.50, train_loss_epoch=21.50]         \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.90, train_loss_epoch=20.90]         \n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00, 161.51it/s, v_num=0, train_loss_step=20.70, train_loss_epoch=20.70]\n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.20, train_loss_epoch=20.20]         \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.50, train_loss_epoch=20.50]         \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.60, train_loss_epoch=19.60]         \n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00, 181.53it/s, v_num=0, train_loss_step=19.90, train_loss_epoch=19.60]\n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.00, train_loss_epoch=20.00]         \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.30, train_loss_epoch=19.30]         \n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.30, train_loss_epoch=19.30]         \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.10, train_loss_epoch=19.10]         \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.70, train_loss_epoch=18.70]         \n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 166.68it/s, v_num=0, train_loss_step=18.80, train_loss_epoch=18.70]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 398.74it/s]\u001b[A\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 55.51it/s, v_num=0, train_loss_step=18.80, train_loss_epoch=18.70, valid_loss=29.50]\n",
      "\u001b[36m(_train_tune pid=28316)\u001b[0m \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.10, train_loss_epoch=18.10, valid_loss=29.50]         \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.20, train_loss_epoch=18.20, valid_loss=29.50]         \n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 166.71it/s, v_num=0, train_loss_step=18.40, train_loss_epoch=18.40, valid_loss=29.50]\n",
      "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.70, train_loss_epoch=17.70, valid_loss=29.50]         \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.60, train_loss_epoch=17.60, valid_loss=29.50]         \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.30, train_loss_epoch=17.30, valid_loss=29.50]         \n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.20, train_loss_epoch=17.20, valid_loss=29.50]         \n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.90, train_loss_epoch=16.90, valid_loss=29.50]         \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.80, train_loss_epoch=16.80, valid_loss=29.50]         \n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 165.85it/s, v_num=0, train_loss_step=16.10, train_loss_epoch=16.10, valid_loss=29.50]\n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80, valid_loss=29.50]         \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.70, train_loss_epoch=15.70, valid_loss=29.50]         \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.70, train_loss_epoch=15.70, valid_loss=29.50]         \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.10, train_loss_epoch=16.10, valid_loss=29.50]         \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80, valid_loss=29.50]         \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40, valid_loss=29.50]         \n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00, 166.67it/s, v_num=0, train_loss_step=15.00, train_loss_epoch=15.00, valid_loss=29.50]\n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.30, train_loss_epoch=15.30, valid_loss=29.50]         \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.10, train_loss_epoch=15.10, valid_loss=29.50]         \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=14.80, valid_loss=29.50]         \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.00, train_loss_epoch=15.00, valid_loss=29.50]         \n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 181.60it/s, v_num=0, train_loss_step=15.20, train_loss_epoch=15.20, valid_loss=29.50]\n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.50, train_loss_epoch=14.50, valid_loss=29.50]         \n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=14.80, valid_loss=29.50]         \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=29.50]         \n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 181.49it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.60, valid_loss=29.50]\n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=29.50]         \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=29.50]         \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=14.80, valid_loss=29.50]         \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=29.50]         \n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20, valid_loss=29.50]         \n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 200.03it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=13.50, valid_loss=29.50]\n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=29.50]         \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=29.50]         \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=29.50]         \n",
      "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=29.50]         \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=29.50]         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=28316)\u001b[0m `Trainer.fit` stopped: `max_steps=100` reached.\n",
      "2024-12-07 21:58:22,183\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 165.93it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.50, valid_loss=29.50]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 385.90it/s]\u001b[A\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 60.17it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.50, valid_loss=22.20] \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 56.76it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=22.20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=29584)\u001b[0m D:\\software\\miniconda3\\envs\\ts\\lib\\site-packages\\torch\\storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m D:\\software\\miniconda3\\envs\\ts\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:194: UserWarning: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m Global seed set to 2\n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 4070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m Missing logger folder: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\ray\\session_2024-12-07_21-58-08_639308_21512\\artifacts\\2024-12-07_21-58-13\\_train_tune_2024-12-07_21-58-07\\working_dirs\\_train_tune_c1f2e0f1\\lightning_logs\n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m   | Name         | Type          | Params\n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m -----------------------------------------------\n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m 0 | loss         | MAE           | 0     \n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m 1 | padder_train | ConstantPad1d | 0     \n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m 2 | scaler       | TemporalNorm  | 0     \n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m 3 | blocks       | ModuleList    | 2.4 M \n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m -----------------------------------------------\n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m 2.4 M     Trainable params\n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m 2.4 M     Total params\n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m 9.712     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.60, train_loss_epoch=37.60]         \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.60, train_loss_epoch=38.60]         \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=35.90, train_loss_epoch=35.90]         \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.60, train_loss_epoch=33.60]         \n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 166.67it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=31.50]\n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.10, train_loss_epoch=28.10]         \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10]         \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.40, train_loss_epoch=25.40]         \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80]         \n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 153.58it/s, v_num=0, train_loss_step=26.30, train_loss_epoch=26.30]\n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.80, train_loss_epoch=22.80]         \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.70, train_loss_epoch=24.70]         \n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.90, train_loss_epoch=22.90]         \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.90, train_loss_epoch=21.90]         \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.50, train_loss_epoch=20.50]         \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.60, train_loss_epoch=21.60]         \n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 153.55it/s, v_num=0, train_loss_step=17.70, train_loss_epoch=18.50]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 285.11it/s]\u001b[A\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 43.62it/s, v_num=0, train_loss_step=17.70, train_loss_epoch=18.50, valid_loss=27.00]\n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.60, train_loss_epoch=17.60, valid_loss=27.00]         \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.00, train_loss_epoch=17.00, valid_loss=27.00]         \n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.90, train_loss_epoch=16.90, valid_loss=27.00]         \n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00, 133.17it/s, v_num=0, train_loss_step=16.20, train_loss_epoch=16.70, valid_loss=27.00]\n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.00, train_loss_epoch=16.00, valid_loss=27.00]         \n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80, valid_loss=27.00]         \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50, valid_loss=27.00]         \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.10, train_loss_epoch=15.10, valid_loss=27.00]         \n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.10, train_loss_epoch=15.10, valid_loss=27.00]         \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.10, train_loss_epoch=15.10, valid_loss=27.00]         \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.50, train_loss_epoch=14.50, valid_loss=27.00]         \n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00, 198.27it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=27.00]\n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=27.00]         \n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 153.57it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=27.00]\n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20, valid_loss=27.00]         \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=27.00]         \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=27.00]         \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=27.00]         \n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00, 153.56it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=27.00]\n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=27.00]         \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=27.00]         \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=27.00]         \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=27.00]         \n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=27.00]         \n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00, 181.44it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=27.00]\n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=27.00]         \n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=27.00]         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=29584)\u001b[0m `Trainer.fit` stopped: `max_steps=100` reached.\n",
      "2024-12-07 21:58:30,409\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (24, 12, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=27.00]         \n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00, 121.84it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=27.00]\n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50, valid_loss=27.00]         \n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=27.00]         \n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=27.00]         \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50, valid_loss=27.00]         \n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=27.00]         \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=27.00]         \n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 166.68it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20, valid_loss=27.00]\n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20, valid_loss=27.00]         \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=27.00]         \n",
      "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10, valid_loss=27.00]         \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 221.91it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=27.00]\n",
      "\u001b[36m(_train_tune pid=29584)\u001b[0m \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 66.60it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=20.00] \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 66.60it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=20.00]\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 62.44it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=20.00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=28456)\u001b[0m D:\\software\\miniconda3\\envs\\ts\\lib\\site-packages\\torch\\storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m D:\\software\\miniconda3\\envs\\ts\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:194: UserWarning: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m Global seed set to 9\n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 4070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m Missing logger folder: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\ray\\session_2024-12-07_21-58-08_639308_21512\\artifacts\\2024-12-07_21-58-13\\_train_tune_2024-12-07_21-58-07\\working_dirs\\_train_tune_527653e3\\lightning_logs\n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m   | Name         | Type          | Params\n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m -----------------------------------------------\n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m 0 | loss         | MAE           | 0     \n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m 1 | padder_train | ConstantPad1d | 0     \n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m 2 | scaler       | TemporalNorm  | 0     \n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m 3 | blocks       | ModuleList    | 2.4 M \n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m -----------------------------------------------\n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m 2.4 M     Trainable params\n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m 2.4 M     Total params\n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m 9.743     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 166.51it/s, v_num=0, train_loss_step=41.50, train_loss_epoch=41.50]\n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=41.50, train_loss_epoch=41.50]         \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=40.70, train_loss_epoch=40.70]         \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 153.77it/s, v_num=0, train_loss_step=42.10, train_loss_epoch=42.10]\n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=41.30, train_loss_epoch=41.30]         \n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 181.71it/s, v_num=0, train_loss_step=39.80, train_loss_epoch=39.80]\n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=40.90, train_loss_epoch=40.90]         \n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 166.70it/s, v_num=0, train_loss_step=40.90, train_loss_epoch=39.50]\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 166.70it/s, v_num=0, train_loss_step=40.90, train_loss_epoch=40.90]\n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=40.10, train_loss_epoch=40.10]         \n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 166.67it/s, v_num=0, train_loss_step=40.30, train_loss_epoch=40.30]\n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=40.50, train_loss_epoch=40.50]         \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.90, train_loss_epoch=38.90]         \n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=40.00, train_loss_epoch=40.00]         \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=40.40, train_loss_epoch=40.40]         \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=39.10, train_loss_epoch=39.10]         \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=40.30, train_loss_epoch=40.30]         \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=40.60, train_loss_epoch=40.60]         \n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00, 153.67it/s, v_num=0, train_loss_step=39.30, train_loss_epoch=39.30]\n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=39.60, train_loss_epoch=39.60]         \n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 181.71it/s, v_num=0, train_loss_step=39.20, train_loss_epoch=39.20]\n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=39.00, train_loss_epoch=39.00]         \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.90, train_loss_epoch=38.90]         \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.90, train_loss_epoch=38.90]         \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.90, train_loss_epoch=38.90]         \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.00, train_loss_epoch=38.00]         \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.70, train_loss_epoch=38.70]         \n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=39.10, train_loss_epoch=39.10]         \n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 153.66it/s, v_num=0, train_loss_step=38.10, train_loss_epoch=38.10]\n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.20, train_loss_epoch=38.20]         \n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.90, train_loss_epoch=37.90]         \n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 166.65it/s, v_num=0, train_loss_step=39.20, train_loss_epoch=38.40]\n",
      "\u001b[36m(_train_tune pid=28456)\u001b[0m \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 330.39it/s]\u001b[A\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 36.87it/s, v_num=0, train_loss_step=39.20, train_loss_epoch=38.40, valid_loss=63.70]\n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.90, train_loss_epoch=36.90, valid_loss=63.70]         \n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 155.24it/s, v_num=0, train_loss_step=36.70, train_loss_epoch=36.70, valid_loss=63.70]\n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.60, train_loss_epoch=36.60, valid_loss=63.70]         \n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 79.91it/s, v_num=0, train_loss_step=37.60, train_loss_epoch=37.60, valid_loss=63.70]\n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.60, train_loss_epoch=37.60, valid_loss=63.70]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.10, train_loss_epoch=37.10, valid_loss=63.70]        \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.80, train_loss_epoch=36.80, valid_loss=63.70]         \n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 138.48it/s, v_num=0, train_loss_step=36.20, train_loss_epoch=37.10, valid_loss=63.70]\n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.10, train_loss_epoch=37.10, valid_loss=63.70]         \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.30, train_loss_epoch=36.30, valid_loss=63.70]         \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.80, train_loss_epoch=36.80, valid_loss=63.70]         \n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00, 165.52it/s, v_num=0, train_loss_step=36.00, train_loss_epoch=36.00, valid_loss=63.70]\n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.00, train_loss_epoch=36.00, valid_loss=63.70]         \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.00, train_loss_epoch=38.00, valid_loss=63.70]         \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.20, train_loss_epoch=36.20, valid_loss=63.70]         \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.90, train_loss_epoch=36.90, valid_loss=63.70]         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=28456)\u001b[0m `Trainer.fit` stopped: `max_steps=100` reached.\n",
      "2024-12-07 21:58:38,444\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (1, 1, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.30, train_loss_epoch=36.30, valid_loss=63.70]         \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=35.80, train_loss_epoch=35.80, valid_loss=63.70]         \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=35.70, train_loss_epoch=35.70, valid_loss=63.70]         \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 200.03it/s, v_num=0, train_loss_step=35.40, train_loss_epoch=35.70, valid_loss=63.70]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 328.66it/s]\u001b[A\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 64.32it/s, v_num=0, train_loss_step=35.40, train_loss_epoch=35.70, valid_loss=58.80] \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 60.43it/s, v_num=0, train_loss_step=35.40, train_loss_epoch=35.40, valid_loss=58.80]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=27784)\u001b[0m D:\\software\\miniconda3\\envs\\ts\\lib\\site-packages\\torch\\storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_train_tune pid=27784)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_train_tune pid=27784)\u001b[0m D:\\software\\miniconda3\\envs\\ts\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:194: UserWarning: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=27784)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_train_tune pid=27784)\u001b[0m Global seed set to 7\n",
      "\u001b[36m(_train_tune pid=27784)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=27784)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=27784)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[36m(_train_tune pid=27784)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=27784)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 4070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=27784)\u001b[0m Missing logger folder: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\ray\\session_2024-12-07_21-58-08_639308_21512\\artifacts\\2024-12-07_21-58-13\\_train_tune_2024-12-07_21-58-07\\working_dirs\\_train_tune_1e067e90\\lightning_logs\n",
      "\u001b[36m(_train_tune pid=27784)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=27784)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=27784)\u001b[0m   | Name         | Type          | Params\n",
      "\u001b[36m(_train_tune pid=27784)\u001b[0m -----------------------------------------------\n",
      "\u001b[36m(_train_tune pid=27784)\u001b[0m 0 | loss         | MAE           | 0     \n",
      "\u001b[36m(_train_tune pid=27784)\u001b[0m 1 | padder_train | ConstantPad1d | 0     \n",
      "\u001b[36m(_train_tune pid=27784)\u001b[0m 2 | scaler       | TemporalNorm  | 0     \n",
      "\u001b[36m(_train_tune pid=27784)\u001b[0m 3 | blocks       | ModuleList    | 2.4 M \n",
      "\u001b[36m(_train_tune pid=27784)\u001b[0m -----------------------------------------------\n",
      "\u001b[36m(_train_tune pid=27784)\u001b[0m 2.4 M     Trainable params\n",
      "\u001b[36m(_train_tune pid=27784)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=27784)\u001b[0m 2.4 M     Total params\n",
      "\u001b[36m(_train_tune pid=27784)\u001b[0m 9.698     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=51.30, train_loss_epoch=51.30]         \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=45.80, train_loss_epoch=45.80]         \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=42.30, train_loss_epoch=42.30]         \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=40.70, train_loss_epoch=40.70]         \n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 151.44it/s, v_num=0, train_loss_step=39.80, train_loss_epoch=39.80]\n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=40.70, train_loss_epoch=40.70]         \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=40.90, train_loss_epoch=40.90]         \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=39.70, train_loss_epoch=39.70]         \n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 142.44it/s, v_num=0, train_loss_step=38.10, train_loss_epoch=39.10]\n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.20, train_loss_epoch=37.20]         \n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 153.70it/s, v_num=0, train_loss_step=36.00, train_loss_epoch=36.00]\n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.00, train_loss_epoch=36.00]         \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.40, train_loss_epoch=33.40]         \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.50, train_loss_epoch=32.50]         \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.80, train_loss_epoch=22.80]         \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.30, train_loss_epoch=22.30]         \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.50, train_loss_epoch=20.50]         \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.10, train_loss_epoch=22.10]         \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.80, train_loss_epoch=20.80]         \n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.90, train_loss_epoch=20.90]         \n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 166.53it/s, v_num=0, train_loss_step=19.30, train_loss_epoch=19.30]\n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.40, train_loss_epoch=19.40]         \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.50, train_loss_epoch=18.50]         \n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 181.59it/s, v_num=0, train_loss_step=18.50, train_loss_epoch=18.50]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 499.98it/s]\u001b[A\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 36.88it/s, v_num=0, train_loss_step=18.50, train_loss_epoch=18.50, valid_loss=28.40]\n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.30, train_loss_epoch=15.30, valid_loss=28.40]         \n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.10, train_loss_epoch=15.10, valid_loss=28.40]         \n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00, 166.53it/s, v_num=0, train_loss_step=14.50, train_loss_epoch=14.50, valid_loss=28.40]\n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=14.80, valid_loss=28.40]         \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=14.80, valid_loss=28.40]         \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=28.40]         \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=28.40]         \n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00, 166.67it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=28.40]\n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=28.40]         \n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 200.00it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=28.40]\n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=28.40]         \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=28.40]         \n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=28.40]         \n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00, 166.67it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=28.40]\n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=28.40]         \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=28.40]         \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=28.40]         \n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=28.40]         \n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=28.40]         \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=28.40]         \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=28.40]         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=27784)\u001b[0m `Trainer.fit` stopped: `max_steps=100` reached.\n",
      "2024-12-07 21:58:46,521\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (24, 12, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=28.40]         \n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 132.49it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=28.40]\n",
      "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=28.40]         \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=28.40]         \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 153.64it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=12.90, valid_loss=28.40]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 486.35it/s]\u001b[A\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 47.25it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=12.90, valid_loss=19.90] \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 43.17it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=19.90]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=28964)\u001b[0m D:\\software\\miniconda3\\envs\\ts\\lib\\site-packages\\torch\\storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m D:\\software\\miniconda3\\envs\\ts\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:194: UserWarning: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m Global seed set to 7\n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 4070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m Missing logger folder: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\ray\\session_2024-12-07_21-58-08_639308_21512\\artifacts\\2024-12-07_21-58-13\\_train_tune_2024-12-07_21-58-07\\working_dirs\\_train_tune_9350a408\\lightning_logs\n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m   | Name         | Type          | Params\n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m -----------------------------------------------\n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m 0 | loss         | MAE           | 0     \n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m 1 | padder_train | ConstantPad1d | 0     \n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m 2 | scaler       | TemporalNorm  | 0     \n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m 3 | blocks       | ModuleList    | 2.4 M \n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m -----------------------------------------------\n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m 2.4 M     Trainable params\n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m 2.4 M     Total params\n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m 9.743     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.40it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.2e+12, train_loss_epoch=2.2e+12]           \n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 153.67it/s, v_num=0, train_loss_step=1.03e+13, train_loss_epoch=1.03e+13]\n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.18e+12, train_loss_epoch=3.18e+12]         \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.3e+10, train_loss_epoch=2.3e+10]           \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.25e+13, train_loss_epoch=5.25e+13]         \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.73e+11, train_loss_epoch=1.73e+11]        \n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 151.40it/s, v_num=0, train_loss_step=1.47e+12, train_loss_epoch=1.85e+12]\n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.55e+10, train_loss_epoch=1.55e+10]         \n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.21e+13, train_loss_epoch=1.21e+13]         \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.47e+10, train_loss_epoch=1.47e+10]         \n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.21e+11, train_loss_epoch=1.21e+11]         \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.8e+13, train_loss_epoch=1.8e+13]           \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.1e+13, train_loss_epoch=1.1e+13]           \n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.3e+13, train_loss_epoch=1.3e+13]           \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.03e+13, train_loss_epoch=9.03e+13]         \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.54e+12, train_loss_epoch=1.54e+12]         \n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 181.63it/s, v_num=0, train_loss_step=2.67e+10, train_loss_epoch=2.67e+10]\n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.2e+13, train_loss_epoch=2.2e+13]           \n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00, 136.96it/s, v_num=0, train_loss_step=3.65e+14, train_loss_epoch=3.65e+14]\n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.6e+12, train_loss_epoch=4.6e+12]           \n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 181.62it/s, v_num=0, train_loss_step=3.46e+11, train_loss_epoch=3.46e+11]\n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.08e+12, train_loss_epoch=8.08e+12]         \n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 152.33it/s, v_num=0, train_loss_step=1.48e+11, train_loss_epoch=1.48e+11]\n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.62e+10, train_loss_epoch=3.62e+10]         \n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00, 163.95it/s, v_num=0, train_loss_step=2.29e+12, train_loss_epoch=3.09e+10]\n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.45e+11, train_loss_epoch=8.45e+11]         \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.94e+12, train_loss_epoch=1.94e+12]         \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.37e+11, train_loss_epoch=1.37e+11]         \n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.25e+10, train_loss_epoch=3.25e+10]         \n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 165.10it/s, v_num=0, train_loss_step=1.58e+12, train_loss_epoch=1.58e+12]\n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.58e+12, train_loss_epoch=1.58e+12]         \n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.41e+10, train_loss_epoch=6.41e+10]         \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.43e+11, train_loss_epoch=1.43e+11]         \n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 159.49it/s, v_num=0, train_loss_step=2.84e+10, train_loss_epoch=2.84e+10]\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 144.03it/s, v_num=0, train_loss_step=1.32e+11, train_loss_epoch=2.84e+10]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 500.10it/s]\u001b[A\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 41.92it/s, v_num=0, train_loss_step=1.32e+11, train_loss_epoch=2.84e+10, valid_loss=5.48e+10]\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 129.69it/s, v_num=0, train_loss_step=1.57e+12, train_loss_epoch=2.73e+11, valid_loss=5.48e+10]\n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.09e+12, train_loss_epoch=1.09e+12, valid_loss=5.48e+10]         \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.43e+11, train_loss_epoch=2.43e+11, valid_loss=5.48e+10]         \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.05e+11, train_loss_epoch=1.05e+11, valid_loss=5.48e+10]         \n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 181.44it/s, v_num=0, train_loss_step=9.71e+8, train_loss_epoch=9.71e+8, valid_loss=5.48e+10]  \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.87e+10, train_loss_epoch=2.87e+10, valid_loss=5.48e+10]         \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.07e+9, train_loss_epoch=1.07e+9, valid_loss=5.48e+10]           \n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00, 181.58it/s, v_num=0, train_loss_step=1.09e+9, train_loss_epoch=1.09e+9, valid_loss=5.48e+10]\n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.08e+9, train_loss_epoch=1.08e+9, valid_loss=5.48e+10]         \n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.01e+9, train_loss_epoch=1.01e+9, valid_loss=5.48e+10]         \n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.87e+8, train_loss_epoch=8.87e+8, valid_loss=5.48e+10]         \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.18e+8, train_loss_epoch=8.18e+8, valid_loss=5.48e+10]         \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.65e+8, train_loss_epoch=6.65e+8, valid_loss=5.48e+10]         \n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.93e+8, train_loss_epoch=5.93e+8, valid_loss=5.48e+10]         \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.93e+8, train_loss_epoch=3.93e+8, valid_loss=5.48e+10]         \n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 160.01it/s, v_num=0, train_loss_step=2.2e+8, train_loss_epoch=2.2e+8, valid_loss=5.48e+10]  \n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.16e+8, train_loss_epoch=2.16e+8, valid_loss=5.48e+10]         \n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.06e+8, train_loss_epoch=2.06e+8, valid_loss=5.48e+10]         \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.01e+8, train_loss_epoch=2.01e+8, valid_loss=5.48e+10]         \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.1e+8, train_loss_epoch=2.1e+8, valid_loss=5.48e+10]           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=28964)\u001b[0m `Trainer.fit` stopped: `max_steps=100` reached.\n",
      "2024-12-07 21:58:54,400\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (1, 1, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.89e+8, train_loss_epoch=1.89e+8, valid_loss=5.48e+10]         \n",
      "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.56e+8, train_loss_epoch=1.56e+8, valid_loss=5.48e+10]         \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 177.30it/s, v_num=0, train_loss_step=8.52e+7, train_loss_epoch=1.08e+8, valid_loss=5.48e+10]\n",
      "\u001b[36m(_train_tune pid=28964)\u001b[0m \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 333.33it/s]\u001b[A\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 52.22it/s, v_num=0, train_loss_step=8.52e+7, train_loss_epoch=1.08e+8, valid_loss=1.39e+8]  \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 47.28it/s, v_num=0, train_loss_step=8.52e+7, train_loss_epoch=8.52e+7, valid_loss=1.39e+8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=29684)\u001b[0m D:\\software\\miniconda3\\envs\\ts\\lib\\site-packages\\torch\\storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_train_tune pid=29684)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_train_tune pid=29684)\u001b[0m D:\\software\\miniconda3\\envs\\ts\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:194: UserWarning: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=29684)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_train_tune pid=29684)\u001b[0m Global seed set to 3\n",
      "\u001b[36m(_train_tune pid=29684)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=29684)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=29684)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[36m(_train_tune pid=29684)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=29684)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 4070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=29684)\u001b[0m Missing logger folder: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\ray\\session_2024-12-07_21-58-08_639308_21512\\artifacts\\2024-12-07_21-58-13\\_train_tune_2024-12-07_21-58-07\\working_dirs\\_train_tune_6ed39a0e\\lightning_logs\n",
      "\u001b[36m(_train_tune pid=29684)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=29684)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=29684)\u001b[0m   | Name         | Type          | Params\n",
      "\u001b[36m(_train_tune pid=29684)\u001b[0m -----------------------------------------------\n",
      "\u001b[36m(_train_tune pid=29684)\u001b[0m 0 | loss         | MAE           | 0     \n",
      "\u001b[36m(_train_tune pid=29684)\u001b[0m 1 | padder_train | ConstantPad1d | 0     \n",
      "\u001b[36m(_train_tune pid=29684)\u001b[0m 2 | scaler       | TemporalNorm  | 0     \n",
      "\u001b[36m(_train_tune pid=29684)\u001b[0m 3 | blocks       | ModuleList    | 2.4 M \n",
      "\u001b[36m(_train_tune pid=29684)\u001b[0m -----------------------------------------------\n",
      "\u001b[36m(_train_tune pid=29684)\u001b[0m 2.4 M     Trainable params\n",
      "\u001b[36m(_train_tune pid=29684)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=29684)\u001b[0m 2.4 M     Total params\n",
      "\u001b[36m(_train_tune pid=29684)\u001b[0m 9.712     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.03e+17, train_loss_epoch=1.03e+17]         \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.41e+15, train_loss_epoch=4.41e+15]         \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.12e+17, train_loss_epoch=1.12e+17]         \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.53e+16, train_loss_epoch=1.53e+16]         \n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.3e+13, train_loss_epoch=6.3e+13]           \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.23e+14, train_loss_epoch=3.23e+14]         \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.19e+13, train_loss_epoch=9.19e+13]         \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.43e+13, train_loss_epoch=6.43e+13]         \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.52e+16, train_loss_epoch=9.52e+16]         \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.06e+15, train_loss_epoch=1.06e+15]         \n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.17e+13, train_loss_epoch=5.17e+13]         \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.08e+10, train_loss_epoch=5.08e+10]         \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.9e+10, train_loss_epoch=2.9e+10]           \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.05e+13, train_loss_epoch=3.05e+13]         \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.62e+10, train_loss_epoch=3.62e+10]         \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.81e+10, train_loss_epoch=4.81e+10]         \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.91e+10, train_loss_epoch=4.91e+10]         \n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.75e+10, train_loss_epoch=4.75e+10]         \n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.5e+10, train_loss_epoch=2.5e+10]           \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.26e+10, train_loss_epoch=2.26e+10]         \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.16e+10, train_loss_epoch=2.16e+10]         \n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 141.87it/s, v_num=0, train_loss_step=1.5e+10, train_loss_epoch=2.16e+10] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 338.50it/s]\u001b[A\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 35.64it/s, v_num=0, train_loss_step=1.5e+10, train_loss_epoch=2.16e+10, valid_loss=1.13e+10]\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 200.00it/s, v_num=0, train_loss_step=5.38e+9, train_loss_epoch=5.38e+9, valid_loss=1.13e+10]  \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.41e+9, train_loss_epoch=4.41e+9, valid_loss=1.13e+10]         \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.33e+9, train_loss_epoch=3.33e+9, valid_loss=1.13e+10]         \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.75e+9, train_loss_epoch=3.75e+9, valid_loss=1.13e+10]         \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.38e+9, train_loss_epoch=3.38e+9, valid_loss=1.13e+10]         \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.91e+9, train_loss_epoch=2.91e+9, valid_loss=1.13e+10]         \n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00, 181.43it/s, v_num=0, train_loss_step=3e+9, train_loss_epoch=3e+9, valid_loss=1.13e+10]      \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.58e+9, train_loss_epoch=1.58e+9, valid_loss=1.13e+10]         \n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.12e+9, train_loss_epoch=1.12e+9, valid_loss=1.13e+10]         \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.78e+9, train_loss_epoch=1.78e+9, valid_loss=1.13e+10]         \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.69e+9, train_loss_epoch=1.69e+9, valid_loss=1.13e+10]         \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.58e+9, train_loss_epoch=1.58e+9, valid_loss=1.13e+10]         \n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00, 178.32it/s, v_num=0, train_loss_step=1.7e+9, train_loss_epoch=1.7e+9, valid_loss=1.13e+10]  \n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 181.41it/s, v_num=0, train_loss_step=1.63e+9, train_loss_epoch=1.63e+9, valid_loss=1.13e+10]\n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.14e+9, train_loss_epoch=1.14e+9, valid_loss=1.13e+10]         \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.87e+8, train_loss_epoch=7.87e+8, valid_loss=1.13e+10]         \n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.05e+9, train_loss_epoch=1.05e+9, valid_loss=1.13e+10]         \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.04e+9, train_loss_epoch=1.04e+9, valid_loss=1.13e+10]         \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.96e+8, train_loss_epoch=5.96e+8, valid_loss=1.13e+10]         \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.44e+8, train_loss_epoch=7.44e+8, valid_loss=1.13e+10]         \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 166.63it/s, v_num=0, train_loss_step=5.24e+8, train_loss_epoch=7.44e+8, valid_loss=1.13e+10]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 398.89it/s]\u001b[A\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 64.47it/s, v_num=0, train_loss_step=5.24e+8, train_loss_epoch=7.44e+8, valid_loss=8.05e+8]  \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 57.10it/s, v_num=0, train_loss_step=5.24e+8, train_loss_epoch=5.24e+8, valid_loss=8.05e+8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=29684)\u001b[0m `Trainer.fit` stopped: `max_steps=100` reached.\n",
      "2024-12-07 21:59:02,413\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m D:\\software\\miniconda3\\envs\\ts\\lib\\site-packages\\torch\\storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m D:\\software\\miniconda3\\envs\\ts\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:194: UserWarning: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m Global seed set to 3\n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 4070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m Missing logger folder: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\ray\\session_2024-12-07_21-58-08_639308_21512\\artifacts\\2024-12-07_21-58-13\\_train_tune_2024-12-07_21-58-07\\working_dirs\\_train_tune_391f076b\\lightning_logs\n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m   | Name         | Type          | Params\n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m -----------------------------------------------\n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m 0 | loss         | MAE           | 0     \n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m 1 | padder_train | ConstantPad1d | 0     \n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m 2 | scaler       | TemporalNorm  | 0     \n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m 3 | blocks       | ModuleList    | 2.4 M \n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m -----------------------------------------------\n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m 2.4 M     Trainable params\n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m 2.4 M     Total params\n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m 9.712     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=41.50, train_loss_epoch=41.50]         \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=43.20, train_loss_epoch=43.20]         \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=41.50, train_loss_epoch=41.50]        \n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 153.59it/s, v_num=0, train_loss_step=40.60, train_loss_epoch=40.60]\n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=40.60, train_loss_epoch=40.60]         \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=41.40, train_loss_epoch=41.40]         \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.90, train_loss_epoch=38.90]         \n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 156.45it/s, v_num=0, train_loss_step=37.60, train_loss_epoch=38.90]\n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.60, train_loss_epoch=37.60]         \n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=35.40, train_loss_epoch=35.40]         \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.30, train_loss_epoch=33.30]         \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.00, train_loss_epoch=32.00]         \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.60, train_loss_epoch=19.60]         \n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 181.50it/s, v_num=0, train_loss_step=18.80, train_loss_epoch=18.80]\n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.70, train_loss_epoch=17.70]         \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.10, train_loss_epoch=17.10]         \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.50, train_loss_epoch=16.50]         \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.40, train_loss_epoch=16.40]         \n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50]         \n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.30, train_loss_epoch=15.30]         \n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.60]         \n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 181.59it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.50]\n",
      "\u001b[36m(_train_tune pid=28500)\u001b[0m \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 57.07it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.50, valid_loss=24.70]\n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=24.70]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=24.70]         \n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=24.70]         \n",
      "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=24.70]         \n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00, 221.21it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=14.10, valid_loss=24.70]\n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=24.70]         \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=24.70]         \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=24.70]         \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=24.70]         \n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 199.99it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=24.70]\n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=24.70]         \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10, valid_loss=24.70]         \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.40, valid_loss=24.70]         \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.50, train_loss_epoch=11.50, valid_loss=24.70]         \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.80, train_loss_epoch=11.80, valid_loss=24.70]         \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30, valid_loss=24.70]         \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.50, train_loss_epoch=11.50, valid_loss=24.70]         \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30, valid_loss=24.70]         \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30, valid_loss=24.70]         \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20, valid_loss=24.70]         \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10, valid_loss=24.70]         \n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00, 160.89it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=11.00, valid_loss=24.70]\n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90, valid_loss=24.70]         \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50, valid_loss=24.70]         \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=11.00, valid_loss=24.70]         \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70, valid_loss=24.70]         \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10, valid_loss=24.70]         \n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00, 181.60it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=10.70, valid_loss=24.70]\n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50, valid_loss=24.70]         \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 154.36it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.50, valid_loss=24.70]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 398.66it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=28500)\u001b[0m `Trainer.fit` stopped: `max_steps=100` reached.\n",
      "2024-12-07 21:59:10,507\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 48.80it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.50, valid_loss=18.70] \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 46.52it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.80, valid_loss=18.70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=16948)\u001b[0m D:\\software\\miniconda3\\envs\\ts\\lib\\site-packages\\torch\\storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_train_tune pid=16948)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_train_tune pid=16948)\u001b[0m D:\\software\\miniconda3\\envs\\ts\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:194: UserWarning: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=16948)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_train_tune pid=16948)\u001b[0m Global seed set to 8\n",
      "\u001b[36m(_train_tune pid=16948)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=16948)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=16948)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[36m(_train_tune pid=16948)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=16948)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 4070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=16948)\u001b[0m Missing logger folder: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\ray\\session_2024-12-07_21-58-08_639308_21512\\artifacts\\2024-12-07_21-58-13\\_train_tune_2024-12-07_21-58-07\\working_dirs\\_train_tune_6399b58a\\lightning_logs\n",
      "\u001b[36m(_train_tune pid=16948)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=16948)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=16948)\u001b[0m   | Name         | Type          | Params\n",
      "\u001b[36m(_train_tune pid=16948)\u001b[0m -----------------------------------------------\n",
      "\u001b[36m(_train_tune pid=16948)\u001b[0m 0 | loss         | MAE           | 0     \n",
      "\u001b[36m(_train_tune pid=16948)\u001b[0m 1 | padder_train | ConstantPad1d | 0     \n",
      "\u001b[36m(_train_tune pid=16948)\u001b[0m 2 | scaler       | TemporalNorm  | 0     \n",
      "\u001b[36m(_train_tune pid=16948)\u001b[0m 3 | blocks       | ModuleList    | 2.4 M \n",
      "\u001b[36m(_train_tune pid=16948)\u001b[0m -----------------------------------------------\n",
      "\u001b[36m(_train_tune pid=16948)\u001b[0m 2.4 M     Trainable params\n",
      "\u001b[36m(_train_tune pid=16948)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=16948)\u001b[0m 2.4 M     Total params\n",
      "\u001b[36m(_train_tune pid=16948)\u001b[0m 9.698     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=43.00, train_loss_epoch=43.00]             \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=63.20, train_loss_epoch=63.20]         \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=90.30, train_loss_epoch=90.30]         \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=50.30, train_loss_epoch=50.30]         \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 161.06it/s, v_num=0, train_loss_step=42.70, train_loss_epoch=42.70]\n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=42.70, train_loss_epoch=42.70]         \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=39.60, train_loss_epoch=39.60]         \n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.50, train_loss_epoch=33.50]         \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.20, train_loss_epoch=38.20]         \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=40.60, train_loss_epoch=40.60]         \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.90, train_loss_epoch=24.90]         \n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70]         \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.80, train_loss_epoch=26.80]         \n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.90, train_loss_epoch=20.90]         \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.30, train_loss_epoch=20.30]         \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.20, train_loss_epoch=18.20]         \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.20, train_loss_epoch=17.20]         \n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 181.41it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=16.40]\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 200.01it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40]         \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40]         \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00]         \n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 197.43it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10]\n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40]         \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10]         \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.80, train_loss_epoch=11.80]         \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30]         \n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 153.69it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=11.30]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 333.33it/s]\u001b[A\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 53.98it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=11.30, valid_loss=16.60]\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 155.86it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70, valid_loss=16.60]\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 153.66it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50, valid_loss=16.60]\n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20, valid_loss=16.60]         \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.30, train_loss_epoch=10.30, valid_loss=16.60]         \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.700, train_loss_epoch=9.700, valid_loss=16.60]         \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.940, train_loss_epoch=9.940, valid_loss=16.60]         \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.930, train_loss_epoch=9.930, valid_loss=16.60]         \n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 166.69it/s, v_num=0, train_loss_step=9.820, train_loss_epoch=9.660, valid_loss=16.60]\n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.300, train_loss_epoch=9.300, valid_loss=16.60]         \n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.230, train_loss_epoch=9.230, valid_loss=16.60]         \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.930, train_loss_epoch=8.930, valid_loss=16.60]         \n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 142.80it/s, v_num=0, train_loss_step=8.890, train_loss_epoch=8.890, valid_loss=16.60]\n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.970, train_loss_epoch=8.970, valid_loss=16.60]         \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.040, train_loss_epoch=9.040, valid_loss=16.60]         \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.640, train_loss_epoch=8.640, valid_loss=16.60]         \n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 181.56it/s, v_num=0, train_loss_step=8.700, train_loss_epoch=8.700, valid_loss=16.60]\n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.910, train_loss_epoch=8.910, valid_loss=16.60]         \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.560, train_loss_epoch=8.560, valid_loss=16.60]         \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.440, train_loss_epoch=8.440, valid_loss=16.60]         \n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 133.11it/s, v_num=0, train_loss_step=8.160, train_loss_epoch=8.550, valid_loss=16.60]\n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.310, train_loss_epoch=8.310, valid_loss=16.60]         \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.230, train_loss_epoch=8.230, valid_loss=16.60]         \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.000, train_loss_epoch=8.000, valid_loss=16.60]         \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.450, train_loss_epoch=8.450, valid_loss=16.60]         \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.000, train_loss_epoch=8.000, valid_loss=16.60]         \n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 181.47it/s, v_num=0, train_loss_step=7.450, train_loss_epoch=7.450, valid_loss=16.60]\n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.830, train_loss_epoch=7.830, valid_loss=16.60]         \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.600, train_loss_epoch=7.600, valid_loss=16.60]         \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 181.69it/s, v_num=0, train_loss_step=7.740, train_loss_epoch=7.600, valid_loss=16.60]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 500.04it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=16948)\u001b[0m `Trainer.fit` stopped: `max_steps=100` reached.\n",
      "2024-12-07 21:59:18,455\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 62.40it/s, v_num=0, train_loss_step=7.740, train_loss_epoch=7.600, valid_loss=17.40] \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 58.74it/s, v_num=0, train_loss_step=7.740, train_loss_epoch=7.740, valid_loss=17.40]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=29184)\u001b[0m D:\\software\\miniconda3\\envs\\ts\\lib\\site-packages\\torch\\storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m D:\\software\\miniconda3\\envs\\ts\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:194: UserWarning: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m Global seed set to 4\n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 4070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m Missing logger folder: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\ray\\session_2024-12-07_21-58-08_639308_21512\\artifacts\\2024-12-07_21-58-13\\_train_tune_2024-12-07_21-58-07\\working_dirs\\_train_tune_776d348f\\lightning_logs\n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m   | Name         | Type          | Params\n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m -----------------------------------------------\n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m 0 | loss         | MAE           | 0     \n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m 1 | padder_train | ConstantPad1d | 0     \n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m 2 | scaler       | TemporalNorm  | 0     \n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m 3 | blocks       | ModuleList    | 2.4 M \n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m -----------------------------------------------\n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m 2.4 M     Trainable params\n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m 2.4 M     Total params\n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m 9.698     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 166.57it/s, v_num=0, train_loss_step=2.49e+13, train_loss_epoch=2.49e+13]\n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.01e+11, train_loss_epoch=5.01e+11]         \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.61e+11, train_loss_epoch=5.61e+11]         \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.86e+10, train_loss_epoch=2.86e+10]         \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.43e+9, train_loss_epoch=5.43e+9]           \n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 199.85it/s, v_num=0, train_loss_step=2.74e+11, train_loss_epoch=8.6e+9]\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 153.73it/s, v_num=0, train_loss_step=5.41e+9, train_loss_epoch=5.41e+9]  \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.88e+10, train_loss_epoch=1.88e+10]         \n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.88e+9, train_loss_epoch=9.88e+9]           \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.97e+9, train_loss_epoch=4.97e+9]         \n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.65e+11, train_loss_epoch=4.65e+11]         \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.3e+9, train_loss_epoch=2.3e+9]             \n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00, 152.65it/s, v_num=0, train_loss_step=1.37e+11, train_loss_epoch=1.37e+11]\n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 164.21it/s, v_num=0, train_loss_step=8.78e+10, train_loss_epoch=5.47e+10]\n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.03e+10, train_loss_epoch=1.03e+10]         \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.62e+9, train_loss_epoch=1.62e+9]           \n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.44e+9, train_loss_epoch=5.44e+9]           \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.15e+8, train_loss_epoch=5.15e+8]         \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.31e+8, train_loss_epoch=4.31e+8]         \n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 197.61it/s, v_num=0, train_loss_step=3.21e+8, train_loss_epoch=3.21e+8]\n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.55e+8, train_loss_epoch=2.55e+8]         \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.01e+7, train_loss_epoch=8.01e+7]         \n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.19e+6, train_loss_epoch=4.19e+6]         \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.23e+7, train_loss_epoch=1.23e+7]         \n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 160.82it/s, v_num=0, train_loss_step=1.07e+7, train_loss_epoch=1.07e+7]\n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.84e+6, train_loss_epoch=1.84e+6]         \n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 166.56it/s, v_num=0, train_loss_step=3.69e+4, train_loss_epoch=1.65e+7]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 663.45it/s]\u001b[A\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 37.01it/s, v_num=0, train_loss_step=3.69e+4, train_loss_epoch=1.65e+7, valid_loss=5.54e+7]\n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+4, train_loss_epoch=2.38e+4, valid_loss=5.54e+7]         \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.89e+4, train_loss_epoch=1.89e+4, valid_loss=5.54e+7]         \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.42e+4, train_loss_epoch=1.42e+4, valid_loss=5.54e+7]         \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.4e+3, train_loss_epoch=8.4e+3, valid_loss=5.54e+7]           \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.15e+3, train_loss_epoch=1.15e+3, valid_loss=5.54e+7]         \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.67e+3, train_loss_epoch=5.67e+3, valid_loss=5.54e+7]         \n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 199.87it/s, v_num=0, train_loss_step=8.85e+3, train_loss_epoch=7.66e+3, valid_loss=5.54e+7]\n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.38e+3, train_loss_epoch=9.38e+3, valid_loss=5.54e+7]         \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.33e+3, train_loss_epoch=8.33e+3, valid_loss=5.54e+7]         \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.42e+3, train_loss_epoch=5.42e+3, valid_loss=5.54e+7]         \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=931.0, train_loss_epoch=931.0, valid_loss=5.54e+7]             \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.69e+3, train_loss_epoch=3.69e+3, valid_loss=5.54e+7]         \n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 200.03it/s, v_num=0, train_loss_step=5.18e+3, train_loss_epoch=5.18e+3, valid_loss=5.54e+7]\n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.83e+3, train_loss_epoch=4.83e+3, valid_loss=5.54e+7]         \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.92e+3, train_loss_epoch=2.92e+3, valid_loss=5.54e+7]         \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=785.0, train_loss_epoch=785.0, valid_loss=5.54e+7]             \n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.68e+3, train_loss_epoch=2.68e+3, valid_loss=5.54e+7]         \n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00, 153.59it/s, v_num=0, train_loss_step=2.18e+3, train_loss_epoch=2.18e+3, valid_loss=5.54e+7]\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 153.71it/s, v_num=0, train_loss_step=175.0, train_loss_epoch=1.23e+3, valid_loss=5.54e+7]  \n",
      "\u001b[36m(_train_tune pid=29184)\u001b[0m \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 500.27it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=29184)\u001b[0m `Trainer.fit` stopped: `max_steps=100` reached.\n",
      "2024-12-07 21:59:26,718\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 44.10it/s, v_num=0, train_loss_step=175.0, train_loss_epoch=1.23e+3, valid_loss=901.0]   \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 42.23it/s, v_num=0, train_loss_step=175.0, train_loss_epoch=175.0, valid_loss=901.0]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=19260)\u001b[0m D:\\software\\miniconda3\\envs\\ts\\lib\\site-packages\\torch\\storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_train_tune pid=19260)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_train_tune pid=19260)\u001b[0m D:\\software\\miniconda3\\envs\\ts\\lib\\site-packages\\ray\\tune\\integration\\pytorch_lightning.py:194: UserWarning: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=19260)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_train_tune pid=19260)\u001b[0m Global seed set to 2\n",
      "\u001b[36m(_train_tune pid=19260)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=19260)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=19260)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[36m(_train_tune pid=19260)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=19260)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 4070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=19260)\u001b[0m Missing logger folder: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\ray\\session_2024-12-07_21-58-08_639308_21512\\artifacts\\2024-12-07_21-58-13\\_train_tune_2024-12-07_21-58-07\\working_dirs\\_train_tune_afc3d5ee\\lightning_logs\n",
      "\u001b[36m(_train_tune pid=19260)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=19260)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=19260)\u001b[0m   | Name         | Type          | Params\n",
      "\u001b[36m(_train_tune pid=19260)\u001b[0m -----------------------------------------------\n",
      "\u001b[36m(_train_tune pid=19260)\u001b[0m 0 | loss         | MAE           | 0     \n",
      "\u001b[36m(_train_tune pid=19260)\u001b[0m 1 | padder_train | ConstantPad1d | 0     \n",
      "\u001b[36m(_train_tune pid=19260)\u001b[0m 2 | scaler       | TemporalNorm  | 0     \n",
      "\u001b[36m(_train_tune pid=19260)\u001b[0m 3 | blocks       | ModuleList    | 2.4 M \n",
      "\u001b[36m(_train_tune pid=19260)\u001b[0m -----------------------------------------------\n",
      "\u001b[36m(_train_tune pid=19260)\u001b[0m 2.4 M     Trainable params\n",
      "\u001b[36m(_train_tune pid=19260)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=19260)\u001b[0m 2.4 M     Total params\n",
      "\u001b[36m(_train_tune pid=19260)\u001b[0m 9.757     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=39.40, train_loss_epoch=39.40]         \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.50, train_loss_epoch=38.50]         \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.80, train_loss_epoch=36.80]         \n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.80, train_loss_epoch=36.80]         \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.50, train_loss_epoch=36.50]         \n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.20, train_loss_epoch=34.20]         \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.30, train_loss_epoch=34.30]         \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.70, train_loss_epoch=33.70]         \n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.90, train_loss_epoch=32.90]         \n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.90, train_loss_epoch=31.90]         \n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 153.68it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40]\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 153.68it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=28.60]\n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 181.44it/s, v_num=0, train_loss_step=27.80, train_loss_epoch=27.80]\n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.50, train_loss_epoch=26.50]         \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.20, train_loss_epoch=27.20]         \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.70, train_loss_epoch=25.70]         \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.10, train_loss_epoch=24.10]         \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.50, train_loss_epoch=24.50]         \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.70, train_loss_epoch=22.70]         \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.70, train_loss_epoch=22.70]         \n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 166.55it/s, v_num=0, train_loss_step=22.10, train_loss_epoch=22.70]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 663.45it/s]\u001b[A\n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 49.95it/s, v_num=0, train_loss_step=22.10, train_loss_epoch=22.70, valid_loss=33.20]\n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.30, train_loss_epoch=21.30, valid_loss=33.20]         \n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.40, train_loss_epoch=21.40, valid_loss=33.20]         \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.20, train_loss_epoch=21.20, valid_loss=33.20]         \n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00, 141.13it/s, v_num=0, train_loss_step=20.20, train_loss_epoch=20.20, valid_loss=33.20]\n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.10, train_loss_epoch=20.10, valid_loss=33.20]         \n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00, 200.01it/s, v_num=0, train_loss_step=19.80, train_loss_epoch=19.80, valid_loss=33.20]\n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 153.57it/s, v_num=0, train_loss_step=19.80, train_loss_epoch=19.80, valid_loss=33.20]\n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.20, train_loss_epoch=19.20, valid_loss=33.20]         \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.40, train_loss_epoch=19.40, valid_loss=33.20]         \n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.70, train_loss_epoch=18.70, valid_loss=33.20]         \n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.70, train_loss_epoch=18.70, valid_loss=33.20]         \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.30, train_loss_epoch=18.30, valid_loss=33.20]         \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.40, train_loss_epoch=18.40, valid_loss=33.20]         \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.70, train_loss_epoch=17.70, valid_loss=33.20]         \n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 105.18it/s, v_num=0, train_loss_step=18.20, train_loss_epoch=18.20, valid_loss=33.20]\n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.00, train_loss_epoch=18.00, valid_loss=33.20]         \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.60, train_loss_epoch=17.60, valid_loss=33.20]         \n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.60, train_loss_epoch=17.60, valid_loss=33.20]         \n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.60, train_loss_epoch=17.60, valid_loss=33.20]         \n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.80, train_loss_epoch=17.80, valid_loss=33.20]         \n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.40, train_loss_epoch=17.40, valid_loss=33.20]         \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.90, train_loss_epoch=16.90, valid_loss=33.20]         \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.00, train_loss_epoch=17.00, valid_loss=33.20]         \n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00, 162.27it/s, v_num=0, train_loss_step=16.80, train_loss_epoch=16.80, valid_loss=33.20]\n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.70, train_loss_epoch=16.70, valid_loss=33.20]         \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.30, train_loss_epoch=16.30, valid_loss=33.20]         \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.20, train_loss_epoch=16.20, valid_loss=33.20]         \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.10, train_loss_epoch=16.10, valid_loss=33.20]         \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 181.60it/s, v_num=0, train_loss_step=16.30, train_loss_epoch=16.10, valid_loss=33.20]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 499.74it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=19260)\u001b[0m `Trainer.fit` stopped: `max_steps=100` reached.\n",
      "2024-12-07 21:59:34,757\tINFO tensorboardx.py:311 -- Removed the following hyperparameter values when logging to tensorboard: {'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (1, 1, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
      "2024-12-07 21:59:34,767\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n",
      "You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n",
      "You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n",
      "2024-12-07 21:59:34,775\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to 'C:/Users/Administrator/ray_results/_train_tune_2024-12-07_21-58-07' in 0.0158s.\n",
      "Global seed set to 8\n",
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 60.43it/s, v_num=0, train_loss_step=16.30, train_loss_epoch=16.10, valid_loss=26.20] \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 56.99it/s, v_num=0, train_loss_step=16.30, train_loss_epoch=16.30, valid_loss=26.20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params\n",
      "-----------------------------------------------\n",
      "0 | loss         | MAE           | 0     \n",
      "1 | padder_train | ConstantPad1d | 0     \n",
      "2 | scaler       | TemporalNorm  | 0     \n",
      "3 | blocks       | ModuleList    | 2.4 M \n",
      "-----------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.698     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad9a687926b48f8b57add773e675178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    }
   ],
   "source": [
    "nf = NeuralForecast(models = [model], freq = \"M\")\n",
    "nf.fit(df = Y_df, val_size = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d27a0771-ce3b-4cc2-97bc-88a95dc5b55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>checkpoint_dir_name</th>\n",
       "      <th>done</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>time_total_s</th>\n",
       "      <th>...</th>\n",
       "      <th>config/input_size</th>\n",
       "      <th>config/learning_rate</th>\n",
       "      <th>config/n_pool_kernel_size</th>\n",
       "      <th>config/n_freq_downsample</th>\n",
       "      <th>config/val_check_steps</th>\n",
       "      <th>config/random_seed</th>\n",
       "      <th>config/h</th>\n",
       "      <th>config/loss</th>\n",
       "      <th>config/valid_loss</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.216895e+01</td>\n",
       "      <td>1.340130e+01</td>\n",
       "      <td>1733579902</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>d3dad1d8</td>\n",
       "      <td>2024-12-07_21-58-22</td>\n",
       "      <td>0.342520</td>\n",
       "      <td>2.897422</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>(16, 8, 1)</td>\n",
       "      <td>(168, 24, 1)</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>MAE()</td>\n",
       "      <td>MAE()</td>\n",
       "      <td>d3dad1d8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.002962e+01</td>\n",
       "      <td>1.226470e+01</td>\n",
       "      <td>1733579910</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>c1f2e0f1</td>\n",
       "      <td>2024-12-07_21-58-30</td>\n",
       "      <td>0.366552</td>\n",
       "      <td>2.744386</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>(2, 2, 2)</td>\n",
       "      <td>(24, 12, 1)</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>MAE()</td>\n",
       "      <td>MAE()</td>\n",
       "      <td>c1f2e0f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.880766e+01</td>\n",
       "      <td>3.541467e+01</td>\n",
       "      <td>1733579918</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>527653e3</td>\n",
       "      <td>2024-12-07_21-58-38</td>\n",
       "      <td>0.382810</td>\n",
       "      <td>2.723147</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>(16, 8, 1)</td>\n",
       "      <td>(1, 1, 1)</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>MAE()</td>\n",
       "      <td>MAE()</td>\n",
       "      <td>527653e3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.992324e+01</td>\n",
       "      <td>1.318050e+01</td>\n",
       "      <td>1733579926</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1e067e90</td>\n",
       "      <td>2024-12-07_21-58-46</td>\n",
       "      <td>0.363365</td>\n",
       "      <td>2.716915</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>(16, 8, 1)</td>\n",
       "      <td>(24, 12, 1)</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>MAE()</td>\n",
       "      <td>MAE()</td>\n",
       "      <td>1e067e90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.392712e+08</td>\n",
       "      <td>8.516460e+07</td>\n",
       "      <td>1733579934</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>9350a408</td>\n",
       "      <td>2024-12-07_21-58-54</td>\n",
       "      <td>0.355987</td>\n",
       "      <td>2.656157</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.068864</td>\n",
       "      <td>(16, 8, 1)</td>\n",
       "      <td>(1, 1, 1)</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>MAE()</td>\n",
       "      <td>MAE()</td>\n",
       "      <td>9350a408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.048640e+08</td>\n",
       "      <td>5.235734e+08</td>\n",
       "      <td>1733579942</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>6ed39a0e</td>\n",
       "      <td>2024-12-07_21-59-02</td>\n",
       "      <td>0.343608</td>\n",
       "      <td>2.597581</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.094046</td>\n",
       "      <td>(2, 2, 2)</td>\n",
       "      <td>(168, 24, 1)</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>MAE()</td>\n",
       "      <td>MAE()</td>\n",
       "      <td>6ed39a0e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.874331e+01</td>\n",
       "      <td>1.079683e+01</td>\n",
       "      <td>1733579950</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>391f076b</td>\n",
       "      <td>2024-12-07_21-59-10</td>\n",
       "      <td>0.337792</td>\n",
       "      <td>2.644845</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>(2, 2, 2)</td>\n",
       "      <td>(168, 24, 1)</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>MAE()</td>\n",
       "      <td>MAE()</td>\n",
       "      <td>391f076b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.736157e+01</td>\n",
       "      <td>7.742190e+00</td>\n",
       "      <td>1733579958</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>6399b58a</td>\n",
       "      <td>2024-12-07_21-59-18</td>\n",
       "      <td>0.342476</td>\n",
       "      <td>2.559814</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>(16, 8, 1)</td>\n",
       "      <td>(168, 24, 1)</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>MAE()</td>\n",
       "      <td>MAE()</td>\n",
       "      <td>6399b58a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.014131e+02</td>\n",
       "      <td>1.747967e+02</td>\n",
       "      <td>1733579966</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>776d348f</td>\n",
       "      <td>2024-12-07_21-59-26</td>\n",
       "      <td>0.351033</td>\n",
       "      <td>2.613345</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.063816</td>\n",
       "      <td>(16, 8, 1)</td>\n",
       "      <td>(168, 24, 1)</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>MAE()</td>\n",
       "      <td>MAE()</td>\n",
       "      <td>776d348f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.620863e+01</td>\n",
       "      <td>1.634403e+01</td>\n",
       "      <td>1733579974</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>afc3d5ee</td>\n",
       "      <td>2024-12-07_21-59-34</td>\n",
       "      <td>0.357179</td>\n",
       "      <td>2.611377</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>(2, 2, 2)</td>\n",
       "      <td>(1, 1, 1)</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>MAE()</td>\n",
       "      <td>MAE()</td>\n",
       "      <td>afc3d5ee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss    train_loss   timestamp checkpoint_dir_name   done   \n",
       "0  2.216895e+01  1.340130e+01  1733579902                None  False  \\\n",
       "1  2.002962e+01  1.226470e+01  1733579910                None  False   \n",
       "2  5.880766e+01  3.541467e+01  1733579918                None  False   \n",
       "3  1.992324e+01  1.318050e+01  1733579926                None  False   \n",
       "4  1.392712e+08  8.516460e+07  1733579934                None  False   \n",
       "5  8.048640e+08  5.235734e+08  1733579942                None  False   \n",
       "6  1.874331e+01  1.079683e+01  1733579950                None  False   \n",
       "7  1.736157e+01  7.742190e+00  1733579958                None  False   \n",
       "8  9.014131e+02  1.747967e+02  1733579966                None  False   \n",
       "9  2.620863e+01  1.634403e+01  1733579974                None  False   \n",
       "\n",
       "   training_iteration  trial_id                 date  time_this_iter_s   \n",
       "0                   2  d3dad1d8  2024-12-07_21-58-22          0.342520  \\\n",
       "1                   2  c1f2e0f1  2024-12-07_21-58-30          0.366552   \n",
       "2                   2  527653e3  2024-12-07_21-58-38          0.382810   \n",
       "3                   2  1e067e90  2024-12-07_21-58-46          0.363365   \n",
       "4                   2  9350a408  2024-12-07_21-58-54          0.355987   \n",
       "5                   2  6ed39a0e  2024-12-07_21-59-02          0.343608   \n",
       "6                   2  391f076b  2024-12-07_21-59-10          0.337792   \n",
       "7                   2  6399b58a  2024-12-07_21-59-18          0.342476   \n",
       "8                   2  776d348f  2024-12-07_21-59-26          0.351033   \n",
       "9                   2  afc3d5ee  2024-12-07_21-59-34          0.357179   \n",
       "\n",
       "   time_total_s  ...  config/input_size config/learning_rate   \n",
       "0      2.897422  ...                 24             0.000390  \\\n",
       "1      2.744386  ...                 24             0.000966   \n",
       "2      2.723147  ...                 24             0.000024   \n",
       "3      2.716915  ...                 24             0.000860   \n",
       "4      2.656157  ...                 24             0.068864   \n",
       "5      2.597581  ...                 24             0.094046   \n",
       "6      2.644845  ...                 24             0.002315   \n",
       "7      2.559814  ...                 24             0.003473   \n",
       "8      2.613345  ...                 24             0.063816   \n",
       "9      2.611377  ...                 24             0.000085   \n",
       "\n",
       "  config/n_pool_kernel_size  config/n_freq_downsample  config/val_check_steps   \n",
       "0                (16, 8, 1)              (168, 24, 1)                      50  \\\n",
       "1                 (2, 2, 2)               (24, 12, 1)                      50   \n",
       "2                (16, 8, 1)                 (1, 1, 1)                      50   \n",
       "3                (16, 8, 1)               (24, 12, 1)                      50   \n",
       "4                (16, 8, 1)                 (1, 1, 1)                      50   \n",
       "5                 (2, 2, 2)              (168, 24, 1)                      50   \n",
       "6                 (2, 2, 2)              (168, 24, 1)                      50   \n",
       "7                (16, 8, 1)              (168, 24, 1)                      50   \n",
       "8                (16, 8, 1)              (168, 24, 1)                      50   \n",
       "9                 (2, 2, 2)                 (1, 1, 1)                      50   \n",
       "\n",
       "   config/random_seed  config/h  config/loss config/valid_loss    logdir  \n",
       "0                   9        12        MAE()             MAE()  d3dad1d8  \n",
       "1                   2        12        MAE()             MAE()  c1f2e0f1  \n",
       "2                   9        12        MAE()             MAE()  527653e3  \n",
       "3                   7        12        MAE()             MAE()  1e067e90  \n",
       "4                   7        12        MAE()             MAE()  9350a408  \n",
       "5                   3        12        MAE()             MAE()  6ed39a0e  \n",
       "6                   3        12        MAE()             MAE()  391f076b  \n",
       "7                   8        12        MAE()             MAE()  6399b58a  \n",
       "8                   4        12        MAE()             MAE()  776d348f  \n",
       "9                   2        12        MAE()             MAE()  afc3d5ee  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = nf.models[0].results.get_dataframe()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9121e130-ed93-4b18-9228-ca7d4419158b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## model predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b93df67a-5996-494f-994a-db1984a38a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f21b2d06aff94e80ae04d951dbd6409f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>AutoNHITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-01-31</td>\n",
       "      <td>451.086975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-02-28</td>\n",
       "      <td>424.009766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-03-31</td>\n",
       "      <td>497.700134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-04-30</td>\n",
       "      <td>498.298645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-05-31</td>\n",
       "      <td>512.604980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-06-30</td>\n",
       "      <td>589.544495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-07-31</td>\n",
       "      <td>680.899780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-08-31</td>\n",
       "      <td>675.768188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-09-30</td>\n",
       "      <td>570.443115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-10-31</td>\n",
       "      <td>502.836853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-11-30</td>\n",
       "      <td>426.674500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-12-31</td>\n",
       "      <td>472.989960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unique_id         ds   AutoNHITS\n",
       "0         1.0 1961-01-31  451.086975\n",
       "1         1.0 1961-02-28  424.009766\n",
       "2         1.0 1961-03-31  497.700134\n",
       "3         1.0 1961-04-30  498.298645\n",
       "4         1.0 1961-05-31  512.604980\n",
       "5         1.0 1961-06-30  589.544495\n",
       "6         1.0 1961-07-31  680.899780\n",
       "7         1.0 1961-08-31  675.768188\n",
       "8         1.0 1961-09-30  570.443115\n",
       "9         1.0 1961-10-31  502.836853\n",
       "10        1.0 1961-11-30  426.674500\n",
       "11        1.0 1961-12-31  472.989960"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat_df_ray = nf.predict()\n",
    "Y_hat_df_ray = Y_hat_df_ray.reset_index()\n",
    "Y_hat_df_ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5c10f2-2712-4d19-9ccd-8bf21f6f748e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Optuna hyperparameters grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed92f739-99bf-46a6-be04-d25382196913",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 默认超参数网格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dde95b6b-bd5e-4c59-bdc1-9360f492eb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function BaseAuto._ray_config_to_optuna.<locals>.optuna_config at 0x000001A0024C19D0>\n"
     ]
    }
   ],
   "source": [
    "nhits_default_config = AutoNHITS.get_default_config(h = 12, backend = \"optuna\")\n",
    "print(nhits_default_config)\n",
    "\n",
    "def config_nhits(trial):\n",
    "    config = {\n",
    "        **nhits_default_config(trial)\n",
    "    }\n",
    "    config.update({\n",
    "        \"random_seed\": trial.suggest_int(\"random_seed\", 1, 10),\n",
    "        \"n_pool_kernel_size\": trial.suggest_categorical(\"n_pool_kernel_size\", [[2, 2, 2], [16, 8, 1]]),\n",
    "    })\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190fafed-165d-4ee3-9cae-9f15d10d554c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 自定超参数网格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93924200-ea5c-4e1c-9d2f-c0cb9b4924c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_nhits(trial):\n",
    "    return {\n",
    "        \"max_steps\": 100,  # Number of SGD steps\n",
    "        \"input_size\": 24,  # Size of input window\n",
    "        \"learning_rate\": trial.suggest_loguniform(\n",
    "            \"learning_rate\", \n",
    "            1e-5, 1e-1\n",
    "        ),  # Initial Learning rate\n",
    "        \"n_pool_kernel_size\": trial.suggest_categorical(\n",
    "            \"n_pool_kernel_size\", \n",
    "            [[2, 2, 2], [16, 8, 1]]\n",
    "        ),  # MaxPool's Kernelsize\n",
    "        \"n_freq_downsample\": trial.suggest_categorical(\n",
    "            \"n_freq_downsample\", \n",
    "            [[168, 24, 1], [24, 12, 1], [1, 1, 1]]\n",
    "        ),  # Interpolation expressivity ratios\n",
    "        \"val_check_steps\": 50,  # Compute validation every 50 steps\n",
    "        \"random_seed\": trial.suggest_int(\n",
    "            \"random_seed\",\n",
    "            1, 10\n",
    "        ),  # Random seed\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84442a6-29d2-45a7-943a-893524c77d7e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5015bbf3-7997-402e-9942-39e9bbe10b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoNHITS(\n",
    "    h = 12,\n",
    "    loss = MAE(),\n",
    "    config = config_nhits,\n",
    "    search_alg = optuna.samplers.TPESampler(),\n",
    "    backend = \"optuna\",\n",
    "    num_samples = 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43ec679-dacb-4557-9769-6af948154a18",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3ba6883-983b-43fa-b0d6-d263bc39f8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 9\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params\n",
      "-----------------------------------------------\n",
      "0 | loss         | MAE           | 0     \n",
      "1 | padder_train | ConstantPad1d | 0     \n",
      "2 | scaler       | TemporalNorm  | 0     \n",
      "3 | blocks       | ModuleList    | 2.4 M \n",
      "-----------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.743     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be4b0b281354e2a8cce28922fa8f52a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Global seed set to 7\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params\n",
      "-----------------------------------------------\n",
      "0 | loss         | MAE           | 0     \n",
      "1 | padder_train | ConstantPad1d | 0     \n",
      "2 | scaler       | TemporalNorm  | 0     \n",
      "3 | blocks       | ModuleList    | 2.4 M \n",
      "-----------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.757     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d74caa44fa430487b476044c19f0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Global seed set to 9\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params\n",
      "-----------------------------------------------\n",
      "0 | loss         | MAE           | 0     \n",
      "1 | padder_train | ConstantPad1d | 0     \n",
      "2 | scaler       | TemporalNorm  | 0     \n",
      "3 | blocks       | ModuleList    | 2.4 M \n",
      "-----------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.712     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c8bee9c27f14435acf4e138b1322ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Global seed set to 7\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params\n",
      "-----------------------------------------------\n",
      "0 | loss         | MAE           | 0     \n",
      "1 | padder_train | ConstantPad1d | 0     \n",
      "2 | scaler       | TemporalNorm  | 0     \n",
      "3 | blocks       | ModuleList    | 2.4 M \n",
      "-----------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.743     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a63ca6d8fb54c7385a4f8e362fe8654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Global seed set to 10\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params\n",
      "-----------------------------------------------\n",
      "0 | loss         | MAE           | 0     \n",
      "1 | padder_train | ConstantPad1d | 0     \n",
      "2 | scaler       | TemporalNorm  | 0     \n",
      "3 | blocks       | ModuleList    | 2.4 M \n",
      "-----------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.757     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4439816df7da48cf9a118262af74aa38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Global seed set to 9\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params\n",
      "-----------------------------------------------\n",
      "0 | loss         | MAE           | 0     \n",
      "1 | padder_train | ConstantPad1d | 0     \n",
      "2 | scaler       | TemporalNorm  | 0     \n",
      "3 | blocks       | ModuleList    | 2.4 M \n",
      "-----------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.743     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02555b9168e34071814d46c67022e8bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Global seed set to 6\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params\n",
      "-----------------------------------------------\n",
      "0 | loss         | MAE           | 0     \n",
      "1 | padder_train | ConstantPad1d | 0     \n",
      "2 | scaler       | TemporalNorm  | 0     \n",
      "3 | blocks       | ModuleList    | 2.4 M \n",
      "-----------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.712     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25fbd4912c254fc1ac36f160f1f81c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Global seed set to 2\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params\n",
      "-----------------------------------------------\n",
      "0 | loss         | MAE           | 0     \n",
      "1 | padder_train | ConstantPad1d | 0     \n",
      "2 | scaler       | TemporalNorm  | 0     \n",
      "3 | blocks       | ModuleList    | 2.4 M \n",
      "-----------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.698     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a2c9b45e1d4202afd77c3bea638d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Global seed set to 7\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params\n",
      "-----------------------------------------------\n",
      "0 | loss         | MAE           | 0     \n",
      "1 | padder_train | ConstantPad1d | 0     \n",
      "2 | scaler       | TemporalNorm  | 0     \n",
      "3 | blocks       | ModuleList    | 2.4 M \n",
      "-----------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.712     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45db05b45e7044498d3a2733fd78c0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Global seed set to 1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params\n",
      "-----------------------------------------------\n",
      "0 | loss         | MAE           | 0     \n",
      "1 | padder_train | ConstantPad1d | 0     \n",
      "2 | scaler       | TemporalNorm  | 0     \n",
      "3 | blocks       | ModuleList    | 2.4 M \n",
      "-----------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.757     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c44c4fc29944500b4f75b597453c3e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Global seed set to 9\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params\n",
      "-----------------------------------------------\n",
      "0 | loss         | MAE           | 0     \n",
      "1 | padder_train | ConstantPad1d | 0     \n",
      "2 | scaler       | TemporalNorm  | 0     \n",
      "3 | blocks       | ModuleList    | 2.4 M \n",
      "-----------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.712     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40454d37abf443408168e32c835f4aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922c8ccb5fdf43cdb85713363ef276f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78151d3a7594dd2a11c4ae823cf025c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a61baf9106f40afb206bc5f24cfc87d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    }
   ],
   "source": [
    "nf = NeuralForecast(models = [model], freq = \"M\")\n",
    "nf.fit(df = Y_df, val_size = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9c34950-5804-4236-bc01-bccc0c66dfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_n_freq_downsample</th>\n",
       "      <th>params_n_pool_kernel_size</th>\n",
       "      <th>params_random_seed</th>\n",
       "      <th>user_attrs_METRICS</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.688148e+01</td>\n",
       "      <td>2024-12-07 21:07:10.355972</td>\n",
       "      <td>2024-12-07 21:07:11.927400</td>\n",
       "      <td>0 days 00:00:01.571428</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>[16, 8, 1]</td>\n",
       "      <td>9</td>\n",
       "      <td>{'loss': tensor(16.8815), 'train_loss': tensor...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.645361e+01</td>\n",
       "      <td>2024-12-07 21:07:11.928402</td>\n",
       "      <td>2024-12-07 21:07:13.321231</td>\n",
       "      <td>0 days 00:00:01.392829</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>7</td>\n",
       "      <td>{'loss': tensor(16.4536), 'train_loss': tensor...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.547846e+01</td>\n",
       "      <td>2024-12-07 21:07:13.321231</td>\n",
       "      <td>2024-12-07 21:07:14.602140</td>\n",
       "      <td>0 days 00:00:01.280909</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>[24, 12, 1]</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>9</td>\n",
       "      <td>{'loss': tensor(15.4785), 'train_loss': tensor...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.273332e+08</td>\n",
       "      <td>2024-12-07 21:07:14.603141</td>\n",
       "      <td>2024-12-07 21:07:15.905151</td>\n",
       "      <td>0 days 00:00:01.302010</td>\n",
       "      <td>0.069764</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>[16, 8, 1]</td>\n",
       "      <td>7</td>\n",
       "      <td>{'loss': tensor(1.2733e+08), 'train_loss': ten...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.245753e+01</td>\n",
       "      <td>2024-12-07 21:07:15.905151</td>\n",
       "      <td>2024-12-07 21:07:17.269298</td>\n",
       "      <td>0 days 00:00:01.364147</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>10</td>\n",
       "      <td>{'loss': tensor(22.4575), 'train_loss': tensor...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>6.207273e+01</td>\n",
       "      <td>2024-12-07 21:07:17.269298</td>\n",
       "      <td>2024-12-07 21:07:18.598028</td>\n",
       "      <td>0 days 00:00:01.328730</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>[16, 8, 1]</td>\n",
       "      <td>9</td>\n",
       "      <td>{'loss': tensor(62.0727), 'train_loss': tensor...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>3.401863e+01</td>\n",
       "      <td>2024-12-07 21:07:18.598028</td>\n",
       "      <td>2024-12-07 21:07:19.964827</td>\n",
       "      <td>0 days 00:00:01.366799</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>[168, 24, 1]</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>6</td>\n",
       "      <td>{'loss': tensor(34.0186), 'train_loss': tensor...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.661212e+01</td>\n",
       "      <td>2024-12-07 21:07:19.964827</td>\n",
       "      <td>2024-12-07 21:07:21.420339</td>\n",
       "      <td>0 days 00:00:01.455512</td>\n",
       "      <td>0.005575</td>\n",
       "      <td>[24, 12, 1]</td>\n",
       "      <td>[16, 8, 1]</td>\n",
       "      <td>2</td>\n",
       "      <td>{'loss': tensor(16.6121), 'train_loss': tensor...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>5.422427e+01</td>\n",
       "      <td>2024-12-07 21:07:21.420339</td>\n",
       "      <td>2024-12-07 21:07:22.651821</td>\n",
       "      <td>0 days 00:00:01.231482</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>[168, 24, 1]</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>7</td>\n",
       "      <td>{'loss': tensor(54.2243), 'train_loss': tensor...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.772611e+01</td>\n",
       "      <td>2024-12-07 21:07:22.651821</td>\n",
       "      <td>2024-12-07 21:07:23.968419</td>\n",
       "      <td>0 days 00:00:01.316598</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "      <td>[2, 2, 2]</td>\n",
       "      <td>1</td>\n",
       "      <td>{'loss': tensor(17.7261), 'train_loss': tensor...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number         value             datetime_start          datetime_complete   \n",
       "0       0  1.688148e+01 2024-12-07 21:07:10.355972 2024-12-07 21:07:11.927400  \\\n",
       "1       1  1.645361e+01 2024-12-07 21:07:11.928402 2024-12-07 21:07:13.321231   \n",
       "2       2  1.547846e+01 2024-12-07 21:07:13.321231 2024-12-07 21:07:14.602140   \n",
       "3       3  1.273332e+08 2024-12-07 21:07:14.603141 2024-12-07 21:07:15.905151   \n",
       "4       4  2.245753e+01 2024-12-07 21:07:15.905151 2024-12-07 21:07:17.269298   \n",
       "5       5  6.207273e+01 2024-12-07 21:07:17.269298 2024-12-07 21:07:18.598028   \n",
       "6       6  3.401863e+01 2024-12-07 21:07:18.598028 2024-12-07 21:07:19.964827   \n",
       "7       7  1.661212e+01 2024-12-07 21:07:19.964827 2024-12-07 21:07:21.420339   \n",
       "8       8  5.422427e+01 2024-12-07 21:07:21.420339 2024-12-07 21:07:22.651821   \n",
       "9       9  1.772611e+01 2024-12-07 21:07:22.651821 2024-12-07 21:07:23.968419   \n",
       "\n",
       "                duration  params_learning_rate params_n_freq_downsample   \n",
       "0 0 days 00:00:01.571428              0.002851                [1, 1, 1]  \\\n",
       "1 0 days 00:00:01.392829              0.004284                [1, 1, 1]   \n",
       "2 0 days 00:00:01.280909              0.004060              [24, 12, 1]   \n",
       "3 0 days 00:00:01.302010              0.069764                [1, 1, 1]   \n",
       "4 0 days 00:00:01.364147              0.000101                [1, 1, 1]   \n",
       "5 0 days 00:00:01.328730              0.000018                [1, 1, 1]   \n",
       "6 0 days 00:00:01.366799              0.000060             [168, 24, 1]   \n",
       "7 0 days 00:00:01.455512              0.005575              [24, 12, 1]   \n",
       "8 0 days 00:00:01.231482              0.000017             [168, 24, 1]   \n",
       "9 0 days 00:00:01.316598              0.001261                [1, 1, 1]   \n",
       "\n",
       "  params_n_pool_kernel_size  params_random_seed   \n",
       "0                [16, 8, 1]                   9  \\\n",
       "1                 [2, 2, 2]                   7   \n",
       "2                 [2, 2, 2]                   9   \n",
       "3                [16, 8, 1]                   7   \n",
       "4                 [2, 2, 2]                  10   \n",
       "5                [16, 8, 1]                   9   \n",
       "6                 [2, 2, 2]                   6   \n",
       "7                [16, 8, 1]                   2   \n",
       "8                 [2, 2, 2]                   7   \n",
       "9                 [2, 2, 2]                   1   \n",
       "\n",
       "                                  user_attrs_METRICS     state  \n",
       "0  {'loss': tensor(16.8815), 'train_loss': tensor...  COMPLETE  \n",
       "1  {'loss': tensor(16.4536), 'train_loss': tensor...  COMPLETE  \n",
       "2  {'loss': tensor(15.4785), 'train_loss': tensor...  COMPLETE  \n",
       "3  {'loss': tensor(1.2733e+08), 'train_loss': ten...  COMPLETE  \n",
       "4  {'loss': tensor(22.4575), 'train_loss': tensor...  COMPLETE  \n",
       "5  {'loss': tensor(62.0727), 'train_loss': tensor...  COMPLETE  \n",
       "6  {'loss': tensor(34.0186), 'train_loss': tensor...  COMPLETE  \n",
       "7  {'loss': tensor(16.6121), 'train_loss': tensor...  COMPLETE  \n",
       "8  {'loss': tensor(54.2243), 'train_loss': tensor...  COMPLETE  \n",
       "9  {'loss': tensor(17.7261), 'train_loss': tensor...  COMPLETE  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = nf.models[0].results.trials_dataframe()\n",
    "results.drop(columns = \"user_attrs_ALL_PARAMS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052c5316-f37d-4f34-94ca-3830ec8b1a05",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## model predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc1bff8b-95e3-4e10-8dde-9160c8f8c15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09791c7175014f6eaf03ec67b7d7f266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>AutoNHITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-01-31</td>\n",
       "      <td>453.378510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-02-28</td>\n",
       "      <td>425.522949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-03-31</td>\n",
       "      <td>495.473328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-04-30</td>\n",
       "      <td>503.095551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-05-31</td>\n",
       "      <td>510.216248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-06-30</td>\n",
       "      <td>576.599426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-07-31</td>\n",
       "      <td>666.714111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-08-31</td>\n",
       "      <td>674.762451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-09-30</td>\n",
       "      <td>585.423401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-10-31</td>\n",
       "      <td>506.677429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-11-30</td>\n",
       "      <td>438.493683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1961-12-31</td>\n",
       "      <td>477.154541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unique_id         ds   AutoNHITS\n",
       "0         1.0 1961-01-31  453.378510\n",
       "1         1.0 1961-02-28  425.522949\n",
       "2         1.0 1961-03-31  495.473328\n",
       "3         1.0 1961-04-30  503.095551\n",
       "4         1.0 1961-05-31  510.216248\n",
       "5         1.0 1961-06-30  576.599426\n",
       "6         1.0 1961-07-31  666.714111\n",
       "7         1.0 1961-08-31  674.762451\n",
       "8         1.0 1961-09-30  585.423401\n",
       "9         1.0 1961-10-31  506.677429\n",
       "10        1.0 1961-11-30  438.493683\n",
       "11        1.0 1961-12-31  477.154541"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat_df_optuna = nf.predict()\n",
    "Y_hat_df_optuna = Y_hat_df_optuna.reset_index()\n",
    "Y_hat_df_optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbf1ee1-f7cb-41f1-947c-6b78b27ec3da",
   "metadata": {},
   "source": [
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "110f95f4-485f-46ae-b011-6477a1a957a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABmcAAAKHCAYAAAB0L5wRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3hUZdrH8e+U9EYSUiGEIN0uKqAiVhDRRUVcLAgW1rWvum5xXQXd1d21oL7rumtB7BUrNhBBpSqgIB0kAUIaIZXUmcx5/5jMkJieaQn5fa5rrg1znvM895QT3/fcue/HZBiGgYiIiIiIiIiIiIiIiPiFOdABiIiIiIiIiIiIiIiI9CRKzoiIiIiIiIiIiIiIiPiRkjMiIiIiIiIiIiIiIiJ+pOSMiIiIiIiIiIiIiIiIHyk5IyIiIiIiIiIiIiIi4kdKzoiIiIiIiIiIiIiIiPiRkjMiIiIiIiIiIiIiIiJ+pOSMiIiIiIiIiIiIiIiIHyk5IyIiIiIiIiIiIiIi4kdKzoiIiIjIYW/p0qWYTCZMJhOzZs0KdDgiIiIiIiLSwyk5IyIiIiLdwiOPPOJOsJhMJt55551Ah9Qonl8+IiMj6devHxdccAFPP/00ZWVlgQ5XpE1ZWVmtfq+be8yYMSPQYUsrsrKymDVrFrNmzWLp0qWBDkdERERE6ik5IyIiIiLdwty5c1v9d1dTUVHB3r17+eSTT7jlllsYPHgwX3zxRaDDEpEeJisri9mzZzN79mwlZ0RERES6EGugAxARERERacvy5cvZunVro+cWLlxIdnY2ffv2bfP8M844A8MwfBUeAO+//36jf5eXl/Pjjz/y8ssvU1hYSH5+PpMmTWLp0qWMGjXKp7GIeENCQgLPPvtsm+P69evnh2hERERERA4vSs6IiIiISJf3wgsvuH++5pprePHFF3E4HMybN4977703gJEdctFFFzV5btq0adxzzz2cd955rFmzhpqaGu644w5Wrlzp/wBFOig8PLzZ77WIiIiIiHhObc1EREREpEsrLy/n7bffBmDQoEE88cQThIWFAfDiiy/6vCLGU/Hx8bz00kvuf69atYq9e/cGMCIREREREREJNCVnRERERKRLe+utt6ioqACclSjR0dFcfPHFAOzatatdeygsXbrUvXn5rFmzmh3Tv39/TCYT/fv3B6Cmpoann36aM844g5SUFCwWi/tYRw0fPpyBAwe6/71hwwb3z9XV1Xz44YfcdtttnHLKKSQkJBAUFERUVBSDBg1i2rRpLFq0qF3rlJWV8dhjj3HmmWeSlJREcHAwUVFR9O/fn5NOOonrrruOd955h9ra2mbPz8vLY/bs2Zx66qn07t2boKAgYmJiOOKIIxg9ejQ33XQTn376KQ6Ho9U4fvzxR26//XaOPfZY4uLiCAkJITU1lYkTJzJ37lzsdnur57s+qzPOOMP9Hj311FOMHj2a+Ph4wsLCGDhwIDfeeCOZmZntem8qKip46KGHGDFiBDExMURFRXHkkUfypz/9iX379gEwY8YM99pZWVmtzldaWspjjz3GOeecQ2pqKiEhIcTFxTFixAj+/Oc/u+dsSXNrffDBB1xyySWkp6cTEhLSbBzffvst1157LcOGDSMqKoqgoCASExMZPnw45513Hg8++CDbt29v13viayUlJfzjH/9gzJgx7u9jYmIip512Gg8//DAlJSWtnj9r1iz3e+S6zpcuXcq0adMYMGAA4eHhjY41lJeXxwMPPMBpp51GcnIywcHB9O7dm1NOOYW//e1vFBcXt/t1/PTTT9x1112MGDHCfX3GxMRw/PHHc+ONN/L55583e00YhsHy5cu57777OPfcc+nbty+hoaGEhYXRt29ffvWrXzF37twWr8eGHA4Hr7/+OhdddBHp6emEhYURGhpKnz59OPbYY5kyZQr/+c9/OHDggPsc1++9M8880/3c7Nmz3e9pw0db33cRERER8QFDRERERKQLGzVqlAEYJpPJyMzMNAzDML744gsDMADjyiuvbHOOJUuWuMfff//9zY5JT083ACM9Pd3IzMw0jjrqKPc5rkd6enqjcxoea8spp5ziHvvaa6+5n8/IyGiyTnOPSZMmGeXl5S3Ov2bNGiM5Obldc33//fdNzv/000+NqKiodp2/f//+ZmOorq42rr32WsNkMrV6/pFHHmn8/PPPLb4W17ixY8cau3btMo4++ugW54qIiDCWLFnS6nu/efNm9+fb3CM+Pt5YunSpMX36dPdzru9ac95++20jLi6u1dcYGhpqzJs3r8U5Gq61bds2Y/Lkyc3O44qjrq7OuOGGG9r1+UycOLHV96M1mZmZLX7fO+KTTz5p8z2Ki4szPvnkkxbnuP/++91jlyxZYtx6663NzvPLz//JJ580wsPDW107NjbW+Pzzz1t9DZWVlcY111zT5vcZMD744IMm519zzTXt+ryGDh1qbN++vcU4CgsL3b8H23o88sgj7vMa/t5r69Ha911EREREfEN7zoiIiIhIl7V582ZWrVoFwNixY92VK+eccw59+vRh3759vPfee5SWlhITE+OVNWtqarjkkkvYuHEjo0aN4tJLL6Vv374UFRWxadOmTs9bUFDg/rlhrJWVlfTq1YuzzjqL448/nvT0dMLDwykrK2PDhg289dZb5Obm8uGHH3Lttde6W7w1VFlZyUUXXUReXh4AI0aM4OKLL6ZPnz5ERERQXFzMli1bWLJkCevXr29yfk5ODpdddhkHDx4EnO/1xIkTSU5OJiQkhMLCQjZu3MjixYtbrMqw2+2cd9557iqG1NRUpk6dyjHHHEN4eDjZ2dm89957LFu2jE2bNnH66afzww8/kJCQ0OJ7VlZWxsSJE9myZQvjxo3jwgsvJCkpidzcXF566SXWrVtHRUUFU6dOZcuWLcTGxjaZY//+/Zx99tnk5uYCzs3rr732WoYMGcLBgwdZuHAh7777LpMnT+a4445rMRaX5557jhtuuAHDMAgODmbSpEmcfvrpJCUlcfDgQZYtW8brr79OdXU1M2bMIDg4mMsvv7zVOX/3u9/x2WefkZ6eztVXX83QoUOprq7mu+++IyQkBIB///vf/O9//wMgKiqKSy+91F3JUVtbS3Z2NmvWrOHLL79s8zX42hdffMGkSZPcFVIjR45k6tSppKamkpuby5tvvsmqVasoKipi0qRJLFiwgPHjx7c657/+9S8+++wzEhISmD59OscccwwAP/zwA9HR0e5x9957L3//+98BiIiI4NJLL3VXXBUVFbF48WLmz59PcXExF1xwAV999RVjxoxpsl5NTQ3nnnsuy5cvB8BqtXLJJZcwduxYEhISqKysZOvWrSxatIi1a9c2216xsrKS4OBgTjvtNEaOHMnAgQOJjo6mpqaGnTt38t5777Fhwwa2bt3KhAkTWLduXaPX4jJz5kz378G0tDSmTp3KoEGDiI2NpaKigh07drBy5Uq+/fbbRucdddRRvP/++2zcuJG//vWvAPz6179m6tSpTdZITExs9f0XERERER8IdHZIRERERKQld955p/svu1988cVGx/70pz+5j/3nP/9pdZ6OVM64Hv/4xz/ajK/h+NZs2bKl0djdu3e7j3366adGbW1ti+dWVFQYF110kfvcb7/9tsmYd955x338zjvvbDWWTZs2GQUFBY2ee+SRR9znP/XUU62ev2rVKqOqqqrJ8w0/j5kzZzY7xjCcVQ2ucS1VPTV8r6xWq/HOO+80GWOz2YzzzjvPPe6xxx5rdq6rr77aPeass84yDh482GTMggULjODg4DYrCdavX+8eN2jQIGPLli3Nrrl582YjNTXVAIyoqCjjwIEDTcY0rJwBjIsuuqjF98wwDOPII490V3xkZWW1OK6qqspYtWpVi8fb4mnlTHl5uZGUlOSeY9asWYbD4Wg0xuFwGPfdd597TFJSklFWVtZkroaVM4AxevRoo6ioqMW1P/vsM3eVy6hRo4zs7Oxmxy1btsxdJda/f3/DZrM1GdOwSmfw4MHG1q1bW1x3w4YNxrZt25o8//XXX7car8PhMB5++GH3Og8++GCTMfn5+YbZbDYA45RTTmn1O1JQUGBs3ry5yfPt+f0nIiIiIv6n5IyIiIiIdEm1tbVGQkKCARjh4eFNWno1THiceOKJrc7V0eTMpEmT2hVje5IzRUVFxsiRI93jRo4c2a65GyotLTUiIiIMwLj++uubHG94g3fTpk0dnr9hu6yKiooOn5+fn2+EhoYagHHOOee0Of6KK64wAMNisTR7A73h+3rfffe1OE/D70Bz6+bl5RlBQUEGYMTExBj5+fktznXvvfe2mZy5+OKLDXC2LNuxY0err3HhwoWtJvoaJmf69OnTass6wzCMkJAQAzCmTJnS6jhPNUzOtOfxy2vlqaeech87//zzW12rYXLtiSeeaHK8YXImIiKixWSLywknnGAARkJCQrMJsYaeffZZ99xvvvlmo2N79uxxf2+ioqJabcHnDaeddpoBGAMHDmxybOXKle44n3766U7Nr+SMiIiISNdkRkRERESkC/roo4/Yv38/AJdccgmRkZGNjg8dOpSTTz4ZgDVr1rBhwwavrX3bbbd1+JwPPvig0ePVV1/l7rvvZujQoaxevRqA4OBg5syZ0+G5o6OjOfroowHc7Y0aioiIcP+8du3aDs/v6flvvfUW1dXVANx9991tjp8+fToAdXV1LF68uMVxZrOZ22+/vcXjQ4cOpW/fvgBs3LixyfFPPvkEm80GwJVXXtlq66Zbb70Vi8XS4vGSkhI+/PBDAC6++GIGDhzY4liAc889l5SUFMDZ5qs11157bZPv9y+5PqOffvqpXRvIB8p7773n/vmPf/xjq2PvueeeZs9rziWXXEKfPn1aPP7TTz+xbt06AK6//nri4uJane+KK67AanV2+f7l5/PWW2+5vzczZ85kwIABrc7lqdNOOw2AnTt3cuDAgUbHPL02RURERKTr0p4zIiIiItIlzZ071/2z62b+L02fPp3vvvsOgBdeeIEnn3zS43UtFgunnHJKh8+7+OKLWz2ekJDAvHnzGD16dJNjxcXFvPbaa3z++eds3LiRAwcOUFFR0ew+FtnZ2U2eO+ecczCZTBiGwY033sjOnTu5/PLLGTp0aLtiHzduHI8//jjgvAn+xz/+kSlTppCent6u87/55hv3z/n5+XzwwQetjt+3b5/7582bN7c4bsiQIW3eZO/bty/Z2dkUFxc3Ofb999+7fz7zzDNbnScxMZEjjzyyxSTf8uXLcTgcAISEhLT5GsG5N0xubm6rrxFods+TXxo3bhxvvvkmW7du5eyzz+bOO+9k/PjxhIeHt3luZyUkJPDss8+2OsaVgAIwDMN9PYaHh7uTDi059dRTiYiIoKKigu+//x6Hw4HZ3PzfD7b1HjX8DtbV1bXr84mMjKSkpKTJ59Nw75ZJkya1OU9r7HY77733Hh988AE//vgjOTk5lJeXu79Lv5SdnU18fLz738OHD3fvrzV37lzq6uqYOXMmo0aNajWZKCIiIiJdn5IzIiIiItLl7Nu3z/3X7H379uWss85qdtzUqVO54447qK2t5bXXXuORRx4hODjYo7Xj4+MJDQ31aA6AsLAw4uPjOfroo5kwYQLTpk2jV69eTcZ9+OGHXHfddU3+Yr4lZWVlTZ4bNmwY9957Lw8++CAVFRU88MADPPDAA6SkpHDKKacwZswYzjvvPIYMGdLsnOPHj+fqq6/m5ZdfprCwkLvvvpu7776bjIwMRo8ezemnn875559PWlpas+dnZWW5f7766qvb9TpcioqKWjzWu3fvNs8PCQkBnBu4/1JOTo775yOOOKLNuQYMGNBicqbha5w3bx7z5s1rcz6X1l4j4K7+ac0///lPli1bRnZ2NsuWLWPZsmUEBQVxwgkncMopp3DGGWcwbtw4r3x3XcLDw7nooovaPb6srIzKykrA+X63lGhxMZvNDBw4kPXr11NVVUVJSUmLybi23qOGn8+//vWvdscMTT+fhgnQ4cOHd2iuhrZt28Yll1zSZnKuoV9e3xaLhWeffZZLLrmEmpoaXnrpJV566SWio6MZOXIkp556Kueccw6nnHIKJpOp07GKiIiIiP8pOSMiIiIiXc68efOoq6sD4KqrrmrxJm9cXBwXXngh8+fP58CBA3zwwQdcdtllHq0dFhbWqfOaq3Jpy8qVK7n00kux2+0AHHPMMZxzzjkMHDiQ2NhYQkJC3Ddc7733XjZt2tTiX9w/8MADnHTSSfzjH/9gxYoVAOTm5jJ//nzmz58POCsVHnvsMUaOHNnk/Hnz5nHWWWfx+OOPuxMUmZmZZGZm8vrrr2MymZgwYQKPP/54kyRPSUlJh1+7S2stutq6ud+WiooK98/tqTBp2ELqlzx5ja4WWS1pz3euX79+/PDDD/z973/n5ZdfpqioCJvNxurVq1m9ejVz5swhOjqa22+/nb/85S/upJU/lZeXu39u7b1sqGE7t/Ly8haTM229R978DjZMkLTVbq4lpaWlnHXWWe4EYWpqKhMnTmTYsGEkJSURGhrq/n6/+eabvPXWWwDu33sNnX/++axZs4bZs2fz0UcfUVtbS1lZGYsWLWLRokXMmjWLjIwMHnjgAa666qpOxSsiIiIi/qfkjIiIiIh0KYZhNGpp9o9//IN//OMf7Tp37ty5Hidn/Om+++5zJ2aefvppbrrpphbH/v3vf29zvgsvvJALL7yQ/Px8vv32W1auXMnXX3/NunXrMAyD5cuXM2bMGD799FPOOeecRueaTCamT5/O9OnT2b17N8uWLWPlypUsXbqUTZs2YRgGn376Kd9++y3Lly9374EDjW9gl5WVERUV1dG3wicaJghcFR2taZjM+aWGr/Gpp57i1ltv9Sy4Tujduzdz5szhkUceYd26daxYsYIVK1awePFiioqKKCsr48EHH2T58uUsWrTI4+RWRzX83Ft7Lxs6ePBgs+d3VMPP56OPPuLCCy/s9FzR0dHunw8ePNipaqR///vf7sTMlVdeydy5c1us6lu+fHmb8x111FG88847VFRUsHz5clatWsW3337Lt99+S01NDZmZmUybNo2ff/6Z+++/v8PxioiIiIj/+ff/WhcRERERacPSpUvZtWtXp85dtGgRe/fu9XJEvmGz2Vi6dCkAI0aMaDUxA43bNrUlKSmJSy+9lMcee4w1a9aQlZXFlClT3OvecccdrZ6fnp7OlVdeyb///W82btzI5s2bGTt2LOCsbmi4kTs0bjnVld7/1NRU988///xzm+Nb+951pddotVo5+eST+d3vfsfbb79NQUEB77zzDjExMQB89dVXvP/++36PKzo62p0Q27VrV4tVXi4Oh8P9uYSFhTXb9q+9vPn5NJyrIy3JGlq4cCHg/Kz+7//+r9V2i5mZme2eNyIignHjxnHfffexaNEi9u/fz4MPPug+/ve//528vLxOxSwiIiIi/qXkjIiIiIh0KS+88IL758mTJ3P//fe3+Tj33HMB583ejuwFEkiFhYXuqpmBAwe2Ovb777+nsLCw02v169eP1157jYSEBAA2btzYoTZQw4YNY/78+e5KjIYbpgPuxA3AZ5991uk4ve2kk05y/7xkyZJWxxYUFLBp06YWj48ZM8bdYu7zzz/3ToBeYrFYuPTSS5k1a5b7uV9+Rv5gMpnc77mrwqM1y5cvd1fOnHTSSR5V+njzO3j66ae7f/7www87NYcrQRIfH09sbGyL46qrq91J2s6Iiori3nvvZdKkSYAz+bpq1apGYxq+r51pvygiIiIivqG2ZiIiIiLSZZSUlLj3R7FarTzzzDPuhEJrNmzYwLHHHgvAiy++yL333tvlN8du2HJr586drY71RpuioKAg+vTpw/79+wHciaH2io+PJzo6mpKSkibnTp06lXvvvZeamhoef/xxpk+fTu/evT2O2VPnn38+VqsVu93Oa6+9xqxZs1r8Pv3f//1fs/t9uCQmJjJhwgQ+/fRTfvrpJ9544w0uv/xyX4XeKRkZGe6fO/r5esvkyZPdyYZ//vOfjBkzpsWxDdsVTp482aN1R4wYwVFHHcXGjRv55JNPWL58Oaeeemqn5vr1r3/NPffcQ21tLc8++yw333wzAwYM6NAcruu7oKCAsrKyRq3SGnryySc5cOBAp+JsqLXPvmHLt/a2mxMRERER31PljIiIiIh0Ga+//jrV1dUATJgwoV2JGYBjjjmG4447DnC2CGqrSqIriI6OZvDgwQCsXbuWd999t8mYuro67rjjjjYrAZ566ineeeedJhubN7R8+XI2bNgAONs2NUyezJ49my+++KLVNlRvvPGGu9rG9V679O3bl9tuuw2AnJwcxo8f32ZruvXr13PDDTe0OsZTycnJXHHFFYBzg/apU6c2e3P6k08+4V//+leb8/397393t6e6/vrreeONN1odX1RUxOOPP86XX37ZiegPyc3N5a677mq1NZvdbue5555z//uXn5G/zJgxg6SkJMD5vjZsudXQgw8+yKeffgo42/Bdc801Hq1rMpncyR7DMLjooovafN9zcnKYNWuW+7pw6du3LzfeeCPg3HNmwoQJbNu2rcV5Nm3axI4dOxo956ogMgyDv/zlL82e98Ybb/DXv/611Ri/+OIL5syZQ3FxcYtjCgoK3EltwJ2odmmYuFm3bl2r64mIiIiI/6hyRkRERES6jIYtza6++uoOnXv11Vfz448/uuc566yzvBmaT/zud79z7zVz2WWX8etf/5qxY8cSGxvLzp07ee2119iyZQtHHXUUISEhrF27ttl51q1bx0svvURMTAzjx4/nhBNOoE+fPgQHB5Ofn8/XX3/NRx995E6+/HLPmCVLljBr1iwSExMZP348xx13HMnJyZjNZnJzc/niiy9YtGiRe/wvzwd46KGHWL9+PQsXLmTdunUMHTqUX/3qV4wZM4aUlBQcDgeFhYVs3LiRJUuWsH37diwWC//73/+89XY269FHH2XRokXk5uby1VdfMXz4cK699lqGDh1KeXk5Cxcu5N133yUuLo7jjjuOxYsXAzTbYuu4447jf//7H9dddx2VlZVcccUV/Otf/+LCCy9k0KBBhIWFUVpays6dO/nuu+/45ptvsNvtvPLKKx69BldF0uOPP86IESMYM2YMw4YNIzY2loMHD7Jr1y7eeOMNd/JmwIABTJ061aM1OysyMpKXXnqJiRMnUldXx3333cdnn33Gr3/9a1JSUsjLy+PNN99k5cqVgLNC7qWXXiIqKsrjtSdOnMgDDzzAfffdR2FhIeeeey5jxozhvPPOo3///gQFBVFSUsK2bdtYsWIFq1atwjAMzjnnnCZz/fOf/+T7779nxYoVbN++naOPPpqLL76YsWPHkpiYSGVlJdu3b2fx4sWsXr2a9957j0GDBrnPv+WWW5g7dy52u51///vfrFu3jksvvZQ+ffqQn5/Phx9+yOLFi4mMjORXv/pVo+RKQ7m5udx555388Y9/5IwzzmDUqFEMGDCAyMhIDhw4wIYNG3jjjTfcyZvLLrusURwAsbGxnHDCCaxbt44lS5Zwww03cM455zR6z8eOHUtYWJjHn4GIiIiIdIAhIiIiItIF/PDDDwZgAEZsbKxRXV3dofPz8/MNq9VqAEZoaKhRXFzsPrZkyRL33Pfff3+z56enpxuAkZ6e3u41XXN29v+sdjgcxrXXXttonl8+jj76aGPXrl3G2LFjW1xrxowZrc7hegQFBRl/+9vfmpx/xhlntOv8iIgIY+7cuS2+ntraWuOuu+5yfw5tPVp6r13Hx44d2+Z72Nr74rJ582ajX79+LcYRHx9vLF261LjyyivdzxUVFbU43+eff26kpqa26zWGhIQYn332WZM5pk+f7h6TmZnZ6mvMyspq11qAcdRRRxk7d+5s831rSWZmZpufT3ssWLDAiI2NbTXW2NhYY8GCBS3Ocf/997vHLlmypN1rv/TSS22u7XpERUUZGzZsaHaeiooK46qrrmrXPB9++GGT81944YVWr4X4+Hjjiy++aPV1zps3r92f/aWXXmpUVFQ0+1o+//zzVmNp6zsoIiIiIt6nyhkRERER6RIaVs38+te/JiQkpEPnJyYmct5557FgwQKqq6t5/fXX3VUpXZXJZOKFF15g4sSJPPvss6xZs4aysjLi4+MZMmQIU6ZM4brrriM0NLTVeZ555hmmTp3KkiVLWLNmDdu3b2f//v3Y7Xaio6MZNGgQZ5xxBtddd12Tv6oH+Pjjj/nyyy/5+uuvWbduHTt37qSwsBDDMOjVqxdDhw7lnHPO4frrryc1NbXFOIKCgnj00Ue59dZbmTt3LkuWLGHHjh0UFRVhNpuJj49n8ODBjBw5kvHjxzfaeN2Xhg0bxubNm3nyySd599132blzJ4ZhkJaWxoUXXshtt91Gnz593G2xrFZri3uEAO62ba+//jqffvopa9euZf/+/VRXVxMVFUX//v059thjOeuss7jwwgvp1auXR/Gnp6fz888/88UXX7BixQo2bNjAnj17KC8vJzg4mOTkZI4//ngmT57MZZddhtUa+P83b+LEiezatYtnnnmGTz75hG3btlFSUkKvXr0YPHgwEydO5KabbvL4vWnO1VdfzcUXX8xLL73EF198wfr16yksLMRutxMTE8OAAQM44YQTOPvsszn//PMJDw9vdp7w8HBeeeUVfve73/Hiiy+ydOlSsrOzOXjwIFFRUQwYMIBRo0YxefJkzjzzzCbnX3vttRx33HE8/vjjfP311+Tn5xMVFUW/fv248MIL+e1vf0tqaiorVqxo9bUMHz6cL7/8ktWrV7NlyxZycnKoqqoiPDycfv36MWrUKKZNm8bYsWNbnGf8+PGsXLmSp556ihUrVpCbm0tlZWXH31wRERER8RqTYRhGoIMQEREREREJJIfDQXJyMvv37+fYY491t8gTERERERHxhaaNlEVERERERHqYt956i/379wM0WwUhIiIiIiLiTUrOiIiIiIjIYW3VqlXU1NS0eHzZsmXcfPPNAJjNZn7zm9/4KzQREREREemhAt+MWERERERExIf+9re/sWLFCiZMmMCJJ57o3jdn3759fPnll3z++ee4uj3/4Q9/YNiwYYEMV0REREREegDtOSMiIiIiIoe1Cy64gE8++aTVMSaTibvuuot//vOfmM1qMCAiIiIiIr6l5IyIiIiIiBzWtm7dyltvvcWyZcvYvXs3Bw4coKysjKioKPr168fYsWP5zW9+w5FHHhnoUEVEREREpIdQckZERERERERERERERMSPtOeMBxwOBzk5OURFRWEymQIdjoiIiIiIiIiIiIiIBJBhGJSXl5Oamtpqy2QlZzyQk5NDWlpaoMMQEREREREREREREZEuZO/evfTt27fF40rOeCAqKgpwvsnR0dEBjkakeTabjYULFzJu3DiCgoICHY7IYUnXmYh/6FoT8T1dZyK+p+tMxPd0nYn4nq6zlpWVlZGWlubOH7REyRkPuFqZRUdHKzkjXZbNZiM8PJzo6Gj9ohTxEV1nIv6ha03E93SdifierjMR39N1JuJ7us7a1tZWKC03PBMRERERERERERERERGv65bJmf79+2MymZo8br75ZgCqq6u5+eabiY+PJzIyksmTJ5Ofn99ojj179jBx4kTCw8NJTEzk7rvvxm63B+LliIiIiIiIiIiIiIhID9ItkzPff/89ubm57seiRYsAmDJlCgB33HEHH3/8Me+88w5ff/01OTk5XHLJJe7z6+rqmDhxIrW1taxYsYKXXnqJefPmcd999wXk9YiIiIiIiIiIiIiISM/RLZMzCQkJJCcnux8LFizgiCOOYOzYsZSWlvLCCy/w+OOPc9ZZZzFixAhefPFFVqxYwapVqwBYuHAhmzdv5tVXX+W4445jwoQJPPjggzz99NPU1tYG+NWJiIiIiIiIiIiIiMjhzBroADxVW1vLq6++yp133onJZGLt2rXYbDbOOecc95ihQ4fSr18/Vq5cyahRo1i5ciVHH300SUlJ7jHjx4/nxhtvZNOmTRx//PHNrlVTU0NNTY3732VlZYBz8yObzeajVyjiGdd3U99REd/RdSbiH7rWRHxP15mI7+k6E/E9XWcivqfrrGXtfU+6fXLmgw8+oKSkhBkzZgCQl5dHcHAwvXr1ajQuKSmJvLw895iGiRnXcdexljz88MPMnj27yfMLFy4kPDzcg1ch4nuu9n8i4ju6zkT8Q9eaiO/pOhPxPV1nIr6n60zE93SdNVVZWdmucd0+OfPCCy8wYcIEUlNTfb7Wn//8Z+688073v8vKykhLS2PcuHFER0e3ex673Y7dbvdFiNKDWK1WrNa2L2GbzcaiRYs499xzCQoK8kNkIj2PrjMR/9C1JuJ7us5EfE/XmYjv6ToT8T1dZy1zddxqS7dOzuzevZsvv/yS9957z/1ccnIytbW1lJSUNKqeyc/PJzk52T3mu+++azRXfn6++1hLQkJCCAkJafJ8UFBQu76AZWVlFBYWNmqNJuKJkJAQevfu3a7kYHu/pyLSebrORPxD15qI7+k6E/E9XWcivqfrTMT3dJ011d73o1snZ1588UUSExOZOHGi+7kRI0YQFBTE4sWLmTx5MgDbtm1jz549jB49GoDRo0fz97//nYKCAhITEwFn+VV0dDTDhw/3SaxlZWXs27ePyMhIevfuTVBQECaTySdryeHPMAxsNhulpaXs27cPoEPVWyIiIiIiIiIiIiISON02OeNwOHjxxReZPn16o9ZOMTExXHfdddx5553ExcURHR3NrbfeyujRoxk1ahQA48aNY/jw4UybNo1//etf5OXlce+993LzzTc3WxnjDYWFhURGRtK3b18lZcQrwsLCiIqKIjs7m8LCQiVnRERERERERERERLqJbpuc+fLLL9mzZw/XXnttk2Nz5szBbDYzefJkampqGD9+PP/5z3/cxy0WCwsWLODGG29k9OjRREREMH36dB544AGfxGqz2aipqaF3795KzIhXmUwmYmJi2LdvHzabTSWEIiIiIiIiIiIiIt1At03OjBs3DsMwmj0WGhrK008/zdNPP93i+enp6Xz66ae+Cq+Ruro6oP295kQ6wvW9qqur03dMREREREREREREpBswBzqAnkRVM+IL+l6JiIiIiIiIiIiIdC9KzoiIiIiIiIiIiIiIiPiRkjMiIiIiIiIiIiIiIiJ+pOSMiIiIiIiIiIiIiIiIHyk5IyIiIiIiIiIiIiIi4kdKzoiIiIiIiIiIiIiIiPiRkjMiIiIiIiIiIiIiIiJ+pOSMiIiIiIiIiIiIiIiIHyk5I363Zs0aTCYTp5xySotjHnroIUwmE/fff78fIxMRERERERERERHxo+y1MO8CWP4kVJcFOhrxIyVnxO9OPPFETjjhBFauXMmmTZuaHDcMgxdeeAGz2cx1110XgAhFRERERERERERE/OCHVyDrW1h0HzxxFCx+EA7uD3RU4gfWQAfQ0xmGQZWtLtBhdEhYkAWTyeTRHL/97W/5zW9+w3PPPccTTzzR6NjixYvZtWsXEyZMoF+/fh6tIyIiIiIiIiIiItJlle51/m9wJFSXwrePwsqn4YRpMPoWiE0PbHziM0rOBFiVrY7h930R6DA6ZPMD4wkP9uyrc8UVV/D73/+eV155hX/+85+EhIS4jz3//PMAzJw506M1RERERERERERERLq00mzn/172EtRWwrLHIecH+O5Z+P4FOHoKnPY7SBwW0DDF+9TWTAIiIiKCq666iqKiIubPn+9+vrCwkPfff5/k5GQuvPDCAEYoIiIiIiIiIiIi4kOGASX1lTO9+sPwX8HMJXD1hzDgDDDqYMOb8J9R8MblsH9bIKMVL1PlTICFBVnY/MD4QIfRIWFBFq/M89vf/pb//Oc/PPfcc1xxxRUAvPzyy9TW1nLNNddgterrKSIiIiIiIiIiIoepqmKwVTh/junj/F+TyZmYGXAG7FsLy56gbNvHvJa/jNEvjOW4P+UFKlrxMt39DjCTyeRxi7Du6uijj+aUU05h6dKl7Nixg0GDBvHCCy9gMpm4/vrrAx2eiIiIiIiIiIiIiO+49puJSICgsKbH+4xg/ZET+UP5GnKCrHxdU8Ob/o1QfEhtzSSgfvvb3wLOfWaWL1/O5s2bOfvssxkwYECAIxMRERERERERERHxIdd+MzF9mxxy1NmZ+/G1zFjzN3KCnH/cv9dqBUedPyMUH1JyRgJqypQpxMfHM2/ePP7zn/8AMHPmzABHJSIiIiIiIiIiIuJjrv1mYtIaPX2gcDs3vXoqc4q+x24ycZYpCoAyi4WK/Vv8HaX4iJIzElChoaFMnz6dgoICXn/9dRISErjooosCHZaIiIiIiIiIiIiIb5U2Tc6sXvcsl350CcupJMRhcH/quTxx1TKi6hwA5GV9HYhIxQeUnJGAu+GGGzCZTABMnz6d4ODgAEckIiIiIiIiIiIi4mOu5EyvNOy2av79/lRmbniKQouJI+pMvDHmUS4993FMZjMpdjsAubnfBzBg8aaeuRO9dCmDBw+mb9++7N27l+uvvz7Q4YiIiIiIiIiIiIj4Xn1bszx7FX987VTWmWrBZOKS4GT+NOktwsLj3ENT6urYDuQWbgtQsOJtSs5IwK1cuZK9e/cyduxYhgwZEuhwRERERERERERERHyvNJsdQUFcu/15SiwWIhwG9w2YzPljZzcZmuyqnKnY5+8oxUeUnJGA+/vf/w7ALbfcEuBIRERERERERERERPzAVg0VBbwVH0uJxcJgh5k5Zz9Nv36nNTs8xeHcFiLXqlv6hwt9khIQK1as4IUXXmDjxo189913nHDCCVxyySWBDktERERERERERETE98qcFTA59cmWy/ue3WJiBiA1pj9QSK7F4ofgxB/MgQ5Aeqbt27czd+5ctmzZwsSJE3nvvfcwm/V1FBERERERERERkR6gZA8AuVZnsiW11xGtDk9JOAqAPFXOHDZ0N1wCYsaMGRiGQVlZGQsWLCA9PT3QIYmIiIiIiIiIiIj4R2k2BocqZ1ISjmx1eHLf0QDkWy3U2Wt9HZ34gZIzIiIiIiIiIiIiIiL+VLqXMrOZyvpuQilJx7Y6PCH9VKyGgd1kYv/+jf6IUHxMyRkREREREREREREREX8qzSanvqVZnMMgNCy21eGWqD4k2esAyNuz3Ofhie8pOSMiIiIiIiIiIiIi4k8le9wtzVIJanu8xUqy3Q5Abv4PvoxM/ETJGRERERERERERERERfyrNJte134w1sl2npNQ5K2dyDmzzWVjiP0rOiIiIiIiIiIiIiIj4i8MBZfvcbc1SQ+PbdVqKq3KmItdnoYn/KDkjIiIiIiIiIiIiIuIvB/OhrvZQ5UxkartOcyVn8iy6rX840KcoIiIiIiIiIiIiIuIvpdkAhypneg1o12kpMc5xuRaLb+ISv1JyRkRERERERERERETEX0r3ALgrZ1Ljh7brtJSkYxudJ92bkjMiIiIiIiIiIiIiIv5Smk2lyURxfQWMK+nSlpS0UwEot5gpL9vns/DEP5SckYAxmUyNHmazmZiYGEaNGsUTTzyBzWYLdIgiIiIiIiIiIiIi3lWyl7z6lmaRDoPomLR2nRaeOIyYujoA8gp+8ll44h+qf5KAmz59OgB1dXVkZWWxYsUKVq9ezYIFC/j888+xqkxPREREREREREREDhel2eTU3/NMoQP7x0SlkGKvo9RiIbdwM4MGnuejAMUfdNdbAm7evHmN/r169WrOOOMMFi9ezJtvvslVV10VmMBEREREREREREREvK10rzs5k2oJb/95EQkk2+1sDQkmr2Cjj4ITf1FbM+lyRo4cyYwZMwD44osvAhuMiIiIiIiIiIiIiDeV7iW3vq1ZSkhs+88zW0ixO9ua5RTv8EVk4kdKzkiXdOSRRwJQUFDQ6HnDMHjjjTeYOnUqgwcPJiIigqioKE4++WT+85//4HA4Go2/5ZZbMJlMPPvssy2uNWTIEMxmM7t27fL+CxERERERERERERFxqS6D6tJDlTMRKR06PaXODkBuZUEbI6WrU3JGuqTy8nIAEhMTGz1fU1PDFVdcwZdffklycjIXXngho0aNYtOmTdx8881ce+21jcbfcMMNADz33HPNrvP111+zfft2zj77bAYMGOCDVyIiIiIiIiIiIiJSrzQb4FDlTHR6h053Vc7kmR1tjJSuTskZ6ZI+//xzAM47r/GmVlarlffff5/c3Fy++eYb3nzzTRYtWkRWVhYnnngiL730Et988417/NFHH80pp5zCmjVr+PHHH5us40razJw503cvRkRERERERERERASgdC/AocqZ+CEdOj0luh8AuVZtJ9/dKTkTaIYBtRXd62EYPnkrHA4HP//8MzfeeCPffPMNkyZN4te//nWjMVarlYsuuoigoKBGzyckJPDwww8D8OGHHzY69tvf/hZoWj1TXFzM/PnzSUhI4KKLLvLyqxERERERERERERH5hZI92ID9FmflTGriMR06PSX5eAAKLBbstmpvRyd+pPRaoNkq4aHUQEfRMffkQHCE16YzmUxNnps5cyb/+9//mj0G8OOPP7Jw4UJ2795NZWUlhmG4W6Ht2NF4M6wpU6Zwxx138Nprr/HII48QHh4OwKuvvkp1dTW33HILwcHBXns9IiIiIiIiIiIiIs0qzSbfasFhMhFsGMTFDerQ6b1TTsRavAy7ycT+/ZtISR3ho0DF15SckYCbPn06ANXV1axfv56tW7fy3HPPccoppzBjxoxGY2tra5kxYwZvvPFGi/O5kjQuoaGhTJ8+nccff5x33nnHvd7zzz8PwPXXX+/FVyMiIiIiIiIiIiLSgtK97pZkKQ4TZkvHbtGbY/qSbLeTHRRErpIz3ZqSM4EWFO6sROlOgsK9Ot28efMa/fuRRx7hD3/4AzfffDNnnnkm6emHNsV6/PHHeeONNzj66KP517/+xQknnEBsbCxBQUFs376dIUOGYDTTdu2GG25gzpw5PPfcc0yfPp3vvvuODRs2cPrppzNkSMf6OoqIiIiIiIiIiIh0Smm2e7+ZFEtYx8+PSibFXudMzhTv9HJw4k9KzgSayeTVFmGHg7vvvpsvv/yShQsXMnv2bObOnes+9v777wPwxhtvcOSRRzY6b9euXS3OOXjwYM4880y++uortmzZ4t5/5je/+Y0PXoGIiIiIiIiIiIhIM0r2kmOt328mOKbj50clk2K3A5BbmuXFwMTfzIEOQKQ5//jHPwB45ZVX2L17t/v54uJiAPr27dvknLfffrvVOX/7298CzuqbN998k9jYWCZPnuytkEVERERERERERERaVmeD8txDbc3Ckzo+R0QCyfY6AHLLdrcxWLoyJWekSzr++OO56KKLsNvt/Otf/3I/P3jwYAD++9//Nhr/7rvv8vLLL7c650UXXURycjLPP/88Bw8eZNq0aYSGhno/eBEREREREREREZFfKtsHGO62ZqlR/To+h9lCqqtypmq/F4MTf1NyRrqsWbNmYTKZmDt3Lnl5eQD84Q9/wGKx8Kc//YkTTzyRK664gpNOOokpU6Zwxx13tDpfUFAQ1157rfvfamkmIiIiIiIiIiIiflOaDUBufVuzlNgjOjVNSl195YypzjtxSUAoOSNd1rHHHsvFF19MdXU1jz/+OACnn346y5Yt46yzzmLXrl0sWLCA4OBg5s+fz80339zmnGeddRYAo0ePbrJnjYiIiIiIiIiIiIjPlOzFAYfamiV07v5kckQq1M9jOBzeik78zBroAKTnMgyjzTHz589v8tyoUaNYvHhxp+Z07UujqhkRERERERERERHxq9JsDljM2EwmzIZBUtIxnZomOeUEOPgdFWYz5eX7iI5J83Kg4g+qnJEeY/fu3bzyyiv07t2bX//614EOR0RERERERERERHqS0j3u/WYSHBAUFN6pacLjBxHram1WsMFr4Yl/KTkjh71HHnmEadOmMXLkSKqqqrj33nsJCwsLdFgiIiIiIiIiIiLSk5Tsdbc0SzWHdH6eqGSS7c7kTN6Bbd6ITAJAyRk57H3yySe8+uqrWCwW7r//fm677bZAhyQiIiIiIiIiIiI9TWk2uVYLAClBUZ2fJzKZFLsdgNySTG9EJgGgPWfksLd06dJAhyAiIiIiIiIiIiI9mWFAaTY5MaEApIb27vxcUcmk1FfO5FTs80Z0EgCqnBERERERERERERER8aXKA2Cvcrc1S4nq2/m5olLclTN5VYXeiE4CQMkZERERERERERERERFfKtkDQE59W7PUXkd0fq6I3ofamtUUexyaBIaSMyIiIiIiIiIiIiIivlSaDeCunElNGN75ucwWd1uzXOwehyaBoeSMiIiIiIiIiIiIyGFgQ3YJM19ew5bcskCHIr9Uupcys4mDZuct+eSkYz2aLiUsAYD9Fgs2W6XH4Yn/KTkjIiIiIiIiIiIichh4eeVuFm3O56bX1lFVWxfocKSh0mx31UyswyA8vLdH08UlHkWww8BhMlFQsNEbEYqfKTkjIiIiIiIiIiIichjYW+SsoMgsrOCfn28NcDTSSMkecuqTMylYPZ7OHJ1Kcl39vjP7N3s8n/ifkjMiIiIiIiIiIiIih4Hs4ir3z/NWZLFiZ2EAo5FGSrPJsVoASLVGej5fVMqhfWeKd3o+n/idkjMiIiIiIiIiIiIi3Zy9zkFeWTUA44YnAXD3uxsoq7YFMixxKd3rbmuWEhrv+XxRSSTb6ytnynd7Pp/4nZIzIiIiIiIiIiIiIt1cbmk1dQ6DYKuZx399HP3iwtlXUsXfFqjlVcDVVkDlAXdbs9TIFM/nbFg5U1ng+Xzid0rOiIiIiIiIiIiIiHRzrpZmfXuFERli5dEpx2Iywdtrslm8JT/A0fVwpfsAyK1va5YSk+H5nJFJpLoqZ2pKPJ9P/E7JGQm4oqIiZs2axYknnkhsbCxhYWFkZGQwffp0Vq5cGejwREREREREREREurzs4koA+sSGAXByRhzXn+ZMAvzpvZ8orqgNWGw9XukegEOVM/FDPZ8zKsXd1iyvrqqNwdIVKTkjAbV48WIGDhzI7NmzycrKYsyYMUyaNIno6GhefvllTjnlFH73u9/hcDg8XmvWrFmYTCbmzZvneeAiIiIiIiIiIiJdiLtyJjbc/dxd44YwMDGS/eU1/PXDjYEKTUqzqTaZKLI4K2dSk471fM6I3u62ZjmmOgwv3D8V/1JyRgLm+++/5/zzz6ekpIQHHniA3NxcPvroI958803Wr1/Pt99+S9++fXnyySe5++67Ax2uiIiIiIiIiIhIl3UoORPmfi40yMLjlx2LxWxiwYZcPl6fE6jweraSve6WZuEOg+jofp7PabaQHBQFQJXZTFnZHs/nFL9SckYCwjAMpk+fTm1tLffffz9//etfCQoKajTmtNNOY+HChYSGhjJnzhxWrVoVoGhFRERERERERES6Nldbs4bJGYBj+vbi5jMHAvDXDzdSUFbt99h6vNJscl0tzQwzJrN3bsuHxvYnrs5ZPZObv8Erc4r/KDkjAfHZZ5+xZcsWUlNTueeee1ocN2zYMG6++WYMw+Dxxx93P3/GGWdgMpnIysri1VdfZcSIEYSHh5OYmMj06dPZt29fo3n69+/P7NmzAbjmmmswmUzux9KlS4G22571798fk8nU6LmlS5diMpmYMWMGRUVF3HjjjaSkpBASEsJRRx3F3Llzm53rk08+4dprr2XYsGFER0cTERHBsccey0MPPURNTU1bb5+IiIiIiIiIiEgjzbU1c7n1rIEcmRpNSaWNP7/3E4Zh+Du8nq10Lzn1lTMp1qafT6dFpZBSv+9MbtF2780rfqHkjATEJ598AsCUKVOaVMz80pVXXgnAwoULm+w98+ijj3L11VcTGRnJpEmTiIiI4OWXX2bUqFFkZ2e7x1166aUce6yzl+Opp57K9OnT3Y/k5GSPX09JSQmjR4/mo48+YsyYMZx66qls3bqV6667jueff77J+Ouuu4758+cTFxfHhAkTGDNmDHv37uUvf/kL559/PnX1GW8REREREREREZG22Ooc5JY6kzNpv6icAQiymHn8suMItphZvLWAd9ZkNxkjPlS6lxxX5UxwrPfmjUxy7zuTW5rpvXnFL6yBDqCnMwyDKntVoMPokDBrWJMKko5av349ACeeeGKbY48++miCg4MpLS0lMzOTI444wn3sf//7HwsWLOD8888HwGazcc011/Daa69xyy238MEHHwDOJM6sWbNYv349119/PTNmzPAo/l/68MMPmTp1KvPmzSMkJASADz74gIsvvpgHH3yQ66+/vtH4//3vf4wbN46wsEP/sSwvL+eKK65gwYIFvPbaa1x99dVejVFERERERERERA5PeaXVOAwIsZpJiAppdsyQ5CjuGjeYhz/bygMLNnPKwPhmq2zEyxx1UJZDbnwMACkRnv+huFtUCsmuypmD2k+ou1FyJsCq7FWMfH1koMPokNVXrCY8yLNf3AcOHAAgISGhzbFWq5XY2Fjy8/MpLCxslJy57LLL3IkZgKCgIJ588knef/99PvroI/bu3UtaWppHsbZHdHQ0//73v92JGYCLLrqIo446io0bN5KVlUX//v3dxyZNmtRkjqioKObMmcOCBQv48MMPlZwREREREREREZF22Vu/30yf2Nb/qPr6MQNYtDmfNbuL+efn2/i/y4/3V4g9V3kuOOzutmap0enemzsqmVRX5Uz1Ae/NK36h5Ix0a1OnTm3yXHx8POPGjeODDz5g2bJlXH755T6PY8SIEcTHxzd5fvDgwWzcuJHc3NxGyRmAHTt28Omnn7Jz504qKipwOBzufp87duzwecwiIiIiIiIiInJ4aG2/mYYsZhO3nT2Iq+d+x5bcMn+EJqXOFnK59W3NUuIHe2/uqORDe87YDnpvXvGLbpuc2bdvH3/84x/57LPPqKysZODAgbz44ovuNlmGYXD//ffz3HPPUVJSwqmnnsozzzzDoEGD3HMUFRVx66238vHHH2M2m5k8eTJPPvkkkZGRfnsdYdYwVl+x2m/reUOYtWnfyo5yJTL279/f5li73U5xcTEAvXv3bnQsPb35TLMrEZKT459yvr59+zb7fFRUFAA1NTXu5wzD4Pe//z1z5sxpcfO18vJy7wcpIiIiIiIiIiKHpUPJmbbv2/WpH5NXWu3TmKReyV7sQIGlvnIm4RjvzR2V7N5zJs+o9d684hfmQAfQGcXFxZx66qkEBQXx2WefsXnzZh577DFiYw9tpvSvf/2Lp556iv/+97+sXr2aiIgIxo8fT3X1oV86V155JZs2bWLRokUsWLCAb775ht/85jd+fS0mk4nwoPBu9fB0vxmAY489FoA1a9a0OXbjxo3U1tYSExNDRkaGx2t3lsPhaPGY2dz+S+mtt97i8ccfp2/fvrz77rvs27eP2tpaDMNwJ3FaStqIiIiIiIiIiIj8UnZ9W7P2JGeSo0MBOFhjp7za5tO4BCjdS4HVQp3JRJBh0Lv3UO/N3WDPmf1msNVUeG9u8blumZz55z//SVpaGi+++CInn3wyGRkZjBs3zr0XiWEYPPHEE9x7771MmjSJY445hpdffpmcnBz3BvFbtmzh888/5/nnn2fkyJGcdtpp/N///R9vvvmm36otejLXPjHvvvsuNlvr/xF4/fXXARg3blyTJMju3bubPcf1fGpqartjCg4OBuDgwaYlgHV1deTl5bV7rta8//77ADzzzDNMnjyZ1NRUgoKCANi1a5dX1hARERERERERkZ6jvW3NACJCrESFOhsq5ZepesbnSveSU9/SLNlhwmzxYjOr8N7EGRDicGCYTOQVbPDe3OJz3bKt2UcffcT48eOZMmUKX3/9NX369OGmm25i5syZAGRmZpKXl8c555zjPicmJoaRI0eycuVKpk6dysqVK+nVq5e7DRrAOeecg9lsZvXq1Vx88cVN1q2pqWnUnqqszNmX0WaztZpgsNlsGIaBw+FotfqiJxk/fjxDhw5l69atPPzww9x7773Njtu2bRv//ve/MZlM/O53v2vy/r311ltMnDix0XNFRUUsXLgQk8nE6NGj3ee4EiC1tbXNfg5JSUnuNX95fPHixe7PuOEx18+uz/eXXBUwDT/7oqIiwJk4au71/HLutrj2qrHZbFjqyyMbcsXdVhJMRDpP15mIf+haE/E9XWcivqfrTMT3euJ1ll3krJxJjgpq1+tOigqhvNpOdlEF6bGhvg6vR7MU7yHX6rxnl2IO9fr30hqZRIq9jqxgM/sKfiI5+cS2T/KCnnidtVd735NumZzZtWsXzzzzDHfeeSf33HMP33//PbfddhvBwcFMnz7dXeHgutnukpSU5D6Wl5dHYmJio+NWq5W4uLgWKyQefvhhZs+e3eT5hQsXEh7eclbaarWSnJzMwYMHqa1V7z+Xp59+mgkTJjBr1ixsNhu33347Vuuhr+Tq1au57rrrqKqq4qabbmL48OHuhJi9vlzv7bff5uKLL+bss892P3/rrbdSUVHBeeedR69evdznuNre/fTTT+7nGjrhhBMAePXVV5k5cyb9+vUDnFU4t912m3tcw3MrK53/4bPZbM3O6boQKysr3cdd++E8/fTTPPLII+42cStWrODRRx8FnAmX5uZrTm1tLVVVVXzzzTfu96U5ixYtatd8ItJ5us5E/EPXmojv6ToT8T1dZyK+11OuszoH5JZaABPb1q4g96e2z7HWmgEzC7/9jtJtaq/vS2fu20JOfaVStM3Cp59+6tX5T68LJbnuIFkE8d2GpeRnJ7V9khf1lOusI1z3jNvSLZMzDoeDE088kYceegiA448/no0bN/Lf//6X6dOn+2zdP//5z9x5553uf5eVlZGWlsa4ceOIjo5u8bzq6mr27t1LZGQkoaHKRLucccYZfPzxx0ydOpW//e1v/Pe//2X06NGEhYWxbds21q9fD8Att9zCnDlzGrU0cyVxZs6cyZQpUzj99NNJTk7mu+++IzMzk9TUVJ555plGn8uvfvUr7rrrLp555hl27NhBamoqJpOJ3//+9wwZMoRjjz2WadOm8corr3D66aczZswYqqqqWLVqFRMmTKC6uprdu3c3mtOVlAsKCmr2O+Cq1gkPD3cfv+uuu3jjjTd44YUXWLlyJUcffTQ5OTksW7aMO++8k8ceewyz2dzqd6qh6upqwsLCOP3005v9ftlsNhYtWsS5557rjkdEvEvXmYh/6FoT8T1dZyK+p+tMxPd62nW2t7gSY/UyQqxmfj1pQrv2i/62ZhNb1+0jqf8Qzj9jgB+i7KEMA+umG8m1hgBwRHx/93YP3mI5+Dopxd8BENQLr8/fkp52nXVEe//ovlsmZ1JSUhg+fHij54YNG8b8+fMBSE5OBiA/P5+UlBT3mPz8fI477jj3mIKCgkZz2O12ioqK3Of/UkhICCEhIU2eDwoKavULWFdXh8lkwmw2d2jj+J5g3Lhx7Nixg6eeeoqPP/6Yr7/+mpqaGpKSkpg2bRo33ngjo0ePbvH8u+++m5NOOoknn3yS1atXExERwbRp03jooYfo27dvo7F9+/blww8/5IEHHmD58uXuvWWmTZvGsGHDAHj++efp06cPr732GgsXLiQtLY0///nP/OlPf3LvadTwM3T97Pp8f8n1H8OGn/3QoUNZs2YNf/jDH1i9ejUff/wxQ4YM4X//+x8zZ87ksccea7JOa8xmMyaTqc3vYVvHRcRzus5E/EPXmojv6ToT8T1dZyK+11Ous7xyZ+eWPrFh7j2V25LaKwyAgoO1PeI9CpiqYqitIMfq/APvPjH9vP9+x6SSst/ZTSe/utDvn2dPuc46or3vR7dMzpx66qls27at0XPbt28nPT0dgIyMDJKTk1m8eLE7GVNWVsbq1au58cYbARg9ejQlJSWsXbuWESNGAPDVV1/hcDgYOXKk/16MEB8fz+zZs5ttGdceM2bMYMaMGe0aO27cOMaNG9fi8eDgYB5++GEefvjhJseysrKaPHfGGWe495Vpzrx585g3b16T54cOHcpHH33U7DmtzSciIiIiIiIiItJQdlEVAH1jW9524ZeSY5zJmbzSap/EJPVKswHItThvw6fGDvT+GpHJpNjrnOvUlnh/fvGZbpmcueOOOzjllFN46KGHuOyyy/juu+949tlnefbZZwHcm8f/7W9/Y9CgQWRkZPDXv/6V1NRULrroIsBZaXPeeecxc+ZM/vvf/2Kz2bjllluYOnUqqampAXx1IiIiIiIiIiIiIu2TXezc36JvbFi7z0mOcXYHyitTcsanSvZiALlWCwCpCUd6f42oZFLq96HOrdPn2Z10y+TMSSedxPvvv8+f//xnHnjgATIyMnjiiSe48sor3WP+8Ic/UFFRwW9+8xtKSko47bTT+PzzzxvtyfHaa69xyy23cPbZZ2M2m5k8eTJPPfVUIF6SiIiIiIiIiIiISIdlF7sqZzqQnIlW5YxflO7lgNlMjdmMyTBITjzO+2tEpRyqnDE5MBwOTNpao1volskZgAsuuIALLrigxeMmk4kHHniABx54oMUxcXFxvP76674IT0RERERERERERMTnDiVnOtLWzPkH7Acqaqmx1xFSX9khXla6l1yr8xZ8ggOCQiK8v0ZUEkl1zsqZarOJkpJMYuOO8P464nVKoUm3tHTpUgzDoH///oEORUREREREREREJGBcbc3SOlA5ExseRLDVeWu4oKzGJ3EJULKXnPrEV4op2DdrRKUQYkBvV/VMwU++WUe8TskZERERERERERERkW6o1u5w7xvTkcoZk8lESn31jPad8aEGlTOpQVG+WSO8N5gsh/adKdrmm3XE65ScEREREREREREREemG8kqrcRgQYjXTO7JjlRlJ0c7kTK72nfGd4ixy6pMzKWG9fbOG2QyRSSTXOStn8kqzfLOOeJ2SM35kGEagQ5DDkL5XIiIiIiIiIiI9k6ulWd/YMEwmU4fOdVfOlFZ5PS4Bqsug8gC59W3NUiP7+G6tqGR35UzOwRzfrSNepeSMH5jNzre5rj57KeJNru+V63smIiIiIiIiIiI9Q3axM7HSkZZmLsnRruSM9pzxieJMgEOVM72O8N1aUSmkutqaVRf5bh3xKt3N9YOgoCAsFgtVVcpCi/dVVVVhsVgICgoKdCgiIiIiIiIiIuJHDStnOirZveeM7ln6RJEzOePec6b3MN+tFZVEit35B9w59nLfrSNepeSMH5hMJsLDwyktLVX1jHhVXV0dpaWlhIeHd7h0VUREREREREREujfvVM5ozxmfKM6k3GSi3OK8BZ+adJzv1opKoa/NWTmzF7vv1hGvsgY6gJ4iMTGRrKwsdu/eTVxcHCEhIbqZLp1mGAY1NTUUFRXhcDhITEwMdEgiIiIiIiIiIuJnh5IzHlTOKDnjG0WZ7pZmMQ6D8Egf3r+LSqZvfVuzMrOJ0pIsYnr199164hVKzvhJcHAwffv2pbCwkNzc3ECHI4eJiIgIkpOTCQ4ODnQoIiIiIiIiIiLiZ3u90NasoLyGOoeBxaw/JPeq4sxDLc18fRs+MplwwyDBbme/1crenO+VnOkGlJzxo/DwcPr164fdbsduV3mZeMZqtWK16hIWEREREREREemJau0O8sqcVS+daWuWEBmC2QR2h8GBgzUk1rc5Ey8pyiLHagEgxRrh27WikgFIq0/O7Nm/kaOY4ts1xWO6sxsAuqkuIiIiIiIiIiIinsgtrcIwIMRqpndkx7uqWC1mEqNCySurJre0WskZb7LXQFk2ub2iAUgNifPteq7kjM3OulDYW7LLt+uJV5gDHYCIiIiIiIiIiIiIdEzD/WY6u7d1kmvfmTLtO+NVJXvAcByqnIlM8e164b3BZKGfzdmtaU9Fjm/XE69QckZERERERERERESkm8l27zfT8ZZmLin11TJ5pUrOeFVRJsChPWeiM3y7ntkMUcmk1W+lkV1b4tv1xCuUnBERERERERERERHpZhpWznRWsipnfKM4EwPICgoCIC3pGN+vGZl0qHLGUeP79cRjSs6IiIiIiIiIiIiIdDOu5ExaXOcrZ9zJGVXOeFdRJgcsZsotZsyGQf+003y/ZlQKfe02AAotJiorC32/pnhEyRkRERERERERERGRbuZQWzMPKmfU1sw3ijPZVV8108dhIiQ0xvdrRiUT4zCIrqsDIDvne9+vKR5RckZERERERERERESkmznU1swLlTNqa+ZdRYeSMxnWSP+sGZUMQL/6fWf25q/3z7rSaUrOiIiIiIiIiIiIiHQjtXaHO6HiSeVMSn1yJre0CsMwvBJbj+dwQHEWmfXJmQHhyf5Ztz45k1a/78ze4p3+WVc6TckZERERERERERERkW7EmUyB0CAz8RHBnZ4nqb6tWbXNQVmV3Vvh9WzluVBXw65gKwADeg30z7oxacCh5Myeg9n+WVc6TckZERERERERERERkW6kYUszk8nU6XlCgyzEhjsrPHLLqrwSW49XnAlwqK1Z0nH+WTdhCABprrZmNUX+WVc6TckZERERERERERERkW5kb1El4FlLMxdX9Uxeqfad8YqiTCpMJgqszsqZjH5j/LNuVAoER9HP1dasTsm2rk7JGREREREREREREZFu5FDljOfJGde+M0rOeEnRLvd+M/F1BjEx/fyzrskECYNJs9sAyDUb2Goq/LO2dIqSMyIiIiIiIiIiIiLdSHaxq3Im3OO5kl3JmTIlZ7yiOJNdwfUtzcyh/l07YSi96xyEORw4TCb25a7x7/rSIUrOiIiIiIiIiIiIiHQj3qycSY52zqHKGS8pyiQzyNnSbEBob/+u3XswJqCva9+ZgvX+XV86RMkZERERERERERERkW7kUHLGG5UzIYAqZ7ymOJNd9W3NBsRk+HfthCEApLn2nSna5t/1pUOUnBERERERERERERHpJmrsdeSXOxMpXqmciVHljNdUFkF1qTs5k5FwtH/X7z0YgH6u5EzZHv+uLx2i5IyIiIiIiIiIiIh0Sq3dweacMgzDCHQoPUZuSTWGAaFBZuIjgj2eL6V+z5lcJWc8V5yJDch2tTXrM9q/68f2B0sIaa62ZtWF/l1fOkTJGREREREREREREemw8mobU59dyflPfcsXm/ICHU6P0bClmclk8ni+pGhncqa0ykZVbZ3H8/VoRZnsDbJiN5kIdxgkJR3r3/XNFug9iDSbDYA99gr/ri8douSMiIiIiIiIiIiIdMjBGjszXvyedXtKANi4ryywAfUg2cWVAKR5oaUZQHSolfBgC6B9ZzzWYL+ZDKyYzAG4/d57sLtyJtvsoM5e6/8YpF2UnBEREREREREREZF2O1hjZ8bc71i7u9j9nFpi+U/DyhlvMJlMJNdXz2jfGQ8VZZHpSs4ExwYmhoShJNvrsBoGNpOJgoKfAhOHtEnJGREREREREREREWmXiho71774PWt2FxMVauWaU/sDkFdWFdjAehBX5UxfL1XOACTX7zujz9FDxZnsCnYmZwZEpQUmhoTBWIE+rn1n8n8ITBzSJiVnREREREREREREpE2VtXaumfc932UVERVi5dXrRnLu8CRAlTP+5O3KGaBB5UyN1+bskYp2sSvICsCA+OGBiaH3EAD62pzJmT2FmwMTh7RJyRkRERERERERERFpVVVtHdfO+57vMp2JmZevO5lj03qRGuOs3sgrrcYwjABH2TPs9WXlTKkqZzrNVoWjPPdQW7PUkwITR/wRYDLTrz45s7dsd2DikDZZfb1ATU0Ny5Yto7CwkIyMDE4++WRfLykiIiIiIiIiIiJeUlVbx3Uvfc+qXUVEhlh56bqTOb6fcz8N1039yto6yqrtxIQFBTLUw16NvY78Mmd1izeTMyn1n6MqoDxQnEWBxUKV2YzVMEjrOzowcVhDIG4AabZ8APZWFgQmDmmTR8mZ3bt38/TTTwNwzz330KtXr0bHV61axaWXXkpubq77ueOPP5758+eTnp7uydIiIiIiIiIiIiLiY9W2Oq5/+XtW/HyAiGALL117Mif0O7TReWiQhdjwIIorbeSVVis542M5Jc7kSViQhbiIYK/Nm1Tf1iy/TMmZTis6tN9MmsNMUJD32s51WO8h9NuTDcBee1ng4pBWedTW7L333uPRRx/lyy+/bJKYKSsr46KLLiI3NxfDMNyPdevWMXHiRGw2mydLi4iIiIiIiIiIiA9V2+qY+fIalu88lJgZkR7bZFxyfWuzHLXE8rnsBi3NTCaT1+ZNqf8MVTnjgeJMdrlamgVFBTaWhMGk2evbmlGH4XAENh5plkfJmUWLFmEymZg0aVKTY88++ywFBc6Sqdtuu40PP/yQm266CYAtW7bw0ksvebK0iIiIiIiIiIiI+NAf3t3AtzsKCQ+2MO/akzmxf1yz41Lc+5Xoxr6vZRc7E2DebGkGkBQTAsD+gzXY6nQjv1OKMskMcjaqGhCeEthYEobSx27HZBhUmE0UFe0MbDzSLI+SM7t27QLgxBNPbHLs7bffxmQycckll/DEE09w4YUX8u9//5spU6ZgGAbz58/3ZGkRERERERERERHxEXudg882OrcqeHbaiZzUQmIGDu07o6oL3ztUOePdllm9I0Kwmk0YBuwvr/Hq3D1Gg8qZAXFDAhtL78GEGJBUVwfA3rw1gY1HmuVRcmb//v0ApKQ0zgSWlpaybt06AGbMmNHo2NSpUwFYv369J0uLiIiIiIiIiIiIj+SUVGOrMwi2mjnliPhWx6ZEuypn1NbM13xVOWM2m9z7zuRp35nOabDnTEbScYGNpfdgAPrZ6lub7d8UyGikBR4lZ8rLywGoq8/AuaxYsQKHw4HFYuGMM85odCwtLQ2AoqIiT5YWERERERERERERH8k6UAFAelw4ZnPre5uocsZ/DiVnvL/ZfLLa03Weo47SkkyKLBYAMvqNCWw8IZEQ3ffQvjMluwIbjzTLo+RMr169AMjJyWn0/NKlSwE47rjjiIiIaPbc0NBQT5YWERERERERERERH3ElZ/r3bv7eXkOpvZxVHLqp73uH2pp5t3IGIDlaSbZOK8127zeTVGcQEZkc4ICAhCH0ra+c2VOZF+BgpDkeJWeOPPJIAN5//333c3V1de79Zn5ZNQOwb98+AJKSkjxZWkRERERERERERHwks9CZnMloR3JGFRf+UWOvI7/MuR+MT5Iz9Z9jvtqadVzRrkP7zVi8X9XUKQlD6GezAbC3tjTAwUhzrJ6cfPHFF/P111/zyiuvkJSUxJgxY3jllVfYvXs3JpOJyy67rMk5a9Y4Nx9ytTcTERERERERERGRriWrPjmTHt/2jWZXxUV5jZ3yahtRoUE+ja2nyilxJk3Cgy3ERQR7ff4UtafrvOJMMuuTMxlhiQEOpl7vwe62ZtnUBjgYaY5HlTM33HADw4YNwzAMHn30USZNmsS7774LwIUXXsiJJ57Y5Jz3338fk8nEqFGjPFlaREREREREREREfGT3AWf7rIz4titnIkKsRIc6/wZc1TO+07ClmcnU+j5AnZFUn2TL12fYcUWZ7Aqur5yJGRDgYOolDCGtvq1ZkdnEwfLcAAckv+RRciYkJITFixdzySWXYLVaMQyDoKAgpk2bxiuvvNJk/DfffMPmzZsBGD9+vCdLi4iIiIiIiIiIiA/Y6xzsKXImAtqz5wxASoyzzZaqLnxnb1EVAH1jfdM2y105U1blk/kPa8WZ7Krfc2ZA4rEBDqZewlAiDYO4ujoA9uZ8F+CA5Jc8amsGkJyczLvvvktNTQ1FRUXEx8cTHNx8WV1aWhpLliwB4LTTTvN0aREREREREREREfGyfSVV2B0GIVazu2VZW5JjQtmWX67KGR9qWDnjC4cqZ2owDMMn1TmHq5qCLeyLct5qz+h7SoCjqRceB+G9SbPZKbJY2FOwgWFDJgU6KmnAo+TMnj17AIiMjCQuLo6UlJRWx2dkZJCRkeHJkiIiIiIiIiIiIuJDmQ32mzGb23eDXvuV+F52satyxrfJmdo6B0UVtcRHhvhkncOOYZBVthsjOoWoOgfx8UMCHdEhCUNIq9zKekLYW/JzoKORX/CorVn//v3JyMjgzTff9FY8IiIiIiIiIiIiEkCu/Wb6t2O/GRdXW7M8tcTymUOVM75paxZsNdM70tkRSUm2DqgoJNO134wpCJPZo1vu3tVg35m9B/cFOBj5JY++KWFhzl+6J510kleCERERERERERERkcByVc5ktHO/GVDljK8ZhuH+XPrF+SY5A872dAD5Zfoc2604k8z6/WYyQnoHOJhf6D2ENJsNgL01xQEORn7Jo+RMnz59AKir31RIREREREREREREuresA662Zu1Pzrhu6ueW6Ka+LxQerKW40obJBEckRPpsneRo5x/jK8nWAUWZ7Aqqr5yJTg9wML+QMJg0u7NyZo9Dn2lX41FyZty4cQAsW7bMK8GIiIiIiIiIiIhIYLnbmvVuf4XGocoZtTXzhR0F5YCzaiYs2OKzdZJjnPvMqHKmA4obJGd6HxngYH6h9xD61bc1KzBDTXVpgAOShjxKztx+++2EhYXx6KOPsm+fetaJiIiIiIiIiIh0Z/Y6B3uLnMmZjrQ1c1XOlFXbqaix+yS2nmxH/kEABiX6rmoGDu0dpMqZ9qsr3MFuV1uz1JMDHM0vRKcSa40gwuHAMJnYl7sm0BFJAx4lZwYNGsTrr79OZWUlo0aN4vXXX6e2ttZbsYmIiIiIiIiIiIgfZRdXYXcYhAaZSYoKbfd5UaFBRIY4b1DnqerC67bnOytnBiVF+XSdpGjtOdNROXu+pcZsJthh0KerJWdMJkwJg93VM3vyfwxsPNKI1ZOTzzrrLAASEhLIzMxk2rRpXHfddQwaNIjY2FgslpZL7EwmE4sXL/ZkeREREREREREREfGiTNd+M3ERmM2mDp2bHBPKzoKD5JVW+3RflJ7IVTkzOMnXlTOu9nRKzrRXpq0USCTdbsNiDQ50OE31HkLf3N1sCQlmb9H2QEcjDXiUnFm6dCkm06Ff0oZhUFNTw8aNG1s8x2QyYRhGo/NEREREREREREQk8HYXOpMzHdlvxiWlPjmjG/veZRgG2+v3nBmU6J/KmTx9hu1TU06ma7+Z4LgAB9OChMH02/MJAHvK9wY4GGnIo+TM6aefriSLiIiIiIiIiIjIYSLrgHO/mf4d2G/GxVV1kVda5dWYerr9B2soqbRhNsFAH+8549o76GCNnfJqG1GhQT5dr9srzmJXsPM9yojuH9hYWpIwlLT6tmZ7qw8EOBhpyOPKGRERERERERERETk8ZNZXzmTEdzw5k6zN5H3C1dKsX1w4oUEtbyPhDZEhVqJCrJTX2Mkvq1Zypi1FmexyVc7EDQlwMC3oPZg0e31ypq4ywMFIQ+ZAByAiIiIiIiIiIiJdQ5Zrz5lOJGe0X4lvbM+vb2mW5NuWZi7J7gqoGr+s150ZRbvYFeSsfxiQcmKAo2lBbH/61VfO5JgN7DZdn12FkjMiIiIiIiIiIiKCrc5BdrGzJVlGJ9qaJSs54xPb6ytnBif5tqWZy6HPUe3p2lKUvZIyiwWTYZCedmqgw2me2UJi/GCCHQZ2k4m8/B8DHZHU83pyJjs7mzVr1vDNN99QVaULWEREREREREREpDvILq6izmEQGmQmKTqkw+drzxnf2FngrJwZ7K/KmWjn55hfpiRbW3bt+RaAVHsdoWGxAY6mZeaEYfStb222J29dgKMRF68kZ8rLy/nrX/9KWloa6enpjBw5kjPPPJPMzMxG4958800uu+wyZs6c6Y1lRURERERERERExEuy6veb6R8fgclk6vD5KdHOPWeKK21U2+q8GltPZRiGu3JmYKJ/KmfUnq79Mi3O62RAnRHgSNqQMMS970z2gW0BDkZcrJ5OsGPHDs4//3x27dqFYRz6Ejb3C3zUqFFcddVVGIbB9OnTOe200zxdXkRERERERERERLzAtd9M/07sNwMQHWYlLMhCla2OvNJq+neiNZo0tr+8htIqG2YTHJHgn+RMkrsCSsmZVtlryazfbyYjMi3AwbSh92DSbDYgjD1luwMdjdTzqHKmurqaiRMn8vPPPxMeHs4f/vAHFixY0OL4/v37c+aZZwLw0UcfebK0iIiIiIiIiIiIeJG7cqaTSRWTyaSqCy9zVc2kx0cQGmTxy5ru9nRqa9a60r3sCgoCYEDi0QEOpg0JQ0mzOStn9lbtD3Aw4uJR5cwzzzzDzp07iYiI4Ntvv+W4445r85wJEyawePFiVq5c6cnSIiIiIiIiIiIi4kWZByoByOgd3uk5UnqFsquwgrwy7TvjDdvznfvNDPJTSzOApGhVzrRLUSaZwfXJmaQTAhxMG+KPoJ9rz5na4gAHIy4eVc689957mEwmbr/99nYlZgCOPfZYwNkOTURERERERERERLoGV+VMeifbmgEk1+87k1OiG/vesKPAmZwZnBTltzVTYpyf4YGKWmrs2juoJZW5P5BrrW9rlnZqgKNpgzWEtPp9oLItJgyHI8ABCXiYnNmyZQsA48aNa/c58fHxAJSUlHiytIiIiIiIiIiIiHhJrd1BdrGrcqbzyZkU7VfiVa62ZoOS/Fc5ExseRLDVedu4oKzGb+t2N5k/LwQgrq6OXrEZAY6mbanpYzEbBtVmM/v3bw50OIKHyZmDB52/HCIj2//LoabGeUEH1ffjExERERERERERkcDKLq7EYUBYkIXEqJBOz5OsPWe8xjAMd1szf1bOmEwmkqO170xbMgs3ApBRawtwJO0TlHI0KfWVUHvz1gY4GgEPkzOuKpisrKx2n7Np0yYAkpOTPVlaREREREREREREvCTrgKulWTgmk6nT8xzaTF57zngqv6yG8mo7FrOJAQmdr2bqDCXZ2rD1U3bV7zeTERQd4GDaqfcQ0uzORNLeQlXOdAUeJWdOOMG50dE333zT7nNefvllTCYTo0eP9mRpERERERERERER8ZLMQs9bmsGhm/pqa+Y5134z6fHhhFgtfl3bVTmTr8+xqeIsqt6dztpQZ4XZgJQTAxxQOyUMpp/NDsCe0swAByPgYXLm0ksvxTAMnn32Wfbs2dPm+CeeeMKdyLn88ss9WVpERERERERERES8ZHd95Ux/D5Mzrs3kCw9qM3lPufebSfTffjMuKaqcaZ69hu//dzKTk+NZFxqKyTA46YiJgY6qfXoPJq0+OZNdvjfAwQh4mJyZNm0axxxzDNXV1Zxxxhl89tlnGIbhPm4ymTAMg++//54rr7ySu+66C5PJxJgxY5gwYYLHwYuIiIiIiIiIiIjnMgudyZmMeM+SM7HhQYRoM3mv2BGA/WZckqLVnu6XDpbn8uAzQ7g2JYm9QUEk2e38e9hMhg75VaBDa5+QKNLs9ZUzNQcCHIwAWD052Ww289FHH3HaaaeRlZXFBRdcQHj4ob6UZ5xxBuXl5dTUOH8RG4bBEUccwdtvv+155CIiIiIiIiIiIuIVDfec8YTJZCIlJpSsA5XkllaTFufZfD3Z9vrkzKAAJGf693Z+bltzy/2+dlf07XdP8cBPz5AX7fwsplTDnVd8RWRUSoAj65i04F4A7LV6lBYQL/GocgagX79+/Pjjj1x++eWYzWYqKiowDAPDMNi/fz/V1dXuaprLLruM7777jsTERI8DFxERERERERGRw0txRS1fbMqjzmG0PVi8ptbuYF+xs0LC0z1noOFm8qq66CzDMNhR39ZscJL/25qd0C8WgF2FFRQe7LkVUKUlWdzz2lnctOU58qxW+tpsvFAXz303/NTtEjMAaRlnA1BmsVBc9HOAoxGvpMji4uJ47bXXeOihh/jkk09Ys2YNBQUF1NXVER8fz/HHH8+FF17I4MGDvbGciIiIiIiIiIgcZipq7Ez530p2FhzkP1eewPlHd78bn93V3uJKHAaEB1tIiArxeD7XvjPar6Tz8sqqKa+xYzGbvJIw66he4cEMSoxkR8FB1u4uZvyRyX6PIdAWLXuIv29/nQMWEybD4Kqycm4JO4LwGYsCHVqnhfU5kZTCr8i1WsnKXkls3BGBDqlH87hypqH09HRuuukm5s6dy4IFC/jss8949dVXueuuu7yamJk1axYmk6nRY+jQoe7j1dXV3HzzzcTHxxMZGcnkyZPJz89vNMeePXuYOHEi4eHhJCYmcvfdd2Ov77knIiIiIiIiIiL+YxgGf5y/gZ0FzkoB1/+Kf2QVulqaRbi3K/CEq3ImT8mZTtteXzXTPz6cEKslIDGc2D8OgLW7iwOyfqCUlmRx16tjuPPnNzhgMTGg1sYrufn8oTaE8KlvgDkwn4dXJAyhv80GQGbBj4GNRbybnPGnI488ktzcXPdj2bJl7mN33HEHH3/8Me+88w5ff/01OTk5XHLJJe7jdXV1TJw4kdraWlasWMFLL73EvHnzuO+++wLxUkREREREREREerQXl2exYEOu+995Zbqp70+Z9cmZjN7e2R8mRW3NPLajfr+ZwQHYb8blxHRna7Pvs4oCFoO/ff/jXCa/dwEL60qwGga/qbDzzr5cjq21w6VzISop0CF6pvcQMmqdBQpZRdsCHIx0251/rFYryclNy+lKS0t54YUXeP311znrrLMAePHFFxk2bBirVq1i1KhRLFy4kM2bN/Pll1+SlJTEcccdx4MPPsgf//hHZs2aRXBwsL9fjoiIiIiIiIhIj/R9VhEPfboFgGP7xrA+u5R8VVz41e4DlQD0j/dO+6zkaFXOeGp7fXJmUCCTM/2dyZmN+0qpttURGtSNK0baYLdV88yC6TxfugmHxUR6Hfxz8DSOXPKYc8BZf4X+pwU2SG8IjyPDVTlTmhXYWMSz5Mw333zT4XNMJhOhoaHExMTQv3//TidCduzYQWpqKqGhoYwePZqHH36Yfv36sXbtWmw2G+ecc4577NChQ+nXrx8rV65k1KhRrFy5kqOPPpqkpEOZzvHjx3PjjTeyadMmjj/++GbXrKmpoabm0AZYZWVlANhsNmz1X2qRrsb13dR3VMR3dJ2J+IeuNRHf03Um4nu6zhorKK/hplfXYncYXHB0Mhcem8INr/5AXlmV3iM/2rXf2UIrLTbUK+97QkQQ4NxzJhCf4+FwnbmSM0fEhwXsdaREBZEQGcz+g7WszSrk5Po2Z4ebnJzv+ctXt7DebAOTiUnWRO4+7z9Ev/lrqKvBMXAcdSNvhm78fWrI3dbM5Nk97cPhOvOV9r4nHiVnzjjjDI/6UFqtVo477jhmzJjB9ddfT1BQULvOGzlyJPPmzWPIkCHk5uYye/ZsxowZw8aNG8nLyyM4OJhevXo1OicpKYm8vDwA8vLyGiVmXMddx1ry8MMPM3v27CbPL1y4kPBw75R9ivjKokXdd7Myke5C15mIf+haE/E9XWcivqfrDOoc8PRmC/sPmkgOMzg9LJudG7IBK3v2l/Hpp58GOsQeY0u2BTCRu309n+at93i+chuAlf3l1Xy84FMsAdpYobteZ4YBW3Ocn0nOtnV8ujdwsaQGm9mPmTcWraawjxG4QLzIWldJTOUeghyV7Cr7gqciyjloNhPpcHBPUQXHWfvAi5MxVe+lMrg3S8MuwvbZ54EO22uGBKUBtWRbrXz88XtYLKEezdddrzNfqqysbNc4j9uaGUbnL0qbzcb333/PmjVreOaZZ1iwYAH9+vVr87wJEya4fz7mmGMYOXIk6enpvP3224SFhXU6nrb8+c9/5s4773T/u6ysjLS0NMaNG0d0dLTP1hXxhM1mY9GiRZx77rntToCKSMfoOhPxD11rIr6n60zE93SdHfLwZ9v4uXw3ESEWXv7NKDJ6R3DgYA2PbPiag3YT544/j6BA3dXvQWrsDu5Y9SUAUyeeTUJUiMdzOhwGs3/4ElsdnHDamfTp5bv7dc3p7tdZbmk11au+wWo2cfVF5xFsDdx1kN9rN+s/28bB0CTOP/+EgMXhNYaB9T8nUVW6m4fiY/kwKhIwc2x1Df/cX0gfex2w0jnUEkzwFa9zbp/D4HU3YPpqLeE586k0mzny6FgG9D+zU/N09+vMl1wdt9riUXJmyZIl2Gw2/vrXv7J69WpSU1OZMmUKJ554IgkJCQDs37+fNWvW8M4775CTk8PIkSOZPXs2VVVVbNy4kbfeeouNGzeyceNGzj//fH788Ues1o6F1atXLwYPHszOnTs599xzqa2tpaSkpFH1TH5+vnuPmuTkZL777rtGc+Tn57uPtSQkJISQkKb/gQoKCtIXULo8fU9FfE/XmYh/6FoT8T1dZyK+19Ovs0825DJ3xW4AHptyHINTegGQGGMlyGLCVmdQXO2gTy/PEwXSut3FB3EYEBFsISU2wqMuOQ0lx4Syt6iKwgo7/RMC813vrtfZrgPFAPTvHUFEWGCvgZEDegPbWLenBIvFitnsne9HwJTlsKVyH3f3SWZ3UBBmw2BmSRm/TTsPa3o8hERBSDSERGFKPxVr74GBjtj7EgbRf7eNzSEhZO//gSGDxnk0XXe9znypve+HR2nXsWPH8tRTT/Hdd99x6623snPnTubMmcOVV17JuHHjGDduHFdeeSVz5szh559/5uabb2b16tU88cQTTJo0ib/85S9s2LCBv/zlLwBs2bKFF198scNxHDx4kJ9//pmUlBRGjBhBUFAQixcvdh/ftm0be/bsYfTo0QCMHj2an376iYKCAveYRYsWER0dzfDhwz15S0REREREREREpBU7C8q5+11n66wbxg7gvKMO/aGs2WwiMcrZYie/TJvJ+0NWYQXgTAR4KzEDkBLtrJbJLdXn2FE78p17AA1OigxwJDA8NZqwIAtl1XZ21u9N1J3VFWzhlqQEdgcFkVRn8MJxv+eW3+3BOvlZOO9hOPMeOOUWGDEdDsfEDEDcADJsdgAyD2wJcDA9m0fJmRdffJEFCxZw/vnn8+STTxIa2nJ/upCQEP7v//6P888/ny+++IJnn33WfezBBx9k7NixGIbBe++91+a6v//97/n666/JyspixYoVXHzxxVgsFi6//HJiYmK47rrruPPOO1myZAlr167lmmuuYfTo0YwaNQqAcePGMXz4cKZNm8b69ev54osvuPfee7n55pubrYwRERERERERERHPHayxc8Mra6msrWP0gHjuHjekyZikaOe9mXzd1PeLrAP1yZn4CK/OmxzjvE+Yp8+xw7bnlwMwKDEqwJFAkMXMcWm9AFiTVRzYYLwgd8dnFFitBBkG8y9ZwInHzQh0SP4Xl0H/+g3rM8t2BziYns2j5MzcuXMxmUz85je/afc5N9xwA4Zh8NJLLzV6fsaMGQCsX9/2pmPZ2dlcfvnlDBkyhMsuu4z4+HhWrVrlbqU2Z84cLrjgAiZPnszpp59OcnJyo6SPxWJhwYIFWCwWRo8ezVVXXcXVV1/NAw880O7XISIiIiIiIiIi7WcYBn94dz0/768gOTqUpy4/Hmsze8q4b+qrcsYvMt2VM+FenTel/nNU5UzHbS9wVc4EPjkDcGL/WADWZBUFOBLPZWYtASDdZiOmV//ABhMokclk1DqTM1mV+QEOpmfzaM+ZLVucZU99+/Zt9zmusVu3bm30/LBhwwAoKmr7In/zzTdbPR4aGsrTTz/N008/3eKY9PR0Pv300zbXEhERERERERERz72wLJNPf8ojyGLi6StPaHHjeVdbMyVn/GP3gUrAh5UzZVVenfdwZxgGO+srZ7pCWzOAE/vHAbBmd/evnMmsyofwWHdbrx7JbD7U1sxiwnA4MJk9quGQTvLoXa+udv5HMjs7u93nuMbW1NQ0et61SU54uHez9CIiIiIiIiIiElj2OgdzFm0H4N6JwxmRHtviWNdN/YKymhbHiPdkNthzxptUOdM5+0qqqKitI8hi8vpn0lnH9+uFyQR7iiop6OZJ08wgZ61CRlhigCMJrH5pp2IyDMotZoqKdgY6nB7Lo+TMEUccAcDzzz/f7nOee+65Rue65OTkALhbk4mIiIiIiIiIyOFhV2EFFbV1RARbmDYqvdWxydHaq8Rfqm115JQ6K1u8XTmTEhMGQG6JPseO2FHf0iyjdwRBzbT9C4To0CCG1LdY69bVM3V2MusLBDKSRwQ4mMAKTTqKVHsdAJnZKwIcTc/l0RV+6aWXYhgGCxYs4Pe//z22+o2EmmOz2bjrrrtYsGABJpOJKVOmNDq+fPlyAAYOHOhJSCIiIiIiIiIi0sVsyikFYHhqNGazqdWxSfXJmfxu/hf63UF2cSWGAZEhVnpHBnt1blflTEF5NfY6h1fnPpztqG9pNqiL7DfjcpKrtVlWN07OlOwmM7g+OdP/zAAHE2BxGWTU38vPLGh7D3jxDY/2nPn973/PK6+8ws6dO5kzZw7vvPMOU6ZMYcSIEe4KmP3797N27Vreeecdd0uzI444grvuuss9T11dHa+//jomk4lx48Z5EpKIiIiIiIiIiHQxG/eVAXBkakybY5OinXvR5JVVYxgGJlPryRzpvMzC+v1meod7/X2OjwzBajZhdxjsP1jjrqSR1m3Pd1bODErsGvvNuJzYP5ZXVu1mze629wvvqkp3L6PIYgEgI21MgKMJsNgM+ttsLCOMrNJdgY6mx/IoORMWFsZXX33FxIkT+emnn9i7dy9z5sxpdqxhGAAcddRRfPLJJ4SFHfqFnJ2dzTXXXAM4q3FEREREREREROTwsXGfs3LmqD5tJ2dce85U1tZxsMZOVGiQT2PrybLq95tJ93JLMwCL2URSdCj7SqrILa1WcqadXJUzg7tY5cyJ9ZUzm3LKqKy1Ex7s0W3lgMjavgCARLud8MievecMcQPIsNkByKzMD3AwPZfHjQv79u3L2rVrmTNnDkOHDsUwjGYfgwcP5rHHHmPt2rWkpaU1miM9PZ3777+f+++/nz59+ngakoiIiIiIiIiIdBEOh8HmHGflzFF9otscHx5sJSrUeeNXrc18K/OAMzmT4YPkDBxKtGn/oPZxOAz3njODk7pW5UyfXmGkxIRS5zD4cW9JoMPplMyc7wDcSYkeLSbN3dYsy1Ya4GB6Lq+kOK1WK7fffju33347OTk5bNy4keJiZ//B2NhYjjzySCVdRERERERERER6oD1FlZTX2Am2mjkioX03nJOjQymvPkheaQ0DE7tWBcHhZHd9cqZ/b98mZ3KVnGmXfSVVVNbWEWQx+aSayVMj0mNZsCGXNVnFnHJE70CH02GZFmdnp4y6AAfSFVisZODcZ2qf1UJNdSkhoW1XNop3eb3+LDU1ldTUVG9PKyIiIiIiIiIi3dDGHOdfZQ9LjiLI0r4mLknRoewoOKjKGR/Lcu05Ex/uk/lTol2VM1U+mf9ws6PA2dJsQO/Idl8r/nRS/zhncmZ3caBD6ZTMIGeLxIy4IQGOpGuITz2JKPt2yi1m9mSvZNDA8wIdUo/T9a5yERERERERERE5bGyqb2l2ZDv2m3FJct3UV3LGZ6ptdeTUJ018VTmT0su5z4wqZ9pne76zpdmgLtbSzGVEeiwAP+wups5hBDiaDrJVHUrOpJ8e4GC6BlP8APq7WpvlrQtwND2TkjMiIiIiIiIiIuIzG/c5K2eOSm1/ciY5JgTQnjO+tKeoEsOAqBAr8RHBPlkjRW3NOmRHvmu/ma7Zym9ochSRIVbKa+xsyysPdDgdYsvfRHaQs4lUxoBxAY6mi4gb4N53JrNoS4CD6Zm80tbMbrfzySef8O2337Jr1y7Ky8upq2u9eZ/JZGLx4sXeWF5ERERERERERLogwzDclTNH9Ylu93nJ0dpI3teyCg/tN2MymXyyhmvPGX2O7eNqaza4i1bOWC1mju/Xi293FLJ2dxHDU9t/TQfa3q0fYDeZCHM4SEo8JtDhdA2xGWTY7ABkle/r8OmGw+HtiHocj5Mzy5YtY9q0aezZs8f9nGG0XNZmMpkwDMNnv/RFRERERERERKRryC2tpqiiFqvZ1KFqgMT65Ex+eY2vQuvxsg44kzPpPtpvBg5VzuSXVVPnMLCYdT+wJQ6H4a6cGdRFK2fA2drs2x2FfJ9VzLTR/QMdTrtlZi2BIMiw2TCZ1UwKgLhDbc0ya4s6fPp974wnv6qEvpvLGHHsNG9H1yN4lJzZunUr5513HlVVVRiGQXBwMIMGDSIuLg6zvuQiIiIiIiIiIj2aq6XZwMRIQoMs7T7PVTmTr4oLn8ksrAQgw0f7zQAkRIZgNoHdYXDgYI076SZN7SupospWR7DFTHqc7xJmnjqpfxwAa3cXBziSjsks3wNxvdyVIgLEph9qa4YNw+Fod+LKbqvmG1sh5cEmTCblATrLo+TMQw89RGVlJRaLhdmzZ3PbbbcRGdk1y+5ERERERERERMS/NrpbmrV/vxk41A5r/8EaVVz4iLutWbzvkjNWi5nEqFDyyqrJLa1WcqYV2/OdLc0GJERgtXTdm93HpfXCYjaxr6SKnJIqUnuFBTqkdsl07TcTHBvgSLqQoDDSgnphNgwqzGYKC7eQkHhku07dsPltys0mYuocDB90kW/jPIx5dKV/9dVXmEwmbr/9du655x4lZkRERERERERExG1TfeXMUR3cm6J3fcVFncOg8KBam/nC7gOH9pzxJVeiLVdVUK3a3g1amgFEhFgZnuK8ntd0o+qZrKAgADKSRwQ4kq4lOGEofe3OaqLMfSvbfd6ynz8GYITNisUa7JPYegKPkjOFhYUAXHzxxV4JRkREREREREREDh+bOlk5YzGbSIgKAZz7lYh3VdvqyKlPlvT34Z4zcGjfmbzSKp+u093tqK+cGZzY9f/4fUS6s/pkbVbH9ykJBKPiAJn1yZn+AycEOJouJi7D3eotq+CnpscdDijOgm2fw7In4P3fwv/GsrxwPQBnle+H0r3+i/cw41Fbs4SEBHJycggL6x7layIiIiIiIiIi4h/7y2vIK6vGZIJhKR2rnAHnvjP5ZTXklVZzTF8fBNiDZda3NIsKtRIX4du/ek+Jcd43VOVMy7bllfPVtgIABid37coZgBP7xzJvRVa3qZw5sOtLyi1mTIZBesZZgQ6na4nLoP9uG18TRmbBetj+BRRsgf1b6x/bwVbR6JQDZjOb052/lE+pqgJT+/cTk8Y8Ss6cdtppvP3222zcuJETTjjBWzGJiIiIiIiIiEg3tynH2dJsQO8IIkI6fgsqKToUKFXljA9srG83NywlGpPJt/v5pKitWat25JdzxXOrKKm0cVSfaMYOTgh0SG06MT0OgC25ZRyssRPZievbnzK3LwCgj91OSGjHqvgOOw6Hs9LFlXz55lEyQpy/AzIPZsPrlzU9xxIM8YMgcSgkDGPFvqVg28PQmlrCLXEQnerf13AY8ejKufPOO5k/fz5PPvkkV1xxBVZr174QRURERERERETEP1wtzY5M7dzNUNdeJXlKznjdT/XJmWM62G6uM9yfo5IzTewsKOfy51ZzoKKWI1OjefW6kYQGdf0qhOSYUPrGhpFdXMUPe4oZM6hrJ5Qyc76D6GB3+64eweGAsmwo2Ar7t9T/71bYv61JJUx/s7OFZFZQECQeWZ+EqX8kDoPYDLAcuu+/7LVPADitqoqiiKNI9t+rOux4lE056aSTeOKJJ7jtttu45JJLmDt3Lr179/ZWbCIiIiIiIiIinVZtq8PuMLr8X3UfrlzVGUf16XhLM3BVzkB+WY3XYhKnDdnOz+bovr5PzrgrZ8q050xDOwsOMvXZ1RQerGFYijMx0yu8+2ysflL/OLKL9/F9VjdIzhjVQDAZNlugQ/E+w3BWwriTL1vr25I1TcK4uSphEoZATB8yVj0NQI7VQtUVCwgLj2txuTp7LStqC8Fs4tSqag4kDFZyxgMe/V8nDzzwAAAnn3wyCxYsID09nXPPPZehQ4cSHt72ZmL33XefJ8uLiIiIiIiIiABQUF7NltxytuSWuR8/73femPrw5lM7vCG9eG5jfVuzozpZOXMoOaOKC2+y1TnYkuusajqmby+fr+eqnMkvrcHhMDCbfdtGrTvYtf8gVzy3isKDNQxNjuK160cS6+O9f7xtRHos7/+wj7W7iwIdSpsyg4IAyIgbEuBIPOBKwuzf9os9YbZB7cHmzzEHQe9BhypgEoZAwjCIG9CoEib2x9eJqauj1GJhT/YKhgy+oMUwtmz/kBKziQiHg2Ora/g2YrC3X2mP4lFyZtasWe6+lCaTiaqqKj7++GM+/vjjdp2v5IyIiIiIiIiIdMba3cV8vjGXLbnlbM0ro/BgbYtjv96+X8kZPyuttLG3yFkp0em2ZtFqh+ULO/IPUmN3EBVqJT2u7T+u9lRiVCgmE9TWOSiqrKV3ZIjP1+zKMgsruPy5VRSUOxMzr88cRVw3S8yAs3IG4Ic9JdjrHFgt5gBH1ALDcLbrAjL6jQ1wMO1gGFCa3bgCZv+WdiZh6pMv9XvDEJcBlqA2lzTFDaC/bQ/rLRYy89a1mpxZtuNDAEZVVWMNi6U8NKVTL1OcPK7rNQyj1X+LiIiIiIiIiHhTta2Oq19YTUVtnfs5swn6945gWEo0w1OiGZYSxYqdB3h+WSY78ssDGG3PtCnXWTWTFhdGTHjbNwebkxzjvImvPWe866d9JQAc3SfGL1UswVYzvSND2F9eQ15pdY9OzmQVVnD5s6vIL6thSJKzYqY7JmYABiVGEh1qpazazpbccr+0yOuMqv1byLE69/HJGHZxgKNpwJ2E2dZgT5h2JGHiBx5KviQMcVbExA1oVxKmRbEZZOT+zPrQEDKLtrU6dHnxZjDBqVVVGH3HgKmLJuW6CY+SMw6Hw1txiIiIiIiIiIi0y7o9xVTU1hEXEczd44cwLCWaIUlRhAU33kjbVmfw/LJMtue3cKNLfGbTPmfbrM62NANIrK+cKa+2U1lrJzxYewd5gz/3m3FJjQllf3kNOSVVPbaKbfcBZ8VMXlk1gxIjeW3mSOK7caLKbDZxQnosS7ftZ83uoi6bnNmzeT6GyURMXR2x8UP9H4BhQNm+BsmXrfU/b4PaFv5wwGw9tCdM4rBDbck8TcK0JC6DjD3O/XiyKva1OKy0dA8bqAVMnFZZjZE2Eoq9H05Pov+qiYiIiIiIiEi3surnAwCMGdSby0/u1+K4wUlRAPy8/yB1DgOL9rrwG9d+M0emRnd6jqgQK+HBFipr68gvqyGjt25jecNP+5yfzTF9evltzT6xYazPLmX3gUq/rdmV7DlQyeXPriK3tJqBiZG8PnPUYVFBdFL/uPrkTDHXnJoR6HCalbl7CQAZNjsmsw+rPFxJGHfyZUs7kzADG+wJM9T5iD/CN0mYlsQNoL/NDkBmbUmLw1aun4fDZOKI2lpS6uqwp42C4v1+CvLwpP+qiYiIiIiIiEi3snKXMzkzekB8q+P6xYUTYjVTY3ewt6iS/r0j/BGeABvrEwBHelAlYTKZSI4OZVdhBXml1WTo8/NYjb2OLbnOqqZj/FjpMCw5mk9/ymNTfdKuJ7HVObh67mpySqs5IiGC12eOJCGq+ydmAEakxwKwJqsowJG0LLN4B8T2IsNm886EhgFlOQ2SL67HNqgpa/6chkmYhKGH2pL5OwnTktgM9/uThR3D4Wg2kbU8+xsATq2qBmsoRsqxsOFLv4Z6uFFyRkRERERERES6jaraOn7cWwLAqDaSMxaziSMSItmcW8b2/HIlZ/ykosbOrsIKwLO2ZgBJ9cmZfO074xXb8w5iqzPoFR5E39gwv63ramW2MaeFm9eHsQ3ZJWQdqCQmLIg3Zo4iMSo00CF5zdH1n2t+WQ0llbX0Cu96++dkBjmTH/0tkR070Z2EqU++FGxpXxIm7ohDyZfE+mRM3BFg7XrvjVvcAPra7FgNgyqzifyCDSQnH9doiOFwsLw6DywmTq2shj4ngqULv6ZuwmvJmcWLFzNv3jxWrlxJXl4e1dXVbNiwgeHDh7vHfPPNN2zcuJHo6Giuuuoqby0tIiIiIiIiIj3Emt1F2OoMUmJCSY8Pb3P84CRncmZHwUHGHemHAIWteWUYBiRFh3hcIZAU7TxfyRnv2LCvBHDeVDeZ/Nfm78g+zvZ2P+8/2OP2D1q1y1lVcsoR8e59lA4XESFWkqNDySurJrOwguP7db2b9Vn1yZmM5BOaH2AYUJ7bIPnSYE+YmhYqvRolYYY22BOmiydhWhLRm6DgSPra7GQFB5G5b1WT5Mz2nz9jv8VEqMPBiJpq6DcqMLEeZjz+TVhZWcn06dN57733ADAMA6DZX/AWi4VbbrkFk8nEyJEjGTRokKfLi4iIiIiIiEgPsqpBS7P23FweVL/vzPb8Fnr+i9dt3Of8q3JPq2YAkmKcN7PzlJzxip+y6/eb8fPm7YlRoSRGhVBQXsOW3DJGpMf5df1AWlm/R1ZblX7dVUbviAbJmdhAh9OIw15DVpDz9nfGoAmHKmF+uSdMS0kYk6W+HdmQQ3vCdOckTEtMJojLIMOWS1ZwEFn7NzL6F0OWb50PwEnVNYQYQL9fjpDO8Dg5c9lll/HZZ59hGAYnn3wyp59+Oo8++mizY0899VSOOuooNm3axPz58/nTn/7k6fIiIiIiIiIi0oO4b3Qe0b4bnYPdyZmDPotJGvPGfjMuyfWVBqqc8Y4N9cmZo/v08vvaR/WJ4autBWzc13OSM7V2B2t2OytnRrfzd1Z3k5EQwcpdB8isb2UYcIYB5Xmwfwv5q5+mymzGahj0+fAOsFU2f47J4tz/xZV8SRhSvyfMwMMrCdOa2Az65+0FILM0s8nhZQc2gAlOq6wCTJB2kp8DPDx5lJyZP38+n376KSaTiWeffZbrr78eoMXkDMAll1zCxo0b+frrr5WcEREREREREZF2q6ixu28uj27nX6EPSnTuM/Dz/oPUOQwsZv+1cuqpXPuKHJka7fFch5IzNR7P1dNV2+rcFWT+rpwBOCo1mq+2FrApp4UqhcPQhuwSqm0O4iKC3b+LDjcD6vfy2uXv5EyDJAz7tzVuS1bt/I5lhoVCciL9bHaCbJUNkjBDGuwJM8z5nNWzFozdXtwAMvYuBiCzen+jQxUH8/iBasDEaVXV8P/s3Xd0HPX1NvBntqqueu/dkpvcLXfjAtj0HoopgQRiIAnpvySkEBLeFAhJgBACDiX0GoPBNsa9F7mqWr2uepe2zvvH7K4tbFllu/R8ztEBa6dcrXZW0vfOvTd6CuATBBgMbgh0fLErOfPqq68CAO68805bYmY4s2bNAgAUFhbac2oiIiIiIiIimmAOV7bBaBYRH+KLhNDh580AQEKoH9QKGXRGM6pae5EaMT4XSD3FgMGEUksCYIoDKmesMzoaO1k5Y6/Chi4YzSLC/FWICXL97BNrJZW17d1EcK6lWahLZ/y4UoolOVPR7PzkzK6Sj/DJ0efwrT4zsprP2pIwFxDkQGgqKgwNUowGA/DQPkslzARPwgwlNEV6ngBUmgZXGB08+RqMgoAEgwGJRiNbmjmQXcmZI0eOQBAE3HrrrSPeJyYmBgDQ3Nw8zJZEREREREREROfsP2/ezEjJZQLSIwNwpr4LpU09TM44WYm2G0aziBA/JWIdkACIthyjqXsAZrMIGSufxuyUpd3c1PggtyQKrJVUJdpu6IwmqBVyl8fgagcqRv+e5W1syZmWXoii6NTX1kf5L+JLvRZxPV3IGui0JWEumAljScJU/D1ZitFgAKImOy2ucSE0FSkGIwCgUS6gr68Ffn7hAIC91V8BABb2W5LkifPdEuJ4ZFdyprVVeoOJjY0d8T4ymQwAYDab7Tk1EREREREREU0wByx3oY92dkNmVKCUnNF24/LJ0c4IjSysVRFT4hyTAIgMVEMQAINJRFufHuEBvOt9rKwtAac5oKJpLOKCfRHsp0RHnwEljT2Y6obWaq6kM5pwtKodADB/HCdnEkL9IJcJ6DeYoO3S2RKqzrBW9MGXADYF+OF7N38CWWT2JSthKpRKAEBKUKrTYho3QlIQZDYj1GRCm1yOqpq9yM66FqLZjL19dYDcOm8GrJxxIJk9OwcFSW+i9fX1I96nokIaKBQeHm7PqYmIiIiIiIhoAukaMNju/B9tciYjSqqWKdH2ODwuGsw6T2RyrGMW3pVyGcL8pcVXbRdbm9njtK1yJtgt5xcEAVMsr4vTE2DuzImaTgwYzAgPUCF9nM6bAaRrNNHSZrK8xbnvsYvNPgg0maFVKHC06diwLcoqlFJdQkriEqfGNS5o4gC5GsmW1mYVjcek/1btQJ0cUIoi5gzogOAkQDPyQg26NLuSM5mZmQCAEydOjHifjz/+GAAwY8YMe05NRERERERERBPI4Yo2mEUgOcwPMUG+o9o3MzIQAGzD0Ml5TtdbK2c0DjtmlIbJGXv160221/80N1asTLa8LqyJovHsgKUN47zUsHE7b8Yq9bzWZs6knn0vVvZJ81A2Fb51yW172ivRrJCSM8k5Nzk1rnFBJgNCkmytzSraSgAAewvfAQDMGhiAnyiyasbB7ErOrF27FqIo4u9//zsGBob/Abl79268/fbbEAQBV199tT2nJiIiIiIiIqIJ5Nxg7dG3B8qMkpIz5c29MJrYZt1ZDCYzChuk5IyjKmcAIFojtUlq7NQ57JgTTUFDJ8yi1CYuSuO8tlPDsVbOnLEk8cYza3JmPLc0s7LNnWl2bnIGaZdhTY90ji39dTDohj5fZcF7AIAIoxGBUVOdG9d4EZqKFL1UOVPZWwcA2Nt8HACwqI/zZpzBruTM+vXrERoaCq1Wi5tuugltbW0X3c5oNOKll17CVVddBbPZjISEBNxzzz32nJqIiIiIiIiIJhDbYO1RtjQDgPgQX/goZdCbzKhq63N0aGRR1twDvdGMALUCSZY2R44QZZlh0cjKmTGzzZtx85yXKZZ5N4UNXeM6UXr+vJm81FA3R+N8KRGuqZyBXIk5U9chwmhEl1yOPcdeGHLTisrtAIBkgxEY55VLDhOScq6tmaETA/3tOGKWvqcL+63JGVbOOJJdyRmNRoN33nkHCoUCn3/+ORISErBmzRrb4z/+8Y+xevVqREZG4sEHH0R3dzfUajXeffddKC0DmYiIiIiIiIiILqWzz2C70z5vDHehy2SCbeZDKVubOc3pOul7lBOrgUzmuMVQa+VME5MzY3bKkpyZGhfs1jiSQv0QoFZAZzSjzNlVFm50vLoDOqMZ4QFqpEWM33kzVikuamsGAPLc23FFr5Rk/6z0wyG3q2g5I8VmSTbQCISm2NqaVcGEQydfg04mIMpoRJrBAPiGAhFZbg5yfLErOQMAK1aswFdffYXExET09/fjiy++sPVR/Pzzz7Ft2zZ0dHRAFEUkJCRg+/btmDt3rt2BExEREREREdHEcLCiFaIIpEb4I3KMLZmsc2dKtc4dWD2RWeeITHFgSzPg3MwZVs6M3ck6z6ickckE5MSM/7kzB8ql7kLzU0PH/bwZAEgNlxJQ1W19MDi7Iip2BtZaWpvtMHWit6fxoptVKKV5MylggcCIhaYi1miEUhQxIBPwQcm7AKSWZgIgtTSbAK9nV7I7OQMACxcuRGlpKV577TXcdNNNSEpKgq+vL1QqFWJiYrB27Vq8+OKLKC0txbx58xxxSiIiIiIiIiKaIPZbZjeMpWrGKsMyd6akickZZymwVDdNsQx9d5Qo28wZJmfGokdnRFmz9Lq3thVzp8mW18fp+vGcnJk482YAKYHqq5TDaBZR4+zWkYKAnIU/QbLeAJ1Mhm2H/nbRzWzJmejZzo1nPAlJgQJAoqXaaLtJukYX9fdLj3PejMMpHHYghQJ33nkn7rzzTkcdkoiIiIiIiIgI+8vGPm/GKjOKbc2cyWwWccay2O7oBEC0ZeaMlpUzY3KmrhOiCMQG+SAiUO3ucGyVVWcsbfDGmwGDCUerpXkzEyU5IwgCUsL9UdDQhYqWXqQ6uZWbMP1WrMn/G55XBWNTxWe4Br8f9LjRMIAqy0iNlIwrnRrLuBKcCAgypBiMKFOpIAoC5KKIeTqT9DjnzTicQypniIiIiIiIiIicoa1Xj6JGKaFiz0JnpqVypry5d1wPIneXytZe9OpNUCtkSLXMn3AU68yZ9j4DdEaTQ489EZyytA+b6uaWZlbW5F1BQxfMZtHN0Tje8ZoO6I1mRASqkRbh2GvBk6VEuG7uDIITsVaUEkD75Sa0tBQNeriuchuMggAfsxnRWVc7P57xQqECguKRfN6cnukGMwJNekDhA8Tkui+2ccolyRmdTgetVguzmb/8EBEREREREdHIHbS0B8qMCkB4wNjv+o8L9oWvUg69yYzKVie33ZmATltammXHaKCQO3a5KchXCZVCOmZTl86hx54ITtZa580EuzcQi7QIf6gVMvTojKhydgssNzi/pdlEmDdjZU3KlrsiOQMgcen/YeqADmZBwObDg1ubVZR8BgBINhgh8w1xSTzjRmgqUgxG2z8XmeTS/8TNlpI35FB2/bTs6enBpk2bsGnTJvT0XNiztaWlBTfeeCM0Gg1iY2MREhKCH/zgB9Dp+IOUiIiIiIiIiIbniHkzgDSIPIOtzZzmTJ21pZlj580AUsska/VMI1ubjZqtcsYD5s0AgEIuQ3aMZe5M3fibO2Ntwzg/NdTNkbhWiiU5U9HsmuQMcq7Fml4pubepZtughyrqD0sxnVcBQiMUkoIU/bnnbRH8pP/hvBmnsCs588EHH+Cqq67Cgw8+CD8/v0GPmc1mXHnllfj4449hMBggiiK6u7vx17/+FbfffrtdQRMRERERERHRxHBuodP+2Q0ZkVJrsxLthTeYkn2sw92t80QczZac6WRyZjQ6+w22NlOekpwBgMmxluRM/fhKzgwYTMiv6QBgf0LZ29iSMy6qnIGPBleEToVMFHFSrUJNzV7bQxW6FikmJmdGLzQV6QYDYoxG5JjlyBqwVLdx3oxT2JWc2bx5MwDg+uuvh0w2+FDvvPMOjh49CgCYOXMmvv/972PmzJkQRREff/wxvvjiC3tOTURERERERETjXEuPDqVNUiJlniOSM9bKmSZWzjiSKIo4Y2lrNsVJCYCoICk5o2XlzKhYK5oSQn0R4u85LYmsr5MzdV1ujsSx8quleTORgWpbsmKisH69jV0D6NUZh9naMcIXfA/zBqT3hM+OPmf7fKVSIcXkH+eSOMaV0BT4iiI+04fi9avfh6yjGhBkQMJcd0c2LtmVnDl9+jQEQcCCBQsueOy1114DAMyaNQsHDhzAX/7yF+zfvx9z50rfyFdffdWeUxMRERERERHROGed3TApOhChDlhYzrS1NWPljCPVdfSjo88Apfxc6zhHiwqU5g0xOTM61pZm0+KC3RvI11grrE7Xd0IURTdH4zj7J+i8GQAI9lPZ3qcrW11UPZN2Gdb2SJUdnzUfg2iZd16hVAIAUpKWuSaO8SQ0FQCg7KyFSntK+lzUZMDH8S0ryc7kTFNTEwAgJSVl0OcNBgN27doFQRCwfv16KBRStlKpVOLBBx+EKIo4dOiQPacmIiIiIiIionHO2tIsL80x7YGsbc3KW3pgMJkdckw6l+xKDQ+AWiF3yjmig6wzZzjHeDROWufNxHtOSzMAyIwOgEImoKPPgPpx1KrOmlB21HuWt3F5azO5EivSroLabEalSonCkv+hva0MHXLpfSgx+zrXxDGehCRL/x3oAIo/l/6fLc2cxq7kTFtbGwBApRp898rhw4fR398PALjiiisGPZaZmQkAaGxstOfURERERERERDTOWe9Cd9TshrhgX/ip5DCYRFS56s7uCaDcshCbGuG8Nk5Rlpkz2nG0kO8Kp2qtlTOelZxRK+TIjJKSpafrxsfcmQGDCcerOwA4ZkaWN7IlZ5pH//76zuFqfHisFu29+lHtFzD3QSztk9ahNx3/FypKNgIAYg1G+MbMGHUcE57KHwiIlv6/UHoukTjfffGMc3YlZ/z8/ACcq6Cx2rVrFwAgPT0dUVFRgx7z9fW155RERERERERENAFouwZQ3twLQQDmpThmoVMmE5ARKbXdKmFrM4eptCRnkp04Y8NaOaPtZnJmpDr69Khuk1o+Tfaw5AwATImT2iSdGSfJmWNV7dCbzIjSqJEc5ufucNxirJUzoiji2S9L8di7J2yt+EYsdgbW9Eqv8897K3C2cpsUi8EAKNSjOxZJQi1dsgzS88rKGeexKzmTlpYGANixY8egz3/00UcQBAFLliy5YJ/m5mYAQGRkpD2nJiIiIiIiIqJxzNoeaHKsBkF+SocdN8Nyt36Jttthx5zorAuxzhyAHhVoaWvWOTCuZpQ4k3WROyXcH0G+jruGHGWybe5Ml5sjcYwD51X6TbR5M1aplveA8lEmZ6pa+1DfOQClXMCc5NDRnVQQsHj2wwg0mdGkUOD9rhIAluQMjY1l7gwAIDgJ0MS6L5Zxzq7kzKpVqyCKIp5//nl8/vnn6Onpwd///nccPnwYAHD11VdfsM/JkycBALGx/KYSERERERER0cXZ5s04uD1QpmVgfSkrZxzGFcmZSI10B7zOaEZnPxddR+KkpaXZFA+smgHOVc6Ml7ZmB8ql8Q8TtaUZAKRYWhuWN/eMKom6t6wFADAjMQS+qtHPrVLNXIfVfVKVR6FaGr+RYmQSd8xCzpsvz6oZp7IrOfPd734XGo0G3d3duOqqqxAUFITvfe97AIDs7OyLJmc+++wzCIKAGTPY84+IiIiIiIiILm6/kwZrs3LGsQYMJtR3SvMenJmc8VHKEWKpoNJ26Zx2nvHEU+fNWGXHaCAIQFO3Dk1e3q6uX2/C8ZoOABM7OZMcJr0HdA0Y0d438iTqPksyfmFa+NhOHJyItT2Dq3VSomeO7Vh0rq0ZwHkzTmZXciYmJgYbN25EdHQ0RFG0faSmpuL999+/oISvrKwMu3fvBgCsXLnSnlMTERERERER0ThV39GPqtY+yARg9mhb3AzDOnOmoqUXBpPZoceeiKrb+iCKQKBagTB/lVPPFaWxtDbr8u6FfFextjWbGu+ZyRk/lQJpEdL1eMbLW5sdq5bmzcQE+SBpgs6bAaQkalywNG+8omVk1Ylms4gDluTMgvSxJ7Zmrfx/iDQabf9OyVg75mNNeOcnZ5IWuC+OCUBh7wEWL16MiooK7N27F42NjYiJicGiRYugUFx46IaGBvzyl78EAKxevdreUxMRERERERHROGSd3TA1LggaH8fOyogL9oW/So5evQmVLb22Shoam/JmS0uzCH+nz9mI0vigqLEb2k4mZ4bT0qNDXUc/BEGa2+SppsRqcLapB2fqOrE8y3vnU1vfs+ZP4HkzVinh/qjr6Ed5cy9mJQ2fXC/WdqO1Vw8/lRzT44PHfF7ZlBuwZu+v8Z9gDQJNZoSlsTBgzCImAYGxgF8YEJbh7mjGNbuTMwCgUqmwfPnyYbdbtGgRFi1a5IhTEhEREREREdE4ZZ03M9/BLc0AQBAEpEcF4kRNB0q0PUzO2KmyVUrOWNsZOVM0K2dGzFo1kxruj0AHJzgdaUpcED4+Xo/Tdd5dOXMuOePYSj9vlBLujz1nW2yzqIZjbWk2JzkUKoUdTZ58gnC9OhbvmruwqL8fQnDi2I810an8gYcPA4IMkNnVeIuGwWeXiIiIiIiIiDyKbd6Mk2Y3ZFpam3HujP0qrJUzTpw3YxUVJCVntEzODMs2b8aOSgRXmBwrtVw7Xd/p5kjG7vx5M3mpY5yZMo5Y3wtGnJw52wIAWGhHSzOr1JVPYFt1HX6viAdkcruPN6GpAwDVxG3R5yoOqZy5lBMnTuD9999HS0sLUlJScMcddyAuLs7ZpyUiIiIiIiIiL1TT1ofa9n4oZALmOHjejFWmpVqmtInJGXtVtLouOWOtnGFyZngnLcmZqXGeOW/GKsfScq22vR8dfXoE+zl3bpEzHK1qh8EkIjbIBwmhvu4Ox+1SIkaenDGazDhY0QYAWJDmgMRW+koEfONdICzN/mMRuYBdyZnDhw9j/fr1UCgU2LRpE4KDgwc9/uKLL2L9+vUQRdH2uSeffBLvv/8+Vq1aZc+piYiIiIiIiGgcOmO5gz47RgN/tXPuKc2IslbOjGxgNQ3NugDrksoZjRoA25qNxKm6DgDAtHjPTs4E+SqRGOqH6rY+FNR3YUG691WecN7MYKnnVc6YzSJksqGfk5N1nejRGRHkq0R2jINmI2Vyzjl5D7vamm3cuBFHjhyBRqO5IDFTUVGBRx99FGazGaIo2j66u7tx6623orm52Z5TExEREREREdE4dLZJSphkWFqPOYO1cqaypRd6o9lp5xnvenRGNHfrAADJLknOWGbOdOqcfi5vVtPWB22XDjLhXGWKJ5sSJ8Xora3NrG0YnTEjyxvFBftCKRegM5rRMEwi1TpfLC81DPJLJHGIxiu7kjM7duyAIAi44oorLnjsueeeg8FggK+vLz788EN0dnbi3Xffha+vLzo7O/HPf/7TnlMTERERERER0ThUZplhkubE5ExMkA8C1AoYzaJtoD2NXqWlaibMX4UgX+cPnY+2zJxp7dXBYGJSbSiv7qsEIFVy+KmcPtHAbra5M3Vdbo5k9Dr69DhhmTczP4XJGQBQyGVIDJVmlVhnUg1lr2XezAIHzJsh8kZ2JWfq6uoAANOmTbvgsU8++QSCIODb3/42rrvuOgQGBuKmm27Cgw8+CFEU8cUXX9hzaiIiIiIiIiIah8qapcqZtAjnJWcEQUB6pLW1GefOjJW1pZkrqmYAINRPBaVcgCjCVrFDg3X2G/DWoWoAwANLUt0czchMsczFcXXlzH8PVuHv20oHjWMYrY/y62A0i8iO0SAxjMPTrVLCpffXipahW0cOGEw4UtUOwEHzZoi8kF3JGWtrsrCwwdnNuro6lJWVAQBuueWWQY+tXi31/SsqKrLn1EREREREREQ0zoiiiDJLW7P0SOcu+Gdy7ozdXDlvBgBkMgGRgZbWZpw7c1FvHapGr96ErKhALMuMcHc4IzLZ0nqtoqUXPTqjS875793l+PlHp/GXrSW21lqjJYoi3jlcAwD4xtwER4bn9VIjpPeEsktUzhyraofeaEZkoBppEa55DyHyNHYlZ/R6PQCgt3fwhbZ7924AgJ+fH+bMmTPosaioKABAdzfvTCEiIiIiIiKicxq7BtCrN0EhE5AU5uzkjDR3ppSVM2NW6eLkDABEadQAAG0nkzNfpzeasWFvBQDg/sUpXjOcPjxAjWiND0QRKGxwfmuzj/Pr8LvPCm3/fsuSYBmtk7WdKGrshlohw7XT4xwV3rhgfU+wJnAvZp8lKbYwPdxrXqtEjmZXciYiQsrAW6tkrLZu3QoAmD9/PuRy+aDHBgakH57BwcH2nJqIiIiIiIjIYRo7B1DX0e/uMCa8siZpIS8xzA9KuV1LFsPKsCRn2NZs7MrdkJyxzp3RsnLmAhtP1EPbpUNkoBrX5Ma6O5xRmRInVc+cqXNua7OdJc344XsnAAArsyMBAJtPN6K9Vz/qY71tSepcOSUaQX7On7nkTUaSnNlbJs2byUvjvBmauOz6TWf27NkQRREvv/wyzGZpEFtrays+/PBDCIKAFStWXLCPNZFjraAhIiIiIiIicqcBgwlr/7Yby/60HS/vqbBr/gDZ52yTlChx5rwZK2tbs8rWPuiMJqefbzyqbHVH5Yy1rRlnzpxPFEW8tLscAHDvwhSoFfJh9vAsk2Otc2ecVzlzvKYDD71xFEaziGumx+Jfd83GlDgN9CYzPsqvG9Wx+vRGbDxRDwC4dU6iM8L1aqmW94Ta9ou/v3YPGHCyVkrELWByhiYwu5Iz69atAyC1MVu0aBF++MMfYsGCBejs7IRCocAdd9xxwT779u0DAKSlpdlzaiIiIiIiIiKHOFzZhtZePQwmEU98WoD7Xz2CtjHcRU32s84nSI90fnImWuODQLUCJrN4ybu76eLae/Xo6DMAAJKd3ILufNbkDCtnBttV2oKixm74q+S4fZ73JQumxFmSM06qnDnb1IN7NxxCn96ExRnh+PPN0yGTCbbEytuHq0eVmP/sZAN6dEYkh/lhfmqoU2L2ZhGBagSoFTCLQE1b3wWPH6pog8ksIinMD/Ehfm6IkMgz2JWcuf7663HTTTdBFEUcOHAAzzzzDEpLSwEAP/7xj5GQMHgYlslkslXVLFq0yJ5TExERERERETnEzuJmAFIlhUohw7aiJlz57K4xD4mmsStr7gHgmsoZQRCQYameKdX2OP18402FpWomJsgHvirXVWlEWytnOHNmkJd2SVUzt85JRJCv97XYsrY1K23qwYDBsZVsjZ0DuPuVQ2jvM2B6fBD+eecsqBTSkui1ubHwUcpQou1Bfk3HiI/5jqWl2c2zEzgv5SIEQbBV1JU3X5j8ts6bWZAW7tK4iDyN3Q1c3377bfztb3/D4sWLkZ6ejiVLluDll1/GE088cdFttVotRFHE2rVr7T01ERERERERkd12lUrJmUdXZODj7yxEaoQ/tF063P7vA3h6awmMJrObI5w4zjZZkzOuqcTItMydKeXcmVGrsCy4urJqBjivcqabyRmr03Wd2HO2BXKZgPsWJbs7nDGJ1vggzF8Fk1lEcaPjrsfOfgPufuUQ6jr6kRruj1fumQN/tcL2uMZHibVTpfk8bx+qHtExzzb14EhVO+QyATfNindYrOPNpebO7D0rzZthSzOa6OxOzshkMjz88MPYuXMniouLsWPHDtx7770X3faOO+6A2WyG2WxGdna2vacmIiIiIiIiskt9Rz9KtD2QCcCi9HDkxGrw6SOLcMvseIgi8Ldtpbj9pYNo6Ox3d6jjXteAAU3d0hyRNBe0NQPOtU8rYeXMqNnmzbgokWYVHWRJzrByxubfllkza6fGeG2LKEEQMNna2qzeMa3N9Cbg22/ko1jbjSiNGq/eNxdhAeoLtrttrtT5Z+OJBnQPGIY97rtHpKqZ5VmRtmQhXWio5Exrjw5FlgRcHpMzNMHZnZwhIiIiIiIi8la7LVUz0xOCEeynAgD4qRT4403T8extuQhQK3Cosg1XPrsbWwu07gx13LO2vokMVEPj45q2TNbKmZImVs6MVrllwTXF5ZUz0uJ6r940ooV0byKKIo5WtY3q66rv6MfGkw0AgG8tSXVWaC4xOVZqbeaIuTNGkxmvlspwtLoDGh8FXr1vLhJCL564mp0UgrQIf/QbTNh4ouGSx9UbzfjgaC0A4NY5CZfcdqJLtSRuy7+WnNlfLrU0mxQdiPCLJMuIJhImZ4iIiIiIiGjC2lkiJWeWZkZc8Ni1uXH49JFFmBoXhI4+Ax547Qh+s/EMzOaRD42mkTvX0sw1VTPAueRMVWsfdEbHzrkY7yqtyZlw1yZn/FQKBPpIbam0XTqXntvZdpQ048YX9uOaf+xFXcfIqvVe2VMBk1nEgrQwTLFUnnir3IRgAMCxqg67jiOKIh7fWIjT7TKoFTL8++45mBStGXJ7QRBw25xEAMA7hy/d2mxboRatvXpEBqqxPOvCnxt0zlCVM9Z5M6yaIWJyhoiIiIiIiCYoo8mM3aVS3/slF0nOAEByuD8+eGgBHlicAgDYsLcSXxaygsYZypql5Ey6i1qaAVIVRqCPAiazeNGh1XRxoijaFlyTXZycAaT5JACg7Rpfrc2OVrYDkBazb/nn/ovO6jhfZ78Bb1nmpDzg5VUzgFTBAgDF2m509o29Kiq/pgPvHa2DABHP3jINc1NCh93nhplxUMoFnKjtREF915DbvWNpaXbTrHgo5FxWvRTre0Nzt25QNdh+S3JmYVq4W+Ii8iQOeRfR6/XYsGEDrr32WiQnJyMgIAByufySHwqFYvgDj8BTTz0FQRDwve99z/a5gYEBrF+/HmFhYQgICMCNN94IrXbwL8/V1dVYu3Yt/Pz8EBkZiR/96EcwGo0OiYmIiIiIiIg834naDnQPGBHkq8T0+OAht1MpZPj52hzcZmlhc6Sq3UURTixltsoZ1y32C4KALEv1jCOHkI93zd069OlNkAlA4hCtopwpNtgXwIXtkrxdiVZ6DSpkAuo6+nHzP/ejqHHoRMHbh6rRqzchIzIAy4ZIMHuTsAC1rRXW0eq2MR9njyXpPj1UxIrsyBGfe3VONIChq2fqO/pt1Za3zGZLs+FofJS2tmWVLX0ApOewoqUXMgGYmzp80oxovLM7OVNSUoLc3Fzcf//92LhxI6qrq9HX1wdRFIf9sNfhw4fx4osvYtq0aYM+//3vfx8bN27Ee++9h507d6K+vh433HCD7XGTyYS1a9dCr9dj3759ePXVV/Gf//wHjz/+uN0xERERERERkXfYWSwtsi3KCIdcJgy7/UzLXd3HazqcGdaEddZSOZPmwsoZAMiOkdodFTQMvQhOg1mTIvEhflApXF89MCMxGABwpHLsC/ieyJqc+cst05Edo0FLjw63vnjgou85eqMZG/ZWApCqZgRh+PcwbzAnSVqwP1w59iT4ActMk4yg0a09WmfIfJRfhwHDhW0O3ztSC1EE5qeGuqVizBulhlvnzkjv79aWZtPig102W4zIk9n1E7S3txdXXnklioqKIAgCrrvuOjzwwAMApLtPfvnLX2L9+vWYN2+e7XMLFizAr371K7sTIT09Pbjjjjvw0ksvISQkxPb5zs5OvPzyy3j66adx2WWXYdasWdiwYQP27duHAwcOAAC2bNmCgoICvPHGG8jNzcWVV16JJ554As899xz0er1dcREREREREZF32Gm5u/pi82YuxjoP4VRtJ4wms7PCmpAMJjOqW6U7q13Z1gw4N4T8TL39Q8gnCnfNm7Gytqk6WN7mkJt/PcGAwYSqNukaWJAWjrcfmI/chGB09htwx0sHbAkHq40n6tHYNYDIQDWuzY11R8hOMTtZWuMba+JNZzThqKW6cbTJmUXp4YgL9kXXgBGfn24Y9JjZLOJdS0sz63waGt7X587sOyv93F3AeTNEAAC7eov985//REVFBeRyOTZv3ozLLrsMZ86cwUsvvQQA+M1vfmPbNj8/H3fddRcOHDiA2267DQ8//LBdga9fvx5r167FypUr8bvf/c72+aNHj8JgMGDlypW2z02aNAmJiYnYv38/5s+fj/3792Pq1KmIioqybXP55ZfjoYcewpkzZzBjxoyLnlOn00GnOzdsrqtLuqvGYDDAYBh7L0wiZ7K+NvkaJXIeXmdErsFrjcj5JtJ11tarx8naDgDAgpTgEX3NicFq+Kvk6NWbUFTfgazoQCdHOXGUNffCaBbhp5IjzFfu0tdgVqS0eHimrgt6vd7pFQjj4To72yRVeCSG+rrl65gSHQClXEBj1wAqmruQEOL61mqOVlTfBVEEQvyUCFILEARgw90z8dB/83Ggoh13v3IIz9+eiyUZ4RBFEf/aVQYAWDc/ETLRDINhfCSMZ8RLydLjNR3o6RuAWikf1f6HK9qgM5oRHqBCpI9x1K/Pm2bG4tmvyvDWwWpcNeXcuuGes62o6+iHxkeBFVlhXn39ulJiqDQfqqypG3q9HnvLpOTMvOSR/dwlzzYefp45y0ifE7uSMxs3boQgCLjllltw2WWXXXLbGTNmYPv27Zg+fToee+wx5OXlYdasWWM679tvv41jx47h8OHDFzzW2NgIlUqF4ODgQZ+PiopCY2OjbZvzEzPWx62PDeUPf/jDoIST1ZYtW+Dn5/2/CND4tnXrVneHQDTu8Tojcg1ea0TONxGus2MtAkRRjhg/EUf3fDXi/WJ8ZDirl+GNz/cgL2p83LHvCU60CgDkCFMa8fnnn7v03EYzIBPk6Og34L8ff45QtWvO683X2cEiGQAZ+horsGlTuVtiiPeTo6JbwMuf7MTcSO+/Fg81W64BhX7QNXBTJNDdIcOZduBbrx/Fugwz1HKgWCuHSiYirKMQmzYVui9wBxNFIFApR7cBeOmDzUjVjG7/z2uk12aiegCCMPrrLFQHCJDjUGU7/vPBJkRK443wnxLpuNOD9Phq6+bRBTWBtbVJr+vjZQ34z4e10HYpoBBENBUcxKZid0dHjuLNP8+cpa+vb0Tb2ZWcKSgoAABcf/31F33cbDZDJjvXOS0iIgKPPfYYfvzjH+Mf//gHNmzYMOpz1tTU4Lvf/S62bt0KHx+fsQU+Rj/72c/w2GOP2f7d1dWFhIQErF69GhrNKH9aELmIwWDA1q1bsWrVKiiV7OdJ5Ay8zohcg9cakfNNpOtsx4enAdRj7cwUrLk8c8T7nZaX4OyeSoihSVizJsd5AU4w1TvLgZKzmJkeizVrprr8/C9V7kORtgfRk2Zj5QgHiI/VeLjO/n52L4BerF0yB4szwt0SQ4GiFC/uroAuKBFr1kx2SwyOdHpzCXC2EvOzE7FmTfagx9aYzPjR+6fx2elGvFoqR2ywL4B+3D4vCTetmeSegJ3o867j2FzQBGVsNtYsSRnVvm+8fBhAO66Znw20nRnTdba95xh2lLSgKSAd91yeibZePX54aCcAET+8cQFyYrgGOFIZTT14uXgf2o1KqOKzgeNFmJ0ciuuunuPu0MgBxsPPM2exdtwajl3JmY6ODgBAUlKS7XNq9blbTHp7exEYOLjMe+HChQCAnTt3jumcR48eRVNTE2bOnGn7nMlkwq5du/CPf/wDmzdvhl6vR0dHx6DqGa1Wi+joaABAdHQ0Dh06NOi4Wq3W9thQ1Gr1oK/PSqlU8gVIHo+vUyLn43VG5Bq81oicb7xfZ6IoYs9ZaX7D8klRo/paZyWH4qU9lThV1zWunyNXq2jrBwBkRAW65XmdHBeMIm0PirS9uHKaa87vrdeZySyiut3y/YoOctvXMD89HC/ursCRqnavfB6/7myzNJMjK+bC51SpBP52+0z4f3gS7x6pRW17P+QyAd9cnDYuvvavm5sajs0FTciv6RzV1zdgMOFEjTQ7amFGOAoOju06+8a8JOwoacFHx+vx4yuz8enpJhhMIqbGBWF6ImeljEZalAaCAPTojPjstLT2ujA9Yly+bicyb/155kwjfT5kw28yNGsrr/P7sZ6fEKmurh5y30u1D7uUFStW4NSpUzh+/LjtY/bs2bjjjjts/69UKrFt2zbbPsXFxaiurkZeXh4AIC8vD6dOnUJTU5Ntm61bt0Kj0SAnh3c+ERERERERjWeFDd1o7tbBVym3DZ8eqekJwQCAYm03+vUmJ0Q3MZVZFqbTIgLccv7JsdKd8GfqR3an60RW39EPvdEMlVxmqeBwj1lJIZAJQGVrH7RdA26Lw1FKtD0AgKyoi8+ykssEPHXDNNy7MBkAcP2MOCSEjs8W+3Ms78tHqtphNo+8Zd3RqnboTWZEa3yQZMdzc9mkSEQEqtHSo8e2Qi3eOSytb94yJ2HMx5yo1Ao54kOk94nDle0AgAXp7qm2I/JEdiVnUlKk0sL6+nrb58LDwxEaGgoA2Lt37wX7HD16FACgUqnGdM7AwEBMmTJl0Ie/vz/CwsIwZcoUBAUF4Zvf/CYee+wxbN++HUePHsW9996LvLw8zJ8/HwCwevVq5OTk4K677sKJEyewefNm/OIXv8D69esvWhlDRERERERE48fOkmYAQF5aGNSK0Q2bjtb4IDJQDZNZxJn6TmeEN+GIooiyJmlhOj3SvcmZAn5Ph1XZKiXSEsP8IJcJw2ztPBofJXIs37dDFW1ui8MRugcMqOuQqpEyo4a+BmQyAb+6ejK+fGwJnrx+iqvCc7mcGA38VHJ09htwtrlnxPvtL5MqIvPSwgbdSD5aSrkMN82KBwD8flMRSrQ98FHKcM302DEfcyJLCT/3mvZXyTEtPsiN0RB5FruSM7NnzwYAHDlyZNDnV6xYAVEU8ac//Qltbed+QJaXl+Opp56CIAjIzc2159SX9Mwzz+Cqq67CjTfeiCVLliA6Ohoffvih7XG5XI5PP/0UcrkceXl5uPPOO7Fu3Tr89re/dVpMRERERERE5Bl2WZIzSzMjRr2vIAi26pnjNR0OjGriaurWoUdnhFwmIDHMPZUA1kX++s4BtPfq3RKDt6hokZIzyWH+bo4EmJsstZjy9uRMqSU5GRmoRrDf8Dczp0cGjjqx7E0UchlmJAYDAA5Xjvx7u7/ckpxJtb/12K2zpSqZ6jZpqPeaqTEI8mXbprFIDT/3XjE3JRRKuV3L0UTjil1Xw6pVqyCKIv73v/8N+vyjjz4KQErGZGZm4uabb8aaNWuQm5trq7L51re+Zc+pB9mxYwf++te/2v7t4+OD5557Dm1tbejt7cWHH354wSyZpKQkbNq0CX19fWhubsaf//xnKBR2jeAhIiIiIiIiD9erM+JIlbTYN5bkDADkWpIzJ2pZZeEI1qqZxFA/ty04B/ookWRJDLG12aVZkzOpER6QnEmROrd4fXJG2w0AyIq+eEuziWh2kvS9PWJphTWcXp0RJywJ87w0+5MzyeH+g5I8t81JtPuYE1XKecmZhWxpRjSIXcmZq666CkuWLEFgYCDKyspsn1+4cCEef/xxiKKItrY2fPjhh9i8eTN6eqRfuO69917cfvvt9kVORERERERENEr7y1phMIlIDPVDcvjYFpenxwcDgG0hkOxjbVvkrnkzVufmzjDpdimeVDljnU1SrO326oqn4kbpGsiIZHLGak6ylJwZaeXM0ap2GM0i4oJ9HTaL5/Z5UkImLcLf9lqj0Ts/OeOIxBnReGJXqYifnx927Nhx0cd+/etfY/Hixfj3v/+NM2fOwGg0IiMjA+vWrcONN95oz2mJiIiIiIiIxmSnHS3NrKZa+uVXt/WhrVePUP+xzVQlibVyJi3SvYv9k2ODsOlUIytnhlFpSc6kjDG56UhhAWpkRAagtKkHhyvbsHpy9PA7eaASW+WMexOUniQ3MRhymYDa9n40dPYjJsj3ktvbWpo5cPH/qmkxMJlFTI0PsmuGzUSXHaOBr1KO8EAVsqM17g6HyKM4tY/XihUrsGLFCmeegoiIiIiIiGjErMmZJXYkZ4J8lUiN8Ed5cy9O1HZgeVako8KbkMqapcV+d1fO5LByZlgGkxk17dLgek9IzgBSa7PSph4cqvD+5ExmFCtnrALUCuTEaHCqrhNHKttx9fRhkjNljps3YyUIAq6bEeew401UEYFqbHxkEfzVcshkTHIRnW9Mbc0+++wzPPLII7jmmmuwdu1aPPDAA/jvf/8Lg8Hg6PiIiIiIiIiIHKKypRfVbX1QygW7767OZWszhzlrqZxJj/SMtmblLb3o0xvdGounqmnrg8kswlcpR5RG7e5wAJw3d2YUg+M9SUefHk3dOgBABpMzg8y2tBI7Msz3tkdnxKk6Kak6n22zPFJ6ZMCw1U9EE9GoKme0Wi2uu+46HDp06ILHXnnlFTz++OP4+OOPMXXqVIcFSEREREREROQI1qqZWUkhCFDb10hiekIwPsyvY3LGTj06Ixq7BgAAaeHuTc5EBvogIlCN5m4dChu6MSuJMya+zjZvJtzfY9o8WZMzp+s60aMz2n1tu1qJVkpOxgX7el3szjYnORQb9lbicGX7Jbc7XNEGk1maJRYXzAQAEXmPEVfOmEwmXHPNNTh48CBEUbzoR0VFBS6//HK0tLQ4M2YiIiIiIiKiUdtlmzdjfxuy6QnBAIATtZ0QRdHu401U5c3SwnR4gBpBfko3R3OueqaArc0uypqcSfWQlmYAEBPki8RQP5hFaSi8tym2zZth1czXzbYkSAsbu9A1MHS3Htu8GQe2NCMicoURJ2feffddHD58GIIgID09HS+//DJOnTqFoqIivPfee5g/fz4AqbrmL3/5i9MCJiIiIiIiIhotndGEfZaZBEvtmDdjlR0TCKVcQFuvHrWWGRw0eudamnnGYv9k29yZLjdH4pnOVc74uTmSwWytzSpa3RzJ6JU0SsmZjCj3Vo55okiND5LC/CCKwLFLJN5s82bY0oyIvMyokjMAkJycjEOHDuHee+/F5MmTkZmZiRtvvBG7d+/G0qVLIYoi3nvvPacFTERERERERDRaRyrb0W8wISJQjewY++9QVyvkyImRFvKPs7XZmJVZKmfSIjxjYXpybBAAJmeGUtkqJWdS3NyC7uvOJWe8b+5MibVyhvNmLmp2kvS9PTJEa7POfgPOWCrdmJwhIm8z4uRMfn4+BEHAD37wAwQHB1/wuFwux29+8xsAQEVFBbq7ux0WJBEREREREZE9rC3NlmREOGxWhq21GZMzY1bWJC32e05yRkq4FTd2w2Ayuzkaz1PRbE3OeFblzDxLcuZETScGDCY3RzNyoijakjOZTM5c1JxkqbXZ4cqLJ94OVbTBLEqt9qI0Pq4MjYjIbiNOzjQ3S7/Izp49e8htzn+Mc2eIiIiIiIjIU+y0Jmcywx12zOnxwQCAE7UdDjvmRHO22drWzDOSMwkhfghUK6A3mW0t10gyYDChvnMAgOdVziSG+iFKo4beZPaqSraWHj3a+wwQBM+5BjzN7GQp8Xa8pgN644UJU2tLs/msmiEiLzTi5Ex/v9RDNyBg6B8Wfn7n7pwYGBiwIywiIiIiIiIix9B2DaCosRuCACzOsH/ejJW1cuZUXSeMrLIYNYPJjCpLm6w0D1mYlskEZHPuzEVZW5ppfBQI8VO6OZrBBEHA3BRpcd6bWptZq2aSw/zho5S7ORrPlBbhjxA/JXRGM05b2ped70C5Zd5MKpMzROR9RpycGS1RFJ11aCIiIiIiIqIRs1bNTIsPRqi/ymHHTQ33R6BagQGDGSVaVlmMVk1bHwwmEb5KOWI8qB3RZFty5sKF4ImsssXS0iwiwGGtAR3JG+fOFDdKyZkMD0lOeiJBEGzVM0e+1tqso0+PwkYpiTqfyRki8kJOS84QEREREREReQLrvJmlGY5raQZIVRbTEqQB8mxtNnrWtmFpkf6QyTxnsX9yrPQ9ZeXMYOXW5EyYZ82bsbLOnTla1e4184JKm6TkTFY0581cyrm5M+2DPn+gvA2iKCW3IgLV7giNiMguitHu8PzzzyMyMtIh2z3++OOjPT0RERERERHRiJnMInaXSjNRl2Y5rqWZ1fT4YOw924oTNR34xtxEhx9/PCuzDJdPi/CsqgFr5UxhfRfMZtGjEkfuZKuc8bB5M1bpEQEI8VOivc+A03WdmJEY4u6QhmWrnIlicuZSzq+cEUXRVrlla2nGeTNE5KVGnZx54YUXLvm49Q1yuO0AJmeIiIiIiIjIuU7VdaKz34BAHwWmxwc7/PjWuTPeNITcU5Q1WypnPCw5kx4ZAJVChm6dETXtfUgK83d3SB6hwpKcSQ73zMoZmUzAnORQbCnQ4lBFm8cnZ0RRRKmlHWIWkzOXNCU2CGqFDO19BpQ19yLd0gZufxnnzRCRdxtVWzNRFB32QURERERERORsJy3txuYkh0Ihd3xn71xLcqZE240+vdHhxx/PrG3N0j1s3oZSLrMtlrO12TkVLX0AgFQPrZwBvGvuTEPnALp1RihkAlLCmQC8FJVCZnuvtc6dae3RoVgrVR7NY3KGiLzUiCtntm/f7sw4iIiIiIiIiBzuTJ20uG5tVeVoURofRGt80Ng1gNN1XbbFYbo0URQ9tnIGkF4vp+o6caa+E2umxrg7HLfrHjCgpUcHwHMrZwBgXoq0SH+osg0mswi5B7eksyYWUsL9oVJwJPRw5iSH4mBFGw5XtuO2uYk4UC4laSZFByLUX+Xm6IiIxmbEyZmlS5c6Mw4iIiIiIiIihytokJIzOTHOSc4AwPSEIDSeGcCJmg4mZ0aouUeH7gEjZIJnLvZbk3msnJFUWqpmwgPUCPRRujmaoWXHBCJArUD3gBHFjd3IcVJS1hFKLcmZzGi2NBuJ2clSm7ojVVJSZn+5NEtsPqtmiMiLMTVPRERERERE45LBZLbdne7MRVrb3BlLCzUanrWlWWKoH9QKuZujuVBObBAAJmesyluk71eKBybSzqeQyzArSVrEP1TR6uZoLq24kfNmRmNmUggEAahq7UNT18C5eTNpTM4QkfdicoaIiIiIiIjGpfLmXuiNZgSoFUgIcd6icm58MADgRE2H084x3pQ1S8PlPbGlGSC1ShIEoLlbh6buAXeH43bWyhlvmI0yL9Uyd6bSs+fOlFgrZ6I88xrwNBofJSZFS0n2TacaUNbcC0EA5qcwOUNE3ovJGSIiIiIiIhqXCho6AUitjmROnD0xJT4IggDUtvfb5nLQpZVZKmfSIj1zYdpfrbAlIgpYPYMKS+VMsjckZyytBQ9VtEEURTdHc3Fms4jSJmtyhpUzIzXH0trsxV3lAKR2lUF+nttmj4hoOEzOEBERERER0bh0pk5aVJ9saVHlLBofpa0C5CRbm41IWbO02J/uoZUzwLnXDVubARWtUuVMqhckZ6bGBUOtkKGlR4/yll53h3NRNe19GDCYoVLIkBTm+c+pp5idLCXeGjqlarY8zpshIi/H5AwREREREZED9etNePKzAhytand3KBNeQYO0qJ4T4/yh4NMtrc2O13Q6/VzjwbnKGc9dmJ5smVM00StnRFFERbP3VM6oFDLMTLTOnfHM1mYl2nPJSbkTq/rGG2vljBXnzRCRt2NyhoiIiIiIyIE+zK/FS7sr8MBrR9DWq3d3OBOWKIrnkjOxzk/O5CZIVRacOzO8Xp0R9ZY731PDPblyRnrdnKmf2Am31l49ugaMAIBkL6nymGtpbXawvNXNkVycdd5MVjRbmo1GTJAv4oJ9AQAyAZhj+T4TEXkrJmeIiIiIiIgc6GilVDHT1qvHE58WuDmaiauhcwAdfQYoZAIyXDBwe3pCMADgRG2Hx8658BTlzVKrqTB/FUL8VW6OZmjWtmaVrX3oHjC4OZrRO9vUjaV/2o5/7y636zh//KIIAJARGQAfpdwRoTmdde7MQQ+dO1PcKCVnXPHeNN5Yq2emxgVB48N5M0Tk3ZicISIiIiIicqBj1efamX2UX4cdxU1ujGbisraiSo8MgFrh/AXlSdEaqOQydPQZUN3W5/TzeTPrvJm0SM9emA71VyEmyAcAUNjQ7eZoRu+9o7Woau3Dk5sKsaukeUzH+N+Jerx7pBaCADxx3RQHR+g8MxJDoJAJaOgcQG17v0vO2dqjg7ZrYETb2ipnolg5M1rXzYgDANw0K97NkRAR2Y/JGSIiIiIiIgdp7dGh0jI427pw9POPTqNXZ3RnWBOSdYi7K1qaAdKcC+u5jrO12SXZkjMRnp2cAby7tdnBcmneiigC33/n+IgTB1Y1bX34+YenAACPLE/HfC8avu6rkmNavFT55Iq5M706I9b+bQ9W/GUnatsvnZw1mMy26rFMJmdGbVlWJEp+dyXunJ/k7lCIiOzG5AwREREREZGD5Fd3AADSIvzx22snIz7EF3Ud/fjLlhL3BjYBFTRIi+k5Ma5JzgBArrW1WY33LeS70rnkjOfPL8mxtDazJvu8RY/OiFN10uswOcwPrb16PPJmPowm84j2N5jMePTtfHTrjJiVFIJHV2Q4M1ynmJsiJZMOVzo/OfPWoWo0dg2gR2fE08O831e19kJvMsNPJbfNT6HRUSlkEATB3WEQEdnNruTMkSNHHBUHERERERGR17O2NJuZGAI/lQJPXj8VALBhXwXyz2t3Rs5X0ODayhkAmJ4gLeSfqO1w2Tm90dkmKTmT7uFtzYDzK2e8KzlztKodJrOI+BBfbLh3LgLUChyqbMPTW0eWKP7rlyXIr+5AoI8Cz96WC4Xc++7tnZkYDMD5lWw6own/3l1h+/dHx+twum7oBG2JVnr9Z0QFQiZjgoGIaCKz66fr3LlzMX36dDz77LNobW11VExEREREREReyZacSZIGFi/NjMANM+IgisBPPzgFvXFkd62TfTr7Dahpk+ZMuLJyZnp8MADgdF0nDCOsUPAWZc09uPGFffj37nK7BqwbTWZUtkhtn7yprVmpths6o8nN0YzcgXJpjWZ+ahhSwv3x1I1Sovj5HWXYPswcrH1nW/D8jjIAwFM3TEN8iJ9zg3WSXEtypljbjR4ntpb8OL8OjV0DiNKoceWUaIgi8P++KBpy++JGad5MphckJ4mIyLnsvvXh9OnTeOyxxxAXF4ebb74ZmzZtsusXNSIiIiIiIm9kNJlt7axmJobYPv+Lq3IQ6q9CsbYbL+4sc1d4E0qhpWomLtgXwX4ql503OcwfGh8FdEazbQF2vPjoWB2OVrXjd58V4luvH0Vnn2HUxxBFEe8frYXeZIaPUuYVLZ3ign0R5KuE0Syi1FLx4A0OWpIz81JCAQBXTYvFXZYZHY+9cxwNnf0X3a+1R4fvvXMcogh8Y24C1k6LcU3AThAZ6IO4YF+IInDSSdVsJrOIf+4sBwA8sDgV/7cmG0q5gN2lLdhV0nzRfUqbpPeGrGjOmyEimujsSs48++yzyM3NhSiK0Ov1+PDDD3H11VcjISEBP//5z3H27FlHxUlEREREROTRihq70W8wIVCtQMZ5d0SH+qvwq6tzAAB//+qsraUTOU9BvetbmgGATCZgumXuTL6TWym52qnz2jRtLdBi7d93j2rBu7a9D/dsOIyfWgbMr86J9oqWToIgnNfazDtmCfXpjThZK8U6PzXM9vmfr83G5FgN2vsMeOTN/Auqu0RRxI/eP4mmbh3SIwPw+FWTXRq3M1jnQDmrtdnnpxtQ0dKLYD8lvjE3EQmhfliXlwwA+MPnRTCZL7x52VY5E8XkDBHRRGdXcuaRRx7B0aNHcfz4cTzyyCMIDQ2FKIqor6/HU089haysLCxZsgSvvvoq+vr6HBUzERERERGRx7HOlMlNDL5g0fma6bFYnhUBvcmMn314EuaLLNiR49jmzbiwpZnVDEvVVH7V+JkxJIqibYbGE9dNQWKoH2rb+3HTC/vx2v7KS3bPMJlFbNhbgdXP7MLOkmaoFDL86PIs/OWW6a4K327eNnfmaFU7jGYRccG+iA85V53ko5Tj+TtmIlCtwJGqdvx5S/Gg/f6zrxJfFTVBpZDhb7fNgK9K7urQHc6WnKnucPixRVHE89ulash7FiTDX60AADy8PB2BPgoUNnTh4/y6QfvojCZUtkrrY0zOEBGRQya6TZs2Dc8++yzq6+vx/vvvY+3atZDJZBBFEXv37sV9992HmJgYPPDAA9i3b58jTklERERERORRjlkW/2ac19LMShAE/O76qfBTyXG4sh3/PVTt4ugmFndVzgDnhpBb5w+NBw2dA2jt1UMuE3DzrHhsfGQRLp8cBb3JjMc/OYOH38pH98CFbc5KtN246Z/78JuNBejTmzA3ORSff3cx1i9Ph9KLBsxPjg0C4D3JmYPlbQCklmaCMDhRnBTmjz/eNA0A8OLOcmwr1AKQqoL+sEmak/LzNdluuXacwTp35nhNh8Nb8O8oaUZBQxf8VHLcsyDZ9vkQfxXWL08HAPxlSzEGDOdmFZU398JkFqHxUSBKo3ZoPERE5H0c+tuQUqnEDTfcgI0bN6KmpgZ/+MMfkJWVBVEU0d3djVdeeQWLFy9GdnY2/vSnP0Gr1Try9ERERERERG5jXYy3Ls5/XVywL358eRYA4P99XjTkzAeyj95ots10mOyGBeYZCVJyrrK1D609Opef3xmsVTMZkQHwUcoR5KvEP++chV9elQOFTMBnJxtwzT/22pJiOqMJT28twdq/7UZ+dQcC1Ar87ropePtb85EW4X1D0K2vo8KGrou2qfI0ByzzZs5vaXa+K6fG2JIJP3jvBM42deORt/KhN5mxMjsK6/KSXBWq002JDYJCJqCpW4eGzgGHHvsFS9XM7XMTL5htdc+CZMQG+aC+cwD/2Vdp+3yJ9lxLs68nzoiIaOJx2q0q0dHR+MlPfoKCggLs3bsX999/PwICAiCKIoqLi/HTn/4UCQkJuO666/DFF184KwwiIiIiIiKna+nRocrSqsa6OH8xd+UlY0ZiMHp0Rvzy49MOv5ObpGHbBpN0Z7o7Bs4H+SmRbpk5lO+EVkruYE3OTI0Lsn1OEAR8c1EK3n0wD7FBPqho6cX1z+/F37aVYu3f9uBv20phMIlYmR2FLx9bijvnJ3nFjJmLSY0IgI9Shj69CZWtve4O55L69SacsMwCmpcaOuR2P1szCdPjg9DRZ8Dav+1BeXMvojU++NNN08ZV0sBXJcekGKl9mCPnzhyubMOhyjao5DLcvzj1gsd9lHL8YLWUjH9u+1m09+oBnJeciWZLMyIicmJy5nx6vR46nQ4mk8n2Q14URRiNRmzcuBFr167FrFmzcOjQIVeEQ0RERERE5FDWRfj0yAAE+SmH3E4uE/D/bpwGpVzAl4VN+OxUg4sinDjOb2nmrkXm8dba7JQ1ORMfdMFjMxND8Nmji7E8KwI6oxlPby3B2aYehAeo8fwdM/HSulmIDvJxdcgOJZcJmBTtHXNnjlW3w2ASERPkg8RQvyG3Uyvk+MftM6HxUUBnNEMQgGduzUWIv2rIfbyVde5MvgOvx+e3nwUA3DgrbsjX93Uz4pAdo0H3gBH/sGxf3NgDAMjivBkiIoITkzPV1dV44oknkJ6ejssuuwxvvPEG+vr6IAgCrrzySrz55pv4v//7P8TFxUEUReTn52PJkiU4ePCgs0IiIiIiIiJyiuFamp0vMyoQ31kmzSP47cYCGE1mZ4Y24RQ0WJIzMRcmElxlpmXu0HhIzoiiiFN10nNqnb3ydSH+Krx89xz86PIsBPoocMvseHz52BKsmRozbqowrK3NzlgSVZ7qoKWl2cXmzXxdQqgfnr1tBmKCfPDzNdnIS7t4GzRvl2upZnRU5cyZ+k5sL26GTAC+vSRtyO3kMgE/u3ISAOC1/ZWoaeuzVc5kRHlfez8iInI8hSMPptPp8MEHH2DDhg3Yvn07RFG0leknJSXhvvvuw3333Ye4uDjbPr/97W/xxhtv4LHHHkNbWxsef/xxbN682ZFhEREREREROdWxKmtyZuiWZuf7zvI0vLq/Ek3dOhyr7sDclKHbD9HoWCtn3DFvxmpmkvQ6OFHTCaPJDIXcJU0rnKKpW4eWHh1kApATM/RzKpMJWL88Hd9ZljZuEjLnm5EYgv8erMahyjZ3h3JJByqk+IaaN/N1yydFYt9PLxuX3zMra+XMqbpOGExmKO28Hl/YIc2aWTstFsnh/pfcdklmBBZnhGN3aQt+s7EANe1S+0tWzhAREeCgypmDBw/iwQcfRHR0NO666y589dVXMJvNUCqVuPnmm7F582aUl5fjl7/85aDEDADIZDKsW7cOzzzzDADg6NGjjgiJiIiIiIjIJYwmM07WSnfTWxflh6NWyLEsMwIAsK1Q67TYJhpRFM9VzrgxOZMeEYBAHwX6DSYUNXa7LQ5HOGV5bWdEBsJXJR92+/G6yD/fMr/lZG0nenRGN0dzcQMGE45bWizOG2FyBhi/3zOr1HB/BPooMGAwo9jO67GypRebLO0oH1o6dNXM+X5yxSQIAvBloRaiCIQHqBAWoLYrDiIiGh/sSs788Y9/xOTJk7FgwQK89NJL6OzshCiKyM7Oxl/+8hfU1dXhnXfewapVq4b9YT9nzhwAQHu795d9ExERERHRxFHU2I1+gwmBPgqkR4y8Vc3KnCgAwFYmZxymtr0f3QNGqOQypI3ie+FoMpnglDkX7mCdNzMlzn1t4jxBfIgfEkJ9YTKLOOKh1TP51R3Qm8yIDFQjOWzoeTMTzfnXo72tzV7cVQazCCzPihhxAnhKXBCuzz13o3JGJKtmiIhIYldy5qc//SmKioogiiL8/Pxw7733Yu/evTh9+jS+//3vIyxs5HdqKJVDD80kIiIiIiLyVNbF99yEYMhkI78DfUlmBBQyAeXNvaho6XVWeBOKdVh7RlQAVAr3thI7N3emw61x2Ou0LTnjvkokTzE/RVrjOFDumcmZA5Z5M/NTw8Z9NcxoOSI509g5gPeP1gIA1i9PH9W+j63OtL0nZUUzOUNERBK7f1udPXs2XnzxRTQ0NODll19GXl7emI6TlpYGs9kMk8lkb0hEREREREQuY118H+m8GSuNjxLzLK2S2NrMMWwtzS4xG8VVrC3ujnl55czpeik5M3WCV84A5+a47LckQZyppq0P2q6BUe1zsEKKy/q+QufMSAwGYF8l2793l8NgEjE3ORSzk0f3HMeH+OG7KzIgCMCK7Mgxx0BEROOLwp6dT5w4galTpzoqFiIiIiIiIq9jXXwf6byZ862YFIW9Z1vxZaEW9y9OdXRoE06BpXJmshvnzVhZ79Svau1DS48O4V44Y6KpewDaLh1kgntn+HiK+WlScuZ0XSe6BwwI9HFsB5D2Xj02nqzHB8fqcKKmA0G+Smz/4TKE+quG3XfAYEK+JVE8fxTzZiaK6fHBAICy5l509hsQ5Du67117rx5vHqoGADy0fGSzZr5u/fJ03L84BWrF8LObiIhoYrCrcoaJGSIiIiIimshaenSoau0DcG4xfjRWZktzZw5XtqOzz+DI0CakAkuVR06s+6s8gnyVyIiU5t7ke2lrM2tLs7SIAPip7Lq3c1yIC/ZFYqifNHemyjEVUTqjCV+cbsS3XjuCub//Eo9/cgYnLK23OvsN+O+BqhEd50RNB3RGM8ID1EgN93dIbONJWIAaiaHSHJ6TtR2j3v8/+yrRpzchJ0aDZZkRY46DiRkiIjqfe5vwEhEREREReTHrontGZMCo78QGgMQwP2REBsBkFrGjpMnB0U0s7b161HdKbaAmxXjGTIdzc2e8s7XZqVqpEmkKW5rZzLe0DDtQNvbWZqIoorIb+PXGQsz7/TY8+MZRbCnQwmASMTlWg19elYNfXZ0DAHh1fxUGDMO3fz9Y0WaLj/NmLs42d2aUydJenRGv7q8EAHxneRqfXyIicpgR3fpSXV3tlJMnJiY65bhERERERESuYGtpNsp5M+dbmROF0qYebCtswrW5cY4KbcIptMybSQz1g8bB7abGamZSMN45UoNjDqqycDXrvBkmZ87JSwvDu0dqcWCMc2c6+vS46+WDOFWnAFADAIjSqHHdjDjcMCPeNizeYDLjX7vK0dA5gP+dqMctsxMueVxrPPPY0mxIuQnB+N+Jehy3VCaN1Ef5dejoMyA5zA9XTolxTnBERDQhjSg5k5KS4vATC4IAo9Ho8OMSERERERG5inXRfWZS8JiPsTI7Ei/sKMP24iYYTGYo5WxwMBYFDZ4zb8bKmrQ7WdsJo8kMhZd9b61tzaYyOWMzL0VKfpwa49yZtw/X4FRdF1QyEVdOjcVNsxOwIC0cctngagylXIZ7FiTjD58X4eXdFbh5VvyQFRs6o8mWKJ6fMrpB9RNJbmIwAOB4TQdEURxRBYwoinjzoHTD8p3zky74PhEREdljRL8ZiqLolA8iIiIiIiJvZTSZcbJWWry2p3ImNyEEof4qdA8YcbiyzVHhTTgF9VJyJifGc5IzaREBCPRRoN9gQlFjt7vDGZWWHh0aOgcgCECOByW83C022BdJYX4wi8CRytFXRH1yvB4AcEOyGX++aSoWZ0QMueB/29xE+KvkKNZ2Y1dpy5DHPFnbiQGDGWH+KqRb5hzRhXJiNFDKBbT26lHb3j+ifU7UdqKgoQsqhQw3zYp3coRERDTRjKhyZsOGDc6Og4iIiIiIyKsUNXaj32BCoI8CaRFjXxCVywQsz4rEB8dqsa2wCQvSwh0Y5cRxxpqc8aBEgkwmIDchGLtLW3Csut2r2oOdslTNpIT7I0A9oqWDCSMvNQxVrX3YX96K5ZMiR7xfibYbhQ1dUMoFTA8b/obVIF8lbpmTgA17K/Hv3eVYOsQg+oO2lmacN3MpPko5cmI0OFHbiWPV7UgI9Rt2n/8eqAIAXDU1BsF+KmeHSEREE8yIfsO6++67nR0HERERERGRV7G2EcpNCIbMzlY3K7OtyRktfrE2mwusozRgMOFscw8Az0rOAFJV1e7SFhyrase6vGR3hzNip2vZ0mwo81PD8PbhmlHPnfnkeB0AYGlGOPwUDSPa576FKXh1XyV2l7agqLELk6IvfH0frGizxUWXlpsQjBO1nThe0zHsjK/OfgM2npQqnW6fx5nJRETkeN7V8JaIiIiIiMhD2ObN2NHSzGpxZgRUchkqW/tQ1txr9/EmmlJtD0xmEaH+KkRrfNwdziAzk6TXx7HqDvcGMkqn65mcGYo1CXK6rhNdA4YR7SOKoq2l2dXTRj5UPiHUD1dMiQYA/Ht3xQWPG0xmW3s16zwcGtoMy/v18ZqOYbf9OL8OAwYzsqICMSvJ/vd5IiKir2NyhoiIiIiIaAysi+0zHbBoF6BWYH6atLC6rVBr9/EmmoIGKZGQE6PxuKqj3IRgAEB1Wx9aenTuDWYUTtdJbeK8qRWbq0QH+SAl3B9mEThcMbI5UceqO1Db3g9/lRzLsy7enmwo9y9OBSBV3jR1DQx67GRtJ/oNJoT6q5DBeTPDsl6PZ+q7oDeah9xOFEX896DU0uz2eYke975CRETjA5MzREREREREo9TSo0N1Wx+Ac4t99lqZLc2u2FbY5JDjTSSeOG/GKshXaVs0t1Zbebq2Xj3qOqSB6Z74nHqC+amhADDi1mb/s7Q0u3xyNHxV8lGda2ZiCGYlhcBgEvHa/qpBj1nPPzc51O72ihNBUpgfQvyU0BvNKGzoGnK7o1XtKNH2wEcpw3UzLt3+jIiIaKwcNtXvxIkT2L17N8rLy9Hd3Q2TyXTJ7QVBwMsvv+yo0xMREREREbmMdZE9IzIAQb5KhxzzskmRePyTMzhS1Yb2Xj1C/Dl8eqQKrMmZGM9MJMxMDEFpUw+OVXdg9eRod4czrFN1UiVSSrg/ND6OeX2PN/NTw/DWoRocKB++csZoMuPTk9KMmWtyY8d0vvsXpeBoVTveOFiF7yxPg59KWs45N28mdEzHnWgEQcD0hGDsKG7G8ZoOTB8iuf7mwWoAwDXTYx32Hk9ERPR1didniouLcd999+HAgQMj3kcURSZniIiIiIjIa9lamjlg3oxVfIgfJkUHoqixG9uLm3DDzHiHHXs8M5tF2x3wnlrlMTMpGO8cqcGxau+onDltSc6wpdnQrHNnztR3orPfcMkF/L1lrWjt1SPMX4WF6eGA+dI3s17M6snRSAz1Q3VbHz44Voe75ifBYDLjaKWUnJmXynkzI5V7XnLm7os83t6rx6enpGTa7fOSXBscERFNKHYlZ+rq6rBkyRK0tLRAFEUAQEBAAEJCQiCTsWMaERERERGNT9ZF9plJwQ497srsKBQ1dmNbIZMzI1Xd1odevQlqhQyp4f7uDueirEm8k7UdMJjMUMo9++9la3JmapxnJrs8QZTGB6nh/ihv6cXhijaszIkacttPLC3N1k6LgVIug2EMyRm5TMB9C5Px640FeGVPBe6Ym4jTdZ3o1ZsQ7KdEVlTgmL+WicbaijJ/iGTpB8dqoTeaMTlWg+nxTFASEZHz2PUb4ZNPPonm5mYAwP3334+ioiJ0dXWhqqoKFRUVw34QERERERF5G4PJjJO1HQAcWzkDwLbAu7Ok+ZLDqumcAkvVzKToQCg8NOmRFhEAjY8CAwYzihq63R3OsKxtzabEcmH6UqzVKpeaOzNgMGHz6UYAwLVjbGlmdfPsBGh8FKho6cW2oiZbSzPOmxkda3KmsrUP7b36QY+Joog3D0ktzW6flwhB4PNKRETOY9dvrl988QUEQcC6devwr3/9C5mZmY6Ki4iIiIiIyCMVNXRjwGCGxkeBtIgAhx57WlwQIgLV6NEZcahi+FkWJLWVAjy3pRkAyGQCci2JPE9vbdbeq0dtez8AYDLbml2Sdc7LgYqhkzPbCpvQqzchPsTX7mSuv1pha7P10u5yW1KILc1GJ9hPhRRLld1xS6Ld6kB5G8qbe+GvkuPa3Dg3REdERBOJXcmZ+vp6AMC6descEgwREREREZGnsy6u5yaGOPxudZlMwGVZkQCALwu1Dj32eFVQb5k3E+O5yRkAmJkYDMDzkzNnLM9nUpgfB6EPI882d6YLnX2Gi25jbWl2zfRYh1Rh3L0gCQqZgEMVbdh7tgXAuSQRjZy1eua4ZX6YlbVq5toZcQhQ2z2mmYiI6JLsSs6EhEh3fQQHBzsiFiIiIiIiIo9nmzdjWWx3tBXZUnJmW5HWNtuThmZta5bj4S24ZnpJ5YytpRmrZoYVqfFBaoQ/RBE4VHlhpVtnnwE7iqVW8I6qwogJ8sXV06X2aAaTCI2PApOiPTsx6YlmWN6/j9d02D7X0qPDF6cbAAC3z010Q1RERDTR2JWcmT17NgCgpKTEIcEQERERERF5unPJGcfOm7FalBEOlUKGmrZ+lDb1OOUc48XZph5ou3QQBGnmjCfLTQyGIAA1bf1o7ta5O5whnea8mVGZf4m5M1+caYDeZMak6EBkOfD1+c1FKbb/n5sSBjnnzYyatXLmRG2HLQn+/tFaGEwipscHMTlJREQuYVdy5tFHH4UoivjXv/7lqHiIiIiIiIg8VnO3DjVt/RAEabHdGfxUCixMkxZ8txaMz9Zm2q4BfO/tfPxzZxmaugZGvX9BfRe+93Y+Lv/rLgBAekQA/D28BZHGR4mMSGlGkSdXz1grZ6ZycXpErK3N9pddmJz55LjUCv6a3FiHnnNKXBAWWN4jFqVz3sxYTIrWQKWQoaPPgMrWPpjNIt6ytDS7wzLXh4iIyNnsSs6sWrUKP/nJT7B9+3Y89NBDMBgu3mOViIiIiIhoPMi3LKpnRAZA4+O8eRwrc6IAANvG6dyZF3eW4+Pj9Xjq8yLkPfUV7vvPYXx+qgF6o3nIfURRxJ7SFtz18kGs+dtufHy8HiaziLzUMPz55ukujH7s3NnabCQt8jr7DKhu6wMATIljq6yRmGeZ91LY2IWOPr3t89quAey3VNNcPc2xyRkAePa2Gfj99VNxx3wmEsZCpZBhSqz0Gs+vbsfeshZUtfYhUK3AVdNj3BwdERFNFCO6tei1114b8rHs7GwsWLAA//rXv7Bx40bcdNNNmDRpEvz8/IY97rp160YeKRERERERkZsdswyPdlZLM6sVk6Lwc5xGfk0HWnp0CA9QO/V8rra7VJrDkRjqh+q2PnxV1ISvipoQ4qfEtblxuHl2PCZb2moZTWZ8dqoB/9pVbhtWLxOANVNj8O0laZga7z0VHjMTQ/D24RrkV3W47JxFjV347lvH4auS47/3z7tkhdGZeqlqJiHUF8F+KleF6NUiA32QFuGPsuZeHKpow+rJ0QCAjSfqIYrA7KQQJIQOvz4yWhGBatw+j3NR7JGbEIJj1R04XtNhazV4w8w4+Kk8uwqPiIjGjxH9xLnnnnsgCMP3MG1oaMDf//73EZ1YEAQmZ4iIiIiIyKscrZKGfjs7ORMd5IMpcRqcruvC9qIm3Dw7wannc6WGTmmWjkwA/vfwQrT06PH+0Vp8eKwWTd06/GdfJf6zrxI5MRosyYzApyfrUdveDwDwUcpw6+wEfHNRKhLDHL/g7Wwzk4IBACfrOmAwmaGU29XMYlhbzjTi++8cR6/eBAB44tMCPHXjtCG3P8V5M2OSlxaGsuZe7C9vtSVn/ndCaml2rYNbmpHj5CYGA3uBHcXNqO+Q3mNuZ0szIiJyoRH/JiiKosM/iIiIiIiIvMWAwYQTNdLi9ZyUUKefb8Uka2uzJqefy5V2l7YAAKbFByPYT4X0yAD89MpJ2PfTy7DhnjlYMzUaSrmAgoYu/HNnGWrb+xHqr8L3V2Zi309X4DfXTvHKxAwApIYHQOOjwIDBjMKGLqedRxRFPLf9LL79xlH06k2YFh8EQQDePlyDzWcah9zPlpzhvJlRmW+ZO3OgXEreljf34GRtJ+QyAWumskWWp5qREAwAqG7rg9EsYlZSCLKiA90bFBERTSgjqpypqKhwdhxEREREREQe7XRdJ/QmM8IDVEh2QXJgZXYUnt1Wil2lzdAZTVAr5E4/pyvssSRnlmSED/q8Qi7D8kmRWD4pEu29enxyvA6HK9sxPy0MN82Mh6/K+79+mUzAjMQQ7CxpxrGqdkyLD3b4OQYMJvzkg5O2YfTr8pLwy6ty8OctxXhxZzl++sFJzEgIRqTG54J9rW3jpjI5MyrzUqTkTJFl7oz1uV+cEY6wcdaScDyJD/FFmL8Krb3SrKA72CaOiIhcbETJmaQklnUSEREREdHEdrhSGuI+Oyl0RG2f7TUlToOIQDWau3U4UtmOhenhw+/k4cxmEXvOSsmZRRkRQ24X4q/CPQtTcM/CFFeF5jIzrcmZ6g7cs9Cxx9Z2DeBbrx3BidpOKGQCfn3NZNxpGRj/2KpM7C5pQUFDF370/kn85945g17HXQMGVLT0AmDlzGhFBKqRHhmAs009OFDexpZmXkIQBOQmBGNbUROCfJWsciIiIpdzboNbIiIiIiKiceJIpdSyaHayc+fNWAmCgKWZUgJjR/H4aG1W0NCFtl49/FVyzEgMdnc4bmGdO3Osut2hxz1R04Fr/rEHJ2o7EeynxGvfnGtLzACAWiHHs7flQq2QYWdJM14/UDVo/zN1UtVMXLAvQv1VDo1tIsiztDb79+5yVLT0wkcpw6qcaDdHRcNZNikSAHDX/CT4KL2/Oo+IiLyLXcmZyy67DCtWrEBVVdXwG1vU19fb9iMiIiIiIvIGZrOII1XSYvqcZOfPm7FalmVNzjS77JzOtKtU+jry0sKhlE/MewWnJwRDEIDa9n40dQ845JifHK/DLS/uh7ZLh4zIAHyyfiEWpF1YaZURFYifXTkJAPDkZ4U429Rte+y0bd6MxiExTTTWuTPW94mV2VEIUI+oWQm50R1zE/HpI4vw2KpMd4dCREQTkF2/De/YsQM7duxAb2/viPfp7++37UdEREREROQNzjb3oLPfAF+lHDmxrlu8XpweAblMQGlTD2rb+1x2XmfZXWKZN5Pp/S3axkrjo0RGZAAAIL+6w65jiaKIP28uxnffPg6d0YwVkyLx4XcWICnMf8h91uUlY0lmBHRGM7779nHojWYAwClLcobzZsZmXurgpO21uXFuioRGQyYTMCUuCDKZ81tVEhERfd3EvFWJiIiIiIhoFA5bWprNSAx2acVHkJ8SMy3tv7y9eqZPb8RRS1XBonEwP8ces5Kk1niHK9rsOs62wib8Y/tZAMCDS9Pwr3WzEeijvOQ+MpmAP900DSF+Spyp78IzX5YAAE7XWytnmJwZi/AANTKjpKRbkK/S1pKQiIiIaCguT85Yq2x8fHxcfWoiIiIiIqIxOVIpJRVmu7ClmdWyLGkmgrcnZw5WtEFvMiMu2Bcp4UNXdkwECy3Jqa+K7JsltOlUAwBgXV4SfnrlJMhHePd/lMYHf7hhKgDgnzvLsK1Qi4oW6W91JmfGzvp9XTstBioF74UlIiKiS3P5bwuff/45ACA+Pn7Mx3jhhRcwbdo0aDQaaDQa5OXl2Y4LAAMDA1i/fj3CwsIQEBCAG2+8EVqtdtAxqqursXbtWvj5+SEyMhI/+tGPYDQaxxwTERERERGNX9bKmbluSM5Y78DfV9YCndHk8vM7yvktzQRhYrcQWpIZAYVMQHlLL8qbe8Z0DIPJjG2W5M5V02JHvf8VU2Jwy+x4iCKw/s1jEEUgJsgH4QHqMcVDwPdWZuIXa7PxU8tcHyIiIqJLGdV0uvvuu++in//FL36B4ODgS+6r0+lQVlaGw4cPQxAELF26dDSnHiQ+Ph5PPfUUMjIyIIoiXn31VVx77bXIz8/H5MmT8f3vfx+fffYZ3nvvPQQFBeHhhx/GDTfcgL179wIATCYT1q5di+joaOzbtw8NDQ1Yt24dlEolfv/73485LiIiIiIiRyuo78LdGw7hisnR+OVVObwb2w0aOvtR294PuUxArqXFmCtNjtUgIlCN5m4djlS22+7O9za7S6XKn8UZbPek8VFifmoY9pxtwbbCJqRGBIz6GIcr2tDZb0Cov8rWJm20Hr96Mg6Ut6G6TZpnxKoZ+wT5KnH/4lR3h0FEREReYlTJmf/85z8X3OEkiiI++eSTEe0viiIAIDQ0FD/72c9Gc+pBrr766kH/fvLJJ/HCCy/gwIEDiI+Px8svv4w333wTl112GQBgw4YNyM7OxoEDBzB//nxs2bIFBQUF+PLLLxEVFYXc3Fw88cQT+MlPfoJf//rXUKlUY46NiIiIiMiR3j1Sg+ZuHV4/UIXixm68cOdMhPHOdpeytjTLidEgQD2qP6EcQhAELMuMwHtHa7GjuMkrkzONnQMobeqBIAAL0sLcHY5HWJEdiT1nW/BloRYPLBn9gv6WAqk7xMrsyBG3M/u6ALUCz9yai5v/uQ9mEZjK5AwRERGRy4zqL4vExMRByZmqqioIgoCYmBgolUMPHRQEAT4+PoiJicGCBQvw0EMPITZ29GXXF2MymfDee++ht7cXeXl5OHr0KAwGA1auXGnbZtKkSUhMTMT+/fsxf/587N+/H1OnTkVUVJRtm8svvxwPPfQQzpw5gxkzZlz0XDqdDjqdzvbvrq4uAIDBYIDBYHDI10PkaNbXJl+jRM7D64zINSbqtbajWGpbJBOAQ5VtuOYfe/DPO2ZgUnSgmyObOA6VS+24ZiYGue31tzg9FO8drcVXRU348eoMp53HWdfZjqJGAMDUOA38lcKEu44vZmmG1CLvSFU7mjv7EOw39N/UXyeKIrackZ7Ty7LC7Xo+p8UG4JdrJ+GNgzW4cnIEvzcuMFF/nhG5Eq8zIufjdTa0kT4no0rOVFZWDvq3TCa1VNiyZQtycnJGcyi7nTp1Cnl5eRgYGEBAQAA++ugj5OTk4Pjx41CpVBe0WYuKikJjo/TLa2Nj46DEjPVx62ND+cMf/oDf/OY3F3x+y5Yt8PPzs/MrInKurVu3ujsEonGP1xmRa0yka625H6hsVUAmiPjeZBNeK5WjrmMAN76wD+syzJgaKro7xAnhq1NyAAJkrRXYtKncLTH0GQEZ5Chr7sUbH21CqJOLpxx9nb1bIgMgQ7TYgU2bNjn02N4s2leOxn7gb+99idkRI7+ea3uB+k4FVDIR3aVHYO/LMhTAo+lAwcGdKLDvUDQKE+nnGZG78Dojcj5eZxfq6+sb0XZ21eQvWbIEgiDA39/fnsOMSVZWFo4fP47Ozk68//77uPvuu7Fz506nnvNnP/sZHnvsMdu/u7q6kJCQgNWrV0Oj0Tj13ERjZTAYsHXrVqxateqSFW5ENHa8zohcYyJea68dqAaOF2FOcigeunUOvtFnwHffOYF95W34d7Ecj61Mx4NLUib8cHVn6h4w4PsHtgMA7r/uMkQGuq+l3AdNh3CkqgOyuKlYMzfBKedwxnVmNov49YkdAAy454p5mJM8tvko41GBohQv7q5Am08c1qyZNuL9nt12FkA5lmZF4bqrc50WHznHRPx5RuRqvM6InI/X2dCsHbeGY1dyZseOHfbsbheVSoX09HQAwKxZs3D48GE8++yzuPXWW6HX69HR0TGoekar1SI6OhoAEB0djUOHDg06nlartT02FLVaDbX6wj/GlEolX4Dk8fg6JXI+XmdErjGRrrVdpa0AgMsmRUGpVCIiSIlXvzkPT3xagNf2V+HpL8/ibHMf/njTNPgo5W6Odnw6VdEBswgkhfkhLnT0Q9sdafmkKByp6sDus224e6Fzh4478jo7XdeJ9j4D/FVyzEkNh1Iuc8hxx4PVU6Lx4u4K7DrbAsjkI35uthVLrfaumHLpFuPk2SbSzzMid+F1RuR8vM4uNNLnY9z8Vmw2m6HT6TBr1iwolUps27bN9lhxcTGqq6uRl5cHAMjLy8OpU6fQ1NRk22br1q3QaDQub89GRERERHQx/XoTDpRLyZllWZG2zyvlMvz22il48vopUMgE/O9EPW55cT8aOwfcFeq4driiDQAwOynUzZEAy7IiAAD7ylqgM5rcHM3I7S6VEgl5aWFMzHxNbkIIwvxV6B4w2l5rw6lp60NhQxfkMgGXTYocfgciIiIi8kh2Vc5cTFdXF7q7u2EyDf/HQmJi4pjO8bOf/QxXXnklEhMT0d3djTfffBM7duzA5s2bERQUhG9+85t47LHHEBoaCo1Gg0ceeQR5eXmYP38+AGD16tXIycnBXXfdhT/+8Y9obGzEL37xC6xfv/6ilTFERERERK52oLwVOqMZsUE+yIy6sGLjjnlJSA0PwEP/PYqTtZ245h978NK62ZieEOz6YMexw5XSgrkntOLKidEgMlCNpm4dDle0Y1FGuLtDGpHdpc0AgMUZEW6OxPPIZQKWT4rE+0dr8WVhExakD/893VIgdX2YkxyCEH+Vs0MkIiIiIidxyG1LW7duxfXXX4+IiAiEhIQgMTERKSkpl/xITR17GX5TUxPWrVuHrKwsrFixAocPH8bmzZuxatUqAMAzzzyDq666CjfeeCOWLFmC6OhofPjhh7b95XI5Pv30U8jlcuTl5eHOO+/EunXr8Nvf/tbu54KIiIiIyBF2FEtV3kuzIoecKZOXFob/rV+EzKgANHXrcP9rR2A0mV0Z5rimN5pxvKYDADA72f2VM4IgYGmmlOCwvj48XZ/eiCOV7QCAxV6STHK1ldlS9cu2Ii1EURx2+y1nGgEAq3OGbslNRERERJ7P7sqZRx99FM899xwAjOgXSUd4+eWXL/m4j48PnnvuOVtcF5OUlIRNmzY5OjQiIiIiIruJoojtxVK1wfKsS1cbJIb54YOHFmDJH7ejuVuHQ5VtWJDGRXBHOF3fCZ3RjBA/JdIi/N0dDgCpxd17R2uxo6QZv3B3MCNwsKINepMZccG+SAn3jOfQ0yzOiIBKLkNVax/ONvUgIypwyG3be/W2aq5VOVGuCpGIiIiInMCu5Mybb76Jf/zjHwCkhMh1112HWbNmITQ0FDIZewkTEREREY1FRUsvqtv6oJQLI2pzFOijxIrsKLx/tBZbC7RMzjjIEcsi+Ozk0CGrl1xtUUY45DIBZ5t6UNPWh4RQP3eHdEl7LPNmFmeEe8xz6Gn81QrMTwvDrpJmfFnYdMnkzLaiJphFqcWdp3/viYiIiOjS7ErOvPjiiwCAhIQEfPXVV0hLS3NIUEREREREE9kOS9XM3JRQBKhH9iv7qpxzyZnHr8rhQrgDHLa04/KEeTNWQb5KzEoMwaHKNuwoacZd85PcHdIlcd7MyKzKjsSukmZsK9TioWVD/11tbWnGqhkiIiIi72dXecvJkychCAJ+9atfMTFDREREROQg2y3zRJZlRo54nyUZEfBRylDb3o/Chm5nhTZhiKI4qHLGkyy1tLrb6eFzZxo7B1Ci7YEgAAvTw9wdjke7LFtKthyrbkdbr/6i2/TrTdhlSXatnszkDBEREZG3sys5YzAYAAAzZsxwSDBERERERBNdn96IgxVSUmD5pJFXG/iq5FiULm2/tUDrlNgmkrLmXrT3GaBWyDAlNsjd4QyyzJKc2Xu2FTqjyc3RDM1aNTMtPhjBfio3R+PZ4oJ9kR2jgVkEthddPOm252wLBgzS/J6cGI2LIyQiIiIiR7MrOZOcnAwA6OnpcUQsREREREQT3v6yVuiN0gJsWkTAqPa13k2/paDRGaFNKNaqmdyEYKgUnjVPMydGg8hANfoNJhyyJPI80Z6zlnkzI5ibRMDKbKlSblvRxZOr1pZmqydHsW0hERER0Thg118ZN9xwAwBg27ZtDgmGiIiIiGiis86bWT4pYtQLsCsmRUImAGfqu1DX0e+M8CaMc/NmPKulGQAIgmCrnrG+XlzlaFUbHnvnODaeqIcoikNuZzaL2FNqSc5kMDkzEissrc12FjdfUBFlNJnxZaGUtOG8GSIiIqLxwa7kzA9+8AMkJibir3/9K4qKihwVExERERHRhCSK4pjmzViFBagxO0lKJmw9w+oZexypss6bCXFzJBe3LEt6fexw0dyZipZePPj6Udz4wn58mF+HR97Kx8Nv5aN9iPkoBQ1daO3Vw18lx4xEz3wOPc20uCBEBKrRqzfhYPngiqijVe1o7zMgyFeJuR6YMCQiIiKi0bMrORMUFITNmzcjKioKCxYswPPPP4/29nZHxUZERERENKGUNfeitr0fKrkMC8Y4QN16V/3WQs6dGaumrgFUtfZBEICZSZ6ZWFiYHg65TEBZcy9q2vqcdp7WHh1+9clprHp6J7440wiZIM28kcsEfHayAav/ugtfXaQN125L1UxeWpjHtYXzVDKZgBWTLK3Nvnb9WudIrciOhELO55OIiIhoPFDYs3NqaioAoK+vDx0dHXjkkUfw6KOPIjw8HH5+fpfcVxAElJWV2XN6IiIiIqJxxVoFMS81FH6qsf2qvionCk9uKsTB8jZ09hkQ5Kd0ZIgTwpEq6YazSdEaaHw88/kL8lViVmIIDlW2YUdxE+7KS3bo8fv1JvxrTxVe2FGGHp0RALA8KwI/vTIbWdGBOFnbge+/cxxlzb247z9H8I25Cfj52hwEqKXX7e5Sqd3a4owIh8Y13q3IjsLbh2vwZWETfn2NCEEQIIoitliSM6tzot0cIRERERE5il3JmcrKykH/FkURoiiiqWn40noOMCQiIiIiGsw6P2Rp5tgXtJPD/ZEZFYASbQ+2FzfhuhlxjgpvwjhcKbWUmuOhLc2slk2KsCRnmh2WnDGZRRxsEvCHZ/egsUsHAJgSp8H/XZmNBennZsdMiw/GZ48uxp82F+OVvRV461AN9pxtwV9uzsXUuCAcsczsWcR5M6OyKD0caoUMdR39KNZ2Y1K0BsXablS39UGtkGFJJp9PIiIiovHCruTM3Xff7ag4iIiIiIgmtF6dEYcqpKTA8kmjnzdzvlU5USjR9mBrgZbJmTGwJhZme/hsj2WZkfjjF8XYV9aKAYMJPkq5Xccra+7B+v8eQ1GjHIAOccG++NHlWbhmeixksgtvrvNRyvHLq3KwMjsKP3zvBGra+nHrv/ZjWWYE9CYz4oJ9kRrub1dME42vSo6F6eH4qqgJ2wqbMClagy1npKqZxRnhY66oIyIiIiLPY9dvdhs2bHBUHEREREREE9q+slboTWYkhNq/oL06JxrPbS/DjuIm6IwmqBX2LdpPJD06I87UdwLw/MqZ7JhARGnU0HbpcLiyze4WYk9+Voiixm74ykU8sjIT9y1KG1HCJy8tDF98bzGe+LQA7x6pxfZia0uzcHZMGIMV2ZH4qqgJWwu0WL883TZvhi3NiIiIiMYXThIkIiIiIvIA1nkzy7Mi7V7QnhoXhCiNGr16E/aVtToivAnjeHUHzCIQF+yLmCBfd4dzSYIg2FrgWVvijZXeaMaBcum1sj7HhAcWpYyqEifQR4k/3jQd/143G+EBKgBSBReN3opJ0vN2orYDJ2s7cKquEzJBStoQERER0fjB5AwRERERkZuJomhbXF+WZf8AdZlMsC2MW1si0ch4y7wZq+VZ0oL99uLh535eSn51O/r0JoT5qxBnR+HWypwobHtsGT54KA+X2dmeb6KKDvLB1LggiCLwi49PAwBmJYUgLEDt5siIiIiIyJEc3rBWq9Xi9OnTaGuT/qgJDQ3FlClTEBXFu6aIiIiIiC7mbFMP6jr6oVLIkJfqmIHfq3Ki8caBanxZqMWT5ikXnRlCFzpSJf0d4+nzZqwWZoRDIRNQ3tyLmrY+JIT6jek4e8+2AADyUkMhE/rsiinIT4lZSd7x/HmqFdmROFXXiZO1Uos9tjQjIiIiGn8cUjkjiiJefPFFTJ06FbGxsVi9ejVuu+023HbbbVi9ejViY2MxdepU/Otf/4Ioio44JRERERE5icks4r0jNThiqSAg57NWzcxPDYOvyjHzYfJSwxCoVqC5W4cTtR0OOeZ4ZzCZkV/dAQCY4yXJGY2PEjOTpCqfHXZUz+yxJGcWpIU5JC6yz8rswTc3skUcERER0fhjd3Kmvb0dS5YswXe+8x0UFBRAFMWLfhQUFOChhx7CkiVL0NHR4YDQiYiIiMjRGjsHcPtLB/Cj90/im68egcFkdndIE8J227wZ+1uaWakUMiy1HG9LAVubjURhQxf69CYE+SqRERng7nBGzNoKb6xzZ7oGDDhhqdBYmOYdSanxbnKsBtEaHwBAVlQgksPt6DVHRERERB7JrrZmoiji2muvxd69ewEAYWFhuOWWWzBv3jxER0tl142NjTh06BDeffddtLS0YN++fbj22muxc+dO+6MnIiIiIof5qkiLH7x7Au19BgBAZ78BhyvasCDdMW226OJ6dEbbnJNlWY6d0bF6cjQ+PdmArQVa/OSKSQ49tjcymUW09urQ0q1HS48Ozd26Qf8tauwGAMxOCvGqNnDLMiPxxy+KsbesBQMGE3yUo6u+OljeBpNZREq4P2KDfXHcOWHSKAiCgCunRmPD3kqsnRbj7nCIiIiIyAnsSs68+eab2LNnDwRBwO23347nn38egYGBF2y3bt06PPXUU1i/fj1ef/117NmzB2+99Ra+8Y1v2HN6IiIiInIAndGEP35RjJf3VACQ7tgOC1BjV0kzvixsYnLGyfaebYHBJCI5zA8pDr47fllWBJRyAWebelDe3IPUCO+pBrFXU9cAzjR0oaDe8tHQharWXphH0GV5qQMrmFwhOyYQURo1tF06HKpow5LM0cVvnTezMJ0tzTzJjy+fhHkpoViRzZZmREREROOR3ckZAFi6dClef/31S24bEBCAV199FdXV1di5cyfeeOMNJmeIiIiI3KyypRePvJWPU3VSS6P7FqbgJ1dmYXtRkyU5o8Uvr8qGIHhPFYG3sbaicnTVDCDNI5mfGobdpS3YWqDFt5eOz+RM94ABO4qbUdDQhTOWZExLj+6i2woCEOavQniAGhGB6vP+K30uPsQPsy0zXLyFIAhYlhmJd47UYEdx86iTM9Z5M4uYiPUovio5rpjCqhkiIiKi8cqu5MyxY8cgCAIefvjhEe/zyCOPYOfOncjPz7fn1ERERERkp4/z6/Dzj06hV29CiJ8Sf7ppOlZahk4vzoiASi5DdVsfzjb1ICPqwuposp8oirYh7sucVK2xOicKu0tbsKVAi28vTXPKOdztoTeO2RIMVjIBSI0IQE6MBpNjNciJ1SAzKhBh/ioo5HaP3vQ4y7IipORMSRMeR86I92vsHMDZph4IApCXyuQMEREREZGr2JWcaWuTemOnpKSMeB/rttZ9iYiIiMi1enVG/Op/Z/D+0VoAwNyUUDx7Wy5ignxt2/irFchLC8NOS2szJmeco0Tbg4bOAagVMsxPdU5LqZU5UfjlJ2dwrLodzd06RASqnXIed2nqGsDeMikx8425CZgcG4ScWA0mRQfCT2XXnzteZWFGOBQyAeXNvahu7UNimN+I9rO2NJsWF4QgPyUMBoMzwyQiIiIiIgu7bhkLCgoCANTX1494n4aGBgCARqOx59RERERENAb1Hf24+h978P7RWsgE4HsrM/DWA/MHJWasVmZLbba2FWpdHeaEYa2ayUsLG/UQ95GKCfLFtPggiCLwVdH4+15uKdBCFIHchGD84YZpuHN+EmYmhkyoxAwgtbCbZWnHtqOkacT7nZs3w6oZIiIiIiJXsis5M2XKFADAhg0bRryPdVvrvkRERETkOn/4vAjlzb2I1vjgzQfm43srMyGXXXyezGWWIdTHqtvR1qt3ZZgTxhdnGgEAy50wb+Z8qyzfyy1nxl9yZrPlObxySrSbI3E/69wi6xyj4YiiyHkzRERERERuYldy5qabboIoivjoo4/w61//GqIoXnL7J554Ah988AEEQcDNN99sz6mJiIiIaJQKG7qw8YRU8fzyPbOHbaMVF+yL7BgNzCKwvWjkd+LTyFS39iG/ugMyAbhyqnMTC6snS8fffbYFvTqjU8/lSh19euwvawUAXD6ZyRnr3KJ9ZS0YMJiG3f5sUw+aunVQK2SYaam6ISIiIiIi17ArOfPAAw8gKysLoijiiSeewPTp0/H0009j7969KC0txdmzZ7F37148/fTTmD59On79618DACZNmoQHHnjAEfETERER0Qj9ZUsJAGDttBhMjg0a0T7W1mZfsrWZw/3vRB0AqZ1UZKCPU8+VGRWAxFA/6I1m7C4dWVWFN/iysAlGs4hJ0YFIDvd3dzhuNyk6ENEaHwwYzDhYMfyMT2vVzNyUUKe11SMiIiIioouzqxGzUqnE559/jhUrVqCiogJnzpzBj370oyG3F0URqamp+Pzzz6FQTKwe0ERERETulF/dji8LtZAJwPdXZo54vxXZUfj7V2exq6QZOqMJagUXcB1BFEV8fFyqYrpmeqzTzycIAlbnROHfeyqwpUCLK6bEOP2crvDFaaml2RVsaQZA+j4vzYzAO0dqsKO4CUszIy65/V62NCMiIiIichu7KmcAIDk5GSdPnsQPfvADBAUFQRTFi34EBQXhhz/8IY4fP47ExERHxE5EREREI2StmrlhZjzSIwNGvN+0uCBEBKrRqzfhYPnwd+LTyBQ2dONsUw9UChkud1FiYVWONHfmywItdMbhW155ul6dEbssVUBMzpyzfJKUkNk5zNwZg8mMA5ZreiGTM0RERERELueQ8hV/f3/86U9/wpNPPomjR4/i9OnTaGuTftEPDQ3FlClTMGvWLKhUKkecjoiIiIhGYX9ZK/acbYFSLuC7KzJGta9MJmDFpEi8fbgG2wq1WDLMnfg0Mp9YWpqtmBQJjY/SJeecnRyKaI0PGrsGsL2o2esTGjuKm6E3mpEc5oesqEB3h+MxFqaHQyETUN7Si6rWXiSFXbzd24maDvTojAjxUyInRuPiKImIiIiIyKG9xVQqFfLy8pCXl+fIwxIRERHRGImiiD9vKQYA3DonAQmhfqM+xorsKLx9uAZfFjbh19eIEATB0WFOKGaziI2WlmbX5jq/pZmVXCbg2hmxeHFnOT7Kr/X65MwXZ6SWZpdPieZr8jyBPkrMSgrBwYo27Chuxt0LLp6csc6bWZAeDpmMzx8RERERkavZ3daMiIiIiDzXjuJmHK1qh1ohwyOXja5qxmpRejjUChnqOvpRrO12cIQTz5GqdtR3DiBQrcCyrEiXnvuGGfEAgK+KmtDRp3fpuR1pwGDCV4VaAMAVk707yeQM1tfVjuKmIbfhvBkiIiIiIvdicoaIiIhonDKbz1XNrMtLQpTGZ0zH8VXJbTMpvizQOiy+ieqT41JLsyumRMNHKXfpubOiA5ETo4HBJGLjyQaXntuR9pW1oFdvQrTGB9Pjg90djsexzp3ZX96KAcOF84V6dEbkV3cAYHKGiIiIiMhdRtzWbNeuXQ4/+ZIlSxx+TCIiIiKSfHGmEWfqu+CvkuOhZel2HWtFdiS+KmrCl4VNeHiMFTgE6I1mfHZKSopcmxvnlhhumBmHgs+68NGxWtw1P8ktMdjri9OWlmaTo9iS6yKyogJt84UOVrRh6ddmRR2qaIXRLCIx1G9MrQ6JiIiIiMh+I07OLFu2zKG9nAVBgNFodNjxiIiIiOgck1nE01tLAADfXJSCUH+VXcdbMSkKP8dpnKjtQHO3DhGBakeEOeHsLm1GR58B4QFq5KWFuSWGa6bH4vebCnGsugOVLb1IDr/4TBJPZTSZsdVSwXW5l8/NcRZBELAsKwJvH67BjuKmC5Ize0pbAcBWEUdERERERK436rZmoig67IOIiIiInOPj/DqcbepBkK8S9y9Jtft40UE+mBoXBFEEthcNPceCLu2T4/UAgKunx0DupoqPSI0PFmVIi/Uf5de5JQZ7HKpsQ3ufASF+SsxNDnV3OB5rWZb0Pd5R3HzBY5w3Q0RERETkfiOunLHy9fXFtddei1WrVkEm48gaIiIiIk+jN5rx121S1cy3l6ZC46N0yHFXZEfiVF0nvizU4pY5CQ455kTSqzPaKj7c1dLMiKk98wAAavZJREFU6oYZcdhV0oyPj9fheyszHFoh72zWlmarc6KhkPPvkaEsTA+HQiagoqUXVa29SAqTKqSaugdQrO2GIMBt1VtERERERDSK5ExgYCC6u7vR39+Pd955Bzt37sTtt9+Ou+66C9OmTXNmjEREREQ0Cu8eqUFNWz/CA9S4Z0Gyw467MjsKf/2yFLtLWzBgMLl8mL23+7JQi36DCUlhfpgeH+TWWFZPjoKfSo6q1j4cq27HrCTvqEAxm0VsPiMlZ65gS7NLCvRRYnZyCA6Ut2FHcTPuXiAlZ/adlVqaTY7V2N3ukIiIiIiIxm7Et5pptVq89dZbWLNmDeRyORoaGvD0009jxowZyM3NxdNPP42GhgZnxkpEREREwxgwmPD3r0oBAOuXp8FPNepC6SFNjtUgWuODfoMJ+8taHXbcicLa0uza3Di3V6r4qRS25MaHx7yntdnx2g5ou3QIUCuwIJ1VH8NZlhUJANhRfK4V4R5LSzPOmyEiIiIicq8RJ2d8fHxw66234tNPP0VdXR2eeeYZzJgxA6Io4uTJk/jRj36ExMREXHHFFXjzzTfR39/vzLiJiIiI6CLeOFAFbZcOsUE+uH1eokOPLQgCLsuWFnu/LNQ69NjjXVuvHrtKpNkf10yPdXM0khtmxAMAPj3ZAJ3R5OZoRmazpaXZZZMioVawcms41rkz+8paMWAwQRRFzpshIiIiIvIQY2rSHBERge9+97s4cuQIzpw5g5/85CeIj4+HyWTCli1bcNdddyEqKgr33HMPtm3b5uiYiYiIiOgienRGPL+jDADw6IoMpyxer7QkZ74qaoIoig4//ni16VQDjGYRU+I0SI8McHc4AKR5I1EaNTr7DdhedOHQeE8jiiK+YEuzUcmKCkS0xgc6oxkHyltR3tKLhs4BqBQyzEn2jlZ2RERERETjld0TNLOzs/GHP/wBVVVV+Oqrr3DPPfcgICAAPT09eO2117B69WokJCTg5z//uSPiJSIiIi/ERXzXeGlXOdp69UgK88ONs+Kdco4FaeHwVcrR0DmAM/VdTjnHePQ/a0uz6XFujuQcuUzAdblSPB/l17otjpG+PxQ1dqOqtQ9qhQxLMyOcHNX4IAgClk+Snqsdxc22qpnZSSGcGUVERERE5GZ2J2fOt2zZMrzyyivQarV48803ceWVV0Iul9vaoBEREdHEU9TYhYVPfYXvv3Pc3aGMa0cq2/CP7WcBAD9YnQWl3KG/5tn4KOVYlCG1Q9pW2DTM1gQAdR39OFTZBkEArpoe4+5wBrl+ppSc+aqoCR19epef/4vTjZj1uy/x6/+dgcl86STNF5aWZksyI+CvdtwspfFuaaZU7bazpBl7Si0tzTLY0oyIiIiIyN2c8le7IAiQyWQQBMHtw06JiIjIfWrb+3D3K4dQ3zmAj/Lr0NQ14O6QxqW2Xj0efjMfJrOIa6bH4uppzk0AWFubbSvi3JmR2HhCqpqZlxKKmCBfN0cz2KRoDbJjNDCYRHx6ssGl5z5Z24HvvZOPtl49/rOvEg+/eeySs282W1uaTWZLs9FYmB4GhUxARUsvdljmHnHeDBERERGR+zk0ObNz507cf//9iI6Oxje+8Q18/vnnMBgMiImJwaOPPurIUxEREZGHa+vVY93Lh6Dt0tk+t7mAi/mOZjaL+P47x9HYNYDUcH/8/oapTr85ZvkkKTlzsrYTWibchvWJtaVZrue0NDvfDTOsrc3qXHbOxs4BPPDaEQwYzJgSp4FKLsPnpxtx74bD6B4wXLB9RUsvihq7oZAJWGFJDtLIBPooMTs5BACgN5oR5KvE5NggN0dFRERERER2J2cKCwvxf//3f0hOTsZll12GDRs2oLOzE76+vrj99tuxefNm1NTU4KmnnnJEvEREROQFenVG3LvhEMpbehEb5IN7FyYDALZY7nwnx3lhZxl2ljRDrZDhuTtmIsAF7Z4iA30wPSEYAFubDadE243Chi4o5QKu9NAh9tfmxkImAEer2lHV2uv08/XrTXjgtSPQdumQERmANx+Yjw33zoG/So59Za34xksH0NKjG7SPtaVZXloYgv1UTo9xvFmedS6htSAtDHIZuxsQEREREbnbmJIzTU1NePbZZzF79mxMmTIF/+///T9UV1dDEARcdtllePXVV6HVavH6669j1apVkMmc0/OciIiIPI/eaMaDbxzFidpOhPgp8do35+HuvGQAwP6yVrfMtRivDpa34i9bigEAv712MrJjNC4790pL9cy2QlZDXcr/LFUzSzMjPTapEKnxwUJLmytnV8+YzSIee/c4TtV1ItRfhVfumQONjxIL08Px9rfyEOavwum6Ltz0wj7UtPXZ9vvCkti9nC3NxmTZecmZhWxpRkRERETkEUZ8a+XAwAA+/vhjvP7669i6dStMJhNEURraOXnyZKxbtw533HEHYmNjnRYsEREReTazWcSP3j+B3aUt8FXK8co9c5AeGQAAmBQdiKLGbmwrbMKNs+LdHKnr/OHzQnx0rA6h/ipEBKoRGeiDiED1uY8ANSI1asQF+8JHKR/xcVt6dHj07XyYReD6GXG4ZXaCE7+KC62eHI2/bC3BrtJmNHUPIDLQx6XndyZRFGEwiVAp7LvBSBRFfHJCSnZcm+vZvyPfMDMOu0tb8FF+Hb67IsNprfGe+bIEn59uhFIu4MW7ZiEh1M/22NT4ILz/0ALc9fJBVLb24cYX9uG1b86FxkeJEzUdEARg9eQop8Q13mVGBSArKhBVbb1YlhXh7nCIiIiIiAijSM5ERkait1dqcyCKom2uzF133YXc3FxnxUdEREReQhRF/O6zQnxyvB4KmYAX7pyJGYkhtscvnxyNosZufHGmccIkZ3p1RryypwIGk4imbh2KGruH3DZArcC3l6Ti/sWp8FVdOkljnTOj7dIhLcIfv7tuitPnzHxdVnQgZiYG41h1B94+VINHV2S49PzO9Ni7J7DlTCN+fc1k3GxH0utYdQdq2vrhp5JjZbZnJxUunxwNP9VpVLX24Vh1B2YlhQy/0yh9nF+Hv391FgDwhxumYU5y6AXbpIT744OHFmDdy4dQrO3GLf/cj5U50nM3OylkXCUBXUkQBLz5wDz06kyID/EbfgciIiIiInK6ESdnenp6IAgCfHx8cM0112D16tWQy+U4efIkTp48OaaTr1u3bkz7ERERkef5585yvLK3AgDw55unD2qjAwBXTInGs9tKsaukGb06I/xdMBvF3Q5WtMJgEhEX7Ivf3zAVzd06NHUPoLlbN+ijqVuHHp0Rf9lagjcOVuEHq7Jw46z4IedCPLf9LHaXtsBHKcPzd8xy23N594JkHKs+jv8erMJDy9KglHt/K1ud0YTPTjVAbzTjR++fxOHKNvzmminDJsy+7nhNB376gfQ78uWTo0e9v6v5qRS4YnI0Psyvw0f5tQ5PzhytasePLc/Hg0vTcNMlErRRGh+8++08fPPVwzhS1Y4Pj0nVR2xpZp+wADXCAtwdBRERERERWY36L/mBgQG8++67ePfdd+06sSAITM4QERGNE+8eqcH/+6IIAPCLtdm4bkbcBdtMig5EUpgfqlr7sLOkGWumxrg6TJfbVdICAFiSGYGlmUO3EjKbRWw8WY8/bS5GbXs/fvzBSby8pwI/XTMJyzIjBlXF7CtrwTNflgAAnrh2CrKiA537RVzCFVOiER6ggrZLh60F2nHxPT1d1wm90QyVQgajyYx3j9TiZG0nnrtjJtIihl/Z7tMb8efNJdiwrwKiCIT6q/Dg0jQXRG6/62fG4cP8Onx6sgG/vCoHaoVjEkq17X349utHoDeasTonCj++PGvYfYL8lHj9m/Pw8JvHsK2oCQCTM0RERERENL6M6vZGURQd+kFERETe78sCLX724SkAwLeXSm25LkYQBFxhWVz94nSjy+Jzp92lzQCAJRmXHsAtkwm4NjcO236wFD9fkw2NjwLF2m7cu+Ew7nz5IE7XdQIAmrt1+O7bx2EWgZtmxdvVcssR1Ao5bpuTCAB4bX+lW2NxlCOV7QCApZkReOOb8xAeoEZRYzeu+fsebDxRf8l9d5Y0Y/Uzu/DKXikxc/2MOHz52FK3JtBGY0FaOKI0anT0GbC9qNkhx+zRGXH/q0fQ0qNHdowGz9yaC9kQFWFf56uS4593zcL3Vmbg8atyBs2nISIiIiIi8nYjrpzZvn27M+MgIiIiL3Sksg3r3zwGk1nEjTPj8dMrJl1y+8unROPFXeXYXtQEndHksDvzPVF9Rz/KmnshE6RF75FQK+R4YEkqbp4dj+e2n8Wr+6qw92wrrv7HHlyfG4f6zn40d+uQGRWAJ66d4uSvYGRun5eIF3aW4UB5G4obu70mETGUI1VScmZOcggWpIdj06OL8Mhb+ThY0YZH3srHoYo2/OKq7EGv3fZePZ74tAAf5kvtt+KCffHk9VMuaO3n6eSWJOG/dpXjo/xaXDHFvkoVk1nEd9/KR1FjNyIC1Xj57tmjbsGnlMvwvZWZdsVBRERERETkiUb819HSpUudGQcRERF5mRJtN+77z2HojGZcNikST904ddih9LnxwYjSqKHt0mFfWSuWe9ni9WjsKZVamk1PCEaQn3JU+wb7qfDztTlYl5eMP20uxv9O1NsW/n2Vcjx/x0yPmWESG+yLVdlR+OJMI14/UInfXTfV3SGNmSiKOGpJzsxKkobVR2p88N/75+GvX5biH9vP4vUDVThe04Hnbp+JhFBf/O9EPX67sQCtvXoIAnDvghT8YHWm185Uun6GlJz5qqgJ7b16hPirxnys57afxbaiJqgVMry0bjZig30dGCkREREREZF38/6prURERORydR39WPfyIXQNGDEzMRjP3T5zRMPgZTIBq3Oku/E3j/PWZv+/vfsOi+rK/zj+mRl6FwSkiFiwBXvvNWpisqbHxDUajWmanuyum8T0TX5JNnVTN0ZN0U01JkaNvUSxYQV7wUpRERCQOvf3BzIbVlFUpoDv1/PwPDD33HO+d5jDwP1yvmf5mZJmvZpUbdXMudQP9tF7d7TTrPE91KVhsNwtJr12cys1CXOt1Sl3dWsgSfpxwxHlFBQ7OZpLt+94njLziuThZlZ8VIDtcTeLWU8ObqYpd3dSHR93bT2SraHvr9CfJ6/RI//ZpBN5RWoW7q8fH+iuSde3rLGJGUlqERGglhEBKi41bAnBS3G6qFSTf98vSXr5hni1rR9UTRECAAAAQO1AcgYAAFyUzLwijZy8Rmk5BYoL89Pnoztd1CqO8lJJ87elq9RaO/egs1oNrdxTtnKmV9PQy+6vTf0gfXNfNyW/METD2kZddn/VrVvjEDUJ81N+Ual+TDzs7HAuWeKZ/WbaRgeds+Rev2Zh+vXhXmofE6RTBSVaueeEPCxmPX51U/3yUE+1i6nj6JDt4s4uZfsIfb3mwCXvE/nz5iPKPl2s+sHeuql9dHWGBwAAAAC1AskZAABQZflFJRozdZ32HctTZKCXvhjbWUE+F1f2qHPDYAX5uCszr0jrUjLtFKlzJR/N0cn8Yvl5ulXrigEPN9f81c1kMtlWz3yx+tJv6Dtb+euxQ2zlSZbIIG99c183Pdy/ia6Jr6c5j/TUwwPiXPZ7cyluaBclXw+L9h3L0+p9Fz9HDcPQFwkHJEl/7tJAFvP5yx0CAAAAwJWo9vwVCQAA7Kq41KoHvtqgTYeyFOTjri/GdlZE4MXvIeFuMWtgi3BJ0rxaWtqsvKRZt8YhVSr3Vhvc+Icb+iv3nHB2OJekfL+ZTudJzkhlr+HHBzXTR3/u4HIl5qqDn6ebhrUrW6H19ZoDF33+hoNZSj6aI083s27rWL+6wwMAAACAWuHKuFsAAAAui9Vq6C/fb9GyXcfk7W7R56M7XdZN6SFXnSltlpxWY1dZnM+KM8mZ3nGXvt9MTePv5a6bO5SVr/oiIcW5wVyC47mF2nc8T5LUvpaUJ7scd3YuK232W3Kajp0qvKhzy7//f2oTqTq+F7eyDgAAAACuFCRnAADAeRmGoX/M2a6ZG4/IYjbpwz+3v+yb1z3j6srHw6Kj2QXaeiS7miJ1DXmFJbYVGD3jLn+/mZpkZNey0mYLt6frSNZpJ0dzccq/Z3Fhfhddqq82io8KVNv6QSouNfRd4qEqn3fsVKHmbE2VJN3VLdZO0QEAAABAzUdyBgAAnNeny/fps9/3S5LeuKW1+jULu+w+vdwt6te8rJ/aVtpszf4TKi41FF3HW7EhPs4Ox6Hiwv3VrVGIrIb09eqLL4flTOXJmY6xwU6OxHXc2aVs9cyMtQdltVZthds36w6quNRQ2/pBahUdaM/wAAAAAKBGIzkDAAAq9X3iYb06d4ck6elrW+im9tHV1nd5abN5SbWrtNmK3cclSb3iQmUyXXkboY/qXrZ65pt1h1RYUurkaKpuXUrZxvcdG1DSrNz1rSPl7+WmQ5mntWLP8Qu2Lym16us1ByX993UAAAAAADg3kjMAAOCclu06pr/+sEWSdF/vRhrXu1G19t+3Wag8LGbtO56nPRm51dq3M5UnZ66k/Wb+aGCLcEUEeulEXpGtvJWrKyguVdKZ8nqdWDlj4+1h0c1nErJVWQm1cHu6UrMLFOLroWtbRdg7PAAAAACo0UjOAACAc3rjtx0qtRq6qV2U/jqkebX37+/lrp5nEhi1pbTZ0azT2pORK7NJ6t74ykzOuFnMts3kp62qGaXNNh/KUnGpoVB/T9UP9nZ2OC5lxJnSZot2ZCg1+/z7CJV/v2/vVF+ebha7xwYAAAAANRnJGQAAcJbU7NNKOpIjk0n6+9AWMpvtU57LVtosuXYkZ34/s2qmdXSQAn3cnRyN8wzvHCN3i0mbDmVp6+FsZ4dzQevL95tpUOeKLEV3PnHh/urcMFilVkPfrDtUabvd6aeUsO+EzCZpRFdKmgEAAADAhZCcAQAAZ1m0PUOS1K5+kOr6edptnIEtw2U2SclHc3QoM99u4zhK+b4cV2pJs3Kh/p62slZfJKQ4N5gqSCxPzlDS7JzKV8/8Z+0hlZRaz9nmyzNlzwa2CFdUEKuPAAAAAOBCSM4AAICzLNqeLkka0CLcruME+3qoS8MQSdJvNXz1jNVq6PfdxyRJvZqGOjka57urW9nqiZ83H9XJvCInR1M5q9XQ+pRMSWUrZ3C2IfH1FOzrobScAi3ekXHW8VMFxfoh8bAk6a5usQ6ODgAAAABqJpIzAACggvyiEq3ce0JS2X/B29uQ+LLSZjU9OZN8NEcn84vl5+mmtvWDnB2O07WPqaOrIgNUWGLVt+srL4flbHuO5SqnoETe7ha1jAxwdjguydPNols7RkuSpq89eNbxmRuPKK+oVI1CfdWjSYijwwMAAACAGonkDAAAqOD33cdVVGJVdB1vNQ33s/t4g64qSwCtP3BSGacK7D6evSw/s2qma6MQuVv4FctkMtlWz3y15oBKrYaTIzq39SllJc3a1g/i+3Yed3YuK222bNexCiUIDcPQFwllJc3u6tqAPXsAAAAAoIr4CxQAAFRQvt/MwBbhDrnRGhHorbb1g2QY0oJt6XYfz15+331mv5mmV/Z+M3/0pzZRCvBy06HM01qz/4SzwzknW0mzWEqanU+DEF/1iqsrw5Bm/GH1TMLeE9qTkStfD4tu7hDtxAgBAAAAoGYhOQMAAGysVkOLdvw3OeMog68qK232y+ajDhuzOuUXlWj9gbKb/L3i2G+mnLeHRdfER0iSZm9JdXI057b+QNnKmY6xwU6OxPWN6FK2eubb9YdUVGKVJNuqmRvbR8nfy91psQEAAABATUNyBgAA2Gw+nKXjuYXy93RT54aOu1l9XesIuZlNWr0vUwtr4OqZNfsyVVxqKLqOt2JDfJwdjku5rk1ZcmZeUpqKS61OjqaijJwCHczMl8kktYsJcnY4Lm9Ai3CF+XvqeG6R5m9L09Gs05q/rWyvqLu6xTo3OAAAAACoYUjOAAAAm/KSZr2bhsrDzXG/JtQP9tHYXg0lSc//kqzTRaUOG7s6lO830ysulD03/ke3RiEK8fVQZl6RVu11rdJm5atmmtcLUACrPi7I3WLW8E71JUlfrz6o6WsOympIXRsFq2m4v5OjAwAAAICaheQMAACwWbi9bNXKgBZhDh/74f5xigj00uGTp/Xh0j0OH/9yrDiz30yvOPab+V9uFrOGxJeVrZvtYmXr1qecKWnWgP1mqur2zjEym6SEfSc0LSFFEqtmAAAAAOBSkJwBAACSpMMn87Uj7ZTMJqlfM8cnZ3w93TTpupaSpE+W7dP+43kOj+FSpGaf1p6MXJlNUvfGIc4OxyVd1zpSkvRbcpptr5LqVFJqVeKBTL29YJfumbZOa/dnVum88n2COsaSnKmqqCBv9W9e9vPhVEGJwgM8dXVLx+1PBQAAAAC1RY1Mzrz66qvq1KmT/P39FRYWphtuuEE7d+6s0KagoEDjx49XSEiI/Pz8dPPNNys9vWIN+4MHD2ro0KHy8fFRWFiYnnrqKZWUlDjyUgAAcBnlJc06NghWHV8Pp8QwJL6eejcNVVGpVZNmJckwDKfEcTHKV820jg5SkI9znjdX17lhsEL9PZVTUKIVZ0rAXa5Dmfn6es0B3f9lotq9tEA3f5Sgdxft1sLtGXp4xkblFp7/d7r8ohIlH82RJHWMddz+SrXBiC4NKnzubqmRf1IAAAAAgFPVyL+kli1bpvHjx2v16tVasGCBiouLNWjQIOXl/fc/bB977DH98ssv+u6777Rs2TIdPXpUN910k+14aWmphg4dqqKiIq1atUrTpk3T1KlTNWnSJGdcEgAATufMkmblTCaTXvjTVfKwmLVi93HNTUpzWixVVZ6c6U1Js0pZzCYNbRUhSZq9JfWS+igptWrRjgx9v9+sq9/5Xb1eX6KnZyZpXnKaThWUKNDbXUNbRyi6jrfScgr0zoJd5+1v06EslVoNRQR6KSrI+5JiulL1bhqqlhEBCvb10PDO9Z0dDgAAAADUSG7ODuBSzJs3r8LXU6dOVVhYmBITE9W7d29lZ2dr8uTJmj59uvr37y9JmjJlilq0aKHVq1era9eumj9/vrZt26aFCxcqPDxcbdu21UsvvaS//vWvev755+XhwX++AgCuHLmFJVqzr6zE04AWzi1R1LCur+7v21jvLdqtF3/Zpj5NQ+Xr6Zq/slithlbuObPfTNNQJ0fj2q5vE6Gpq1K0YFu6CopL5eVuuajzn/p+i2ZuPKKy/y3Kl8VsUvuYIPWKC1XvpqFqFRUoi9mkpTszNHrKOk1ZlaKb2kerZWTAOfuz7TfDqpmLZjGb9OOD3VVcapW/l7uzwwEAAACAGsk173RcpOzsbElScHDZH9eJiYkqLi7WwIEDbW2aN2+umJgYJSQkqGvXrkpISFCrVq0UHv7fG1CDBw/WAw88oOTkZLVr1+6scQoLC1VYWGj7OienrBRGcXGxiouL7XJtwOUqf23yGkVNsCPtlOZvS5f1ApWsPCxm3d4xSiF+no4J7AJqwzxbsj1dRaVWNQj2UUyQh9OvZVyPGP244bAOnzyttxfs1F8HN3VqPJVJPpqjzLwi+XpadFU9X6c/b64svp6fIgK9lJpdoEXbUjXoIvYp2XI4WzM3HpHZJHUNs2p4n9bqGRdaITFgLS2RtVTq0aiOrrkqXHOT0/X3mVv0zT2dZTabzupz3f4TkqR20QF83y6BRZLFUrN/7uHcasN7GuDqmGeA/THPAPtjnlWuqs9JjU/OWK1WPfroo+rRo4fi4+MlSWlpafLw8FBQUFCFtuHh4UpLS7O1+WNipvx4+bFzefXVV/XCCy+c9fj8+fPl4+NzuZcC2NWCBQucHQJwXsVW6eWNFmUVnX0T9Vx+Wbdb41uW6hz3XJ2mJs+zr/aYJZnV0DNXc+fOdXY4kqRrw0369KRFn6/cr7qn9ijCBd9qFxwxSbKooU+xFvw274Ltr3TNfcxKzTbrs/kbVZJirfJ5H20re312qGvV7Y2sMg5t0opDlbfv6iktNlu06VC2Jk2bp+7hFTO+VkNau98iyaTTh5I0JzPp0i4IqMVq8nsaUFMwzwD7Y54B9sc8O1t+fn6V2tX45Mz48eOVlJSk33//3e5jTZw4UY8//rjt65ycHNWvX1+DBg1SQMC5S2YAzlZcXKwFCxbo6quvlrs7pUfguqYmHFBW0U6F+nloyFWV/0e9IenHjUe1J6dURwNa6N5eDR0XZCVq+jwrtRp6/v+WSirWPdd0VpeGrlHm6VpJ+77eqIU7jmlxdqi+urmjTCYXysZJmvH5OkkndXOPlrq2S4yzw3F50YezteSTNdqR46a+A/vKx+PCv4quTcnUjoT1cjOb9PLw7tqx/vcqzbWiegf0ypydmpfqqcdu7VFhpd321FMqXJ0gX0+Lxtw0UG5saA/Y1PT3NKAmYJ4B9sc8A+yPeVa58opbF1KjkzMTJkzQ7NmztXz5ckVHR9ser1evnoqKipSVlVVh9Ux6errq1atna7N27doK/aWnp9uOnYunp6c8Pc8uoePu7s4LEC6P1ylcWX5RiT5Zvl+S9NjVzXTnBW5yt4oO0l9/2Kp3Fu1Rn2bhio8KdESYF1RT59nmlEydzC9WgJebujQOlbsL3ah+fli8ft+7TGtTTmpO8jHd0C7KbmNlny7WjtQcbU/N0fbUU9qelqN9x/JUYq18hUdBcdmxvs3r1cjvvaO1jw1RTLCPDmbma/mek7q+TeR52xuGoXcW7ZUk3d6pvhqFBWiHqjbX7u7RSDM3pmpbao5eX7BHb93W1nZs85GyX5Tbx9SRt5drlEcEXE1NfU8DahLmGWB/zDPA/phnZ6vq8+E6d18ugmEYmjBhgmbOnKnFixerYcOK/zXdoUMHubu7a9GiRbbHdu7cqYMHD6pbt26SpG7dumnr1q3KyMiwtVmwYIECAgLUsmVLx1wIAECSNHVVio7nFqlBiI9u7Rh9wfa3dayvQS3DVVxq6NFvNqmguNQBUdZeC7eXvRf2bRbmUokZSYqu46OH+sdJkl7+dbtyCqqnlm1RiVXzklL11vydumfaevV4bbHavDBft3+6Ws//sk3frD+kLYezlVtYooJia6UfktS2fpBiQ1yw5poLMplMGto6QpI0e8vRC7ZftuuY1qWclKeb2fY6qCo3i1mv3Bgvk0n6ccMRJew9YTu2LuWkJKljA9dYJQYAAAAAuPLUyJUz48eP1/Tp0zVr1iz5+/vb9ogJDAyUt7e3AgMDNXbsWD3++OMKDg5WQECAHnroIXXr1k1du3aVJA0aNEgtW7bUyJEj9frrrystLU3PPPOMxo8ff87VMQAA+8g+XaxPlu2TJD06MK5KyQGTyaTXbm6tjYeWa09Grl6bu0PP/+kqe4fqEg6eyFdaToE6V2PpsUXby1aODmgRVm19Vqd7ejXUD4mHte94nt6av6tavtcPfJWoRTsyzno8MtBLLSICbB/N6vnJy91y3r7qBXi5XLk1V3Zd6wh9tHSvluw8plMFxfL3Ovd/FBmGoX/O3yVJGtm1geoFel30RpPtYurozs4x+nrNQT07K0lzHu4lDzezEg+cSc7E1rm8iwEAAAAA4BLVyOTMRx99JEnq27dvhcenTJmi0aNHS5Lefvttmc1m3XzzzSosLNTgwYP14Ycf2tpaLBbNnj1bDzzwgLp16yZfX1+NGjVKL774oqMuAwAgafKKfco+Xay4MD/9qU3VS1YF+3rojVtaa/SUdZq6KkV9m4WqbzPXTC5Ulx1pObr5w1XKKyrVSzfEa2TXBpfd54ETedqdkSuL2aS+TV3z+fN0s+jFYfH68+Q1+iIhRbd0iL6sUnZr92dq0Y4MuVtMuqFt1B+SMf4K8vGoxshxLi0jAtSorq/2Hc/Twu3purHduVfL/Zacrq1HsuXjYdEDfRtf8nh/GdxcvyWnaU9Grv69Yp9ubBelI1mnZTGb1LZ+0CX3CwAAAADA5XCt2iVVZBjGOT/KEzOS5OXlpQ8++ECZmZnKy8vTjz/+eNZeMg0aNNCcOXOUn5+vY8eO6c0335SbW43MVwFAjXQit1CTfy/ba+aJQU1lMV/c6oO+zcI0qltZguKp77coM6+o2mN0FcdzCzV26nrlFZWVcHtuVpIWbEu/7H7LS5p1jg1WoI/r1ojtGVdXQ1tHyGpIz85KktVqXHJf7y4qW41xS4f6euPWNhrTs6G6NQ4hMeMgJpNJ153Za2b25tRztim1GnprwU5J0pgeDRXid+mrmgN93PXM0LKSte8t2q2ZG49IKksS+Xryex8AAAAAwDlqZHIGAFA7fLxsr/KKStUqKlCDr6p34RPOYeK1LdQkzE/HThXqbz9skWFc+k17V1VQXKr7vkzUkazTig3x0U3tomQ1pIdmbNCmQ1mX1berlzT7o2eHtpSvh0UbD2bplyrsV3Iu61MytXLPCbmZTXrwMlZj4PJcf2bfmeW7jyk7/+xSZb9sPqpd6bkK8HLTuN6NLnu8YW0j1b1xiApLrPrn/LKkT4cGlDQDAAAAADgPyRkAgFOk5xToi4QDkspWzVzqnh1e7ha9c3tbuVtMmr8tXd+tP1ydYTqdYRia+ONWJR44KX8vN00e3Umv39JafZuFqqDYqrFT1+nAibxL6junoFhr92dKkga2CK/OsO2iXqCXHuzXRJL0+rydKiguveg+3l20W5J0S4do1Q/2qdb4UHVx4f5qFu6v4lJDvyWnVThWXGrV2wvLVjfd16exAr0vf0WXyWTSSzfEy8NiVvmiq06x1bdvEwAAAAAAF4vkDADAKd5fvFuFJVZ1iq2jPk1DL6uv+KhAPTGomSTp+V+SLzlZ4Yo+XLpXMzcekcVs0kcjOqhxqJ/cLGZ9cGd7xUcF6ERekUZPWXdJJd2W7TymEquhxqG+iq3ra4foq9+YHg0VEeilI1mnNXVVykWdm3jgpFbsPi43s0njzyR54DzXnVk987+roL5PPKwDJ/JV189Do7vHVtt4jUP9dF+f/67C6RjLyhkAAAAAgPOQnAEAONyhzHz9Z+0hSdITg5pd8qqZPxrXq5G6NAxWflGpHv1mk0pKrZfdp7PNS0rVG7+VlWB6/k9XqWdcXdsxX083fT66k6KCvLX/eJ7umbbuoleSLDxT0qwmrJop5+1h0ZNnEnEfLN5zUUmp986smrmpfRSrZlxA+b4zq/ae0IncQkllJfzKv08P9G1S7XvCjO/XRP2bh+mOzvUVHuBVrX0DAAAAAHAxSM4AABzunYW7VWI11Cuurro2CqmWPi1mk966va38vdy08WCW/rVkT7X06yxJR7L12DebJUmju8dqZNcGZ7UJ8/fStDGdFOjtrg0Hs/TIfzaq1Fq1PXdKSq1auvOYJGlgy5qTnJGkG9tFqWVEgE4Vlthu5F/IpkNZWrbrmCxmkyb0i7NzhKiKhnV9dVVkgEqthuadKW02fc1BpWYXKCLQSyO6xFT7mF7uFn0+upNeval1tfcNAAAAAMDFIDkDAHCoPRmnNHNj2b4w5aXIqktUkLdeviFekvT+4j3adCirWvt3lPScAt0zbb1OF5eqd9NQPTO0RaVtm4T56993dZSHxazfktP10uxtMowLJ2jWHzip7NPFquPjrvYxNau8k9lssj0nX60+oH3Hci94zrtn9jC5sV2UYkJYNeMqrmtdtnpm9uZU5ReV6MOlZUnVh/rHycvd4szQAAAAAACwK5IzAACHenvBblkN6eqW4WpbP6ja+x/WNkrXt4lUqdXQa3O3V3v/9na6qFTjvlivtJwCNQnz07/ubCc3y/nfrjs3DNY/b2sjSZq6KkWTf99/VptTBcVal5KpLxJSNPHHLfrbD1skSf2ahclivvyyco7WvUld9W8ephKrof+bt+O8bTcfytKSncdkNom9ZlxM+b4za/af0Bu/7dTx3CI1CPHRrR2jnRwZAAAAAAD2Vb2FvAEAOI+kI9n6dWuqTCbpiUFN7TbO365prnlJqVq9L1Nr9p1Ql2oqnWZvVquhJ7/brC2Hs1XHx12TR3VUgJd7lc69vk2kUrNP6x9zdujlX7ersMSq4lKrth3N0fa0HB3KPH3O84a1i6rOS3Coidc019KdGfotOV1r92eqc8Pgc7YrL312Q9soNazr68gQcQH1g33Utn6QNh3K0pSVKZKkRwfGyf0CCUkAAAAAAGo6kjMAAId5a0FZaanrW0eqeb0Au40TFeStWzvW1/Q1B/Xe4t36uoYkZ95ZtFu/bk2Vu8WkT0Z2VIOQi0skjOvVSEdOnta0hAN647edZx2vF+ClFhH+ahERoBYRAWoTHVSjS3zFhftreOcYTV9zUK/8uk0zH+wh8/+sAtp6OFuLdmTIbJIm9GfVjCu6rnWErQRhXJif/tSm5iYMAQAAAACoKpIzAACHSDxwUot3ZMhiNumxq+23aqbcg30b69t1h7RyzwmtT8lUx9hzr6pwBYZh6O0Fu/Te4rL9Nv5xY6tKV4Gcj8lk0qTrr1Kx1VDSkWw1DS9PxPirRb0A1fH1qO7Qne6xgU01a+MRbT6crV+2HNWwthVv7L+3uGzVzJ/aRKpRqJ8zQsQFDG0doZd/LStB+MSgpjWyzB4AAAAAABeL5AwAXKGKS616a8EutYkO0pD4enYdKzu/WK/OKbv5ekv7aIeUloqu46NbOkTrP+sO6d1Fu/Xl2C52H/NSFJda9bcftuqHDYclSY9f3VS3dqx/yf1ZzCb948ZW1RWeywv199QDfRvrzfm79Pq8nRp8VT3bRvLJR7O1YFu6TCZpQv84J0eKykQEeuulG+KVmVukwVfZ92cRAAAAAACugoLeAHCF+nnTUX20dK8emrFBSUey7TJGSalVXySkqO+bS7T+wEl5uJn18EDH3SQf36+J3Mwmrdh9XIkHTjps3Ko6VVCsMVPX6YcNh2Uxm/TqTa308ACSCBdrbM9GqhfgpSNZpzVtVYrt8fK9Zq5vHakmYayacWUjuzbQIwPjZDKxagYAAAAAcGUgOQMAV6hv1h2SJBWXGnr0m00qKC6t1v6X7szQkHdXaNKsZJ3ML1bTcD99MaazooK8q3Wc86kf7KOb2peVuXr3zI16V5GeU6DbP1mtFbuPy9vdos/u6qg7Osc4O6waydvDoicHN5Mk/WvJHmXmFWl7ao5+Sy5bNfPwAPaaAQAAAAAAroXkDABcgfYey9XalEyZTVJdPw/tycjVa3N3VEvfu9NPadTnazV6yjrtychVsK+HXr4hXnMe7qWujUKqZYyLMaFfnCxmk5bvOqaNB11j9czu9FO66cNV2paao7p+Hvrmvq7q1zzM2WHVaDe2i1LLiACdKijRe4t221bNDG0VoSZh/k6ODgAAAAAAoCKSMwBwBfp2fdmqmX7NwvTP29pKkqauStHSnRmX3GdmXpEmzUrSkHdXaNmuY3K3mDSuV0MtebKv/ty1gdwsznnLiQnx0Y3tylbPvOcCq2dW7zuhmz9apSNZp9Worq9+fKCHWkcHOTusGs9iNunpoS0kSV+tPqC5SWlnVs1QJg4AAAAAALgekjMAcIUpLrXqh8Syzedv71RffZqGanT3WEnSU99v0YncwovqzzAMfZmQor5vLNEXCQdUajU0qGW4FjzWR08PbalAb/fqvoSLNqFfE1nMJi3ZeUybD2U5LY5fNh/VXZPXKqegRB0a1NEPD3RXTIiP0+KpbXo0qat+zUJVYjUkSdfGR6hpOKtmAAAAAACA6yE5AwBXmEXbM3Q8t0ih/p62Ulp/u6a5moT56dipQk38casMw6hSXwXFpXri2816dlaycgpK1CIiQNPHddGnd3VUbF1fe17GRYmt66thbSMlOWf1zPHcQr06d7semrFRRaVWDbmqnr6+p4vq+Ho4PJbabuK1LWQ+s6f8Q+w1AwAAAAAAXJSbswMAAHv51+LdmrH20AXb+Xu56emhLdQrLtQBUTlfeUmzm9tHy/1MqTEvd4veub2tbvxwpeZvS9e36w/p9k7n35w+41SB7vsyURsPZsliNmniNc11d4+GspTfGXcxD/WP008bj2jRjgxtPZytVtGBdh8z5Xie/r1in75PPKzCEqskaXT3WD17XUuXfZ5quqbh/vpiTBeVWK1qXi/A2eEAAAAAAACcE8kZALXS3mO5emvBLlmrtgBE932ZqG/u7eaQG/bOlJp92ravzO2d6lc4Fh8VqCcGNdNrc3fohV+2qUvDkEpXvyQdyda4L9YrNbtAgd7u+nBEe/VoUtfu8V+OhnV9NaxtlGZuPKJ3F+3WZ6M62m2sjQdP6pNl+/TbtjSVL0JqEx2oB/o20eCrwmUykZixp55xrv1aBAAAAAAAIDkDoFZ6+0xipk/TUD1+ddPztn1z/k6t2H1cd09dp5kPdlf94Nq7B8j36w/LakhdGgar4TkSL+N6NdLSnRlavS9Tj36zSd/f301ulooVMH/dkqonvtukgmKrGof66rNRnc7Zlyua0L+Jftp0RAu3pyvpSLbio6ovGWc1pMU7j2ny7we0NiXT9nj/5mG6t3cjdWkYTFIGAAAAAAAAkkjOAKiFth3N0ewtqTKZyvZSaRFx/tJGH45or9s+Wa3tqTkaNWWtfri/e63cC8RqNfTNmZJm/7tqppzFbNI/b2urIe8s16ZDWfrXkj16dGBT2/nvLNpt27OlT9NQvX9nOwV4uTvmAqpB41A/Xd86Uj9vPqr3F+/WJyOrZ/XMb8npem2zRemrN0qS3C0mDWsbpXt7N2JDegAAAAAAAJzFfOEmAFCzvLVgpyTputaRF0zMSJK/l7umjO6kiEAv7TuWp3FfrFdBcam9w3S4hH0ndPjkafl7uema+IhK20UFeevlG+IlSe8v3qMNB08qv6hE46dvsCVmxvVqqM9Hd6pRiZlyDw9oIpOpLKGyPTXnsvvbfChLE/6zWemnTfLzdNN9fRppxV/6681b25CYAQAAAAAAwDmRnAFQq2w4eFILt2fIYjbpsYFxVT6vXqCXpt7dWf5eblp/4KSe+HazrFXdsKaG+M+6slUzN7SNkreH5bxth7WN0rC2kSq1Gnrsm026+aMEzU1Kk4fFrDduaa2nh9bcDe2bhPlraKuy5FR5sulSGYahf8zZLklqHWzV8id7a+I1LVQv0Ouy4wQAAAAAAEDtRXIGQK3yz/llq2Zubh+lRqF+F3Vus3r++mRkB7lbTPp1a6rtpnttcDKvSL8lpUmqvKTZ/3pxWLwiA7104ES+tqfmqK6fh2bc20W3dqza+a7s4QFxMpmkuUlp2pF26atnluzM0Jr9mfJwM+umWKv8vagWCgAAAAAAgAsjOQOg1li197hW7jkhd4tJDw+o+qqZP+reuK7evLWNJOmz3/drysr91Rmi0/y06YiKSq26KjJA8VGBVTon0Ntdb93eVt7uFsVHBWjWhJ7q0CDYzpE6RtNwf117prTbm7/tuqQ+Sq2GXpu7Q5I0qmuM6nhWW3gAAAAAAACo5UjOAKgVDMPQm7+VrZq5s3OMouv4XHJfw9pG6S9DmkmSXpy9TfOSUqslRmcxDEP/WVtW0mx4FVfNlOvaKETrnhmoXyb0VFSQtz3Cc5pHB8bJzWzSwu3p+nXLxX+Pf0g8rF3puQrycdf9vRvaIUIAAAAAAADUViRnANQKS3ZmaMPBLHm5mzW+X5PL7u+BPo31564xMgzpkf9sUuKBzGqI0jk2H87WzvRT8nQz609toy76fD9PN5lMNXN/mfOJC/fXg2deK5NmJelEbmGVzz1dVKp/LihLBk7o10QB3u52iREAAAAAAAC1E8kZADWe1WrYSlON6harsIDL34zdZDLp+euv0oDmYSosseqeaet18ET+ZffrDN+sK1s1c22rCAWSRKhgQr8mahburxN5RXr+l21VPu/zlfuVnlOo6DreGtmtgR0jBAAAAAAAQG1EcgZAjTc3KU3bUnPk5+mm+/s0rrZ+3SxmvX9nO7WJDtTJ/GK9s/DS9iZxprzCEv286Ygk6faLLGl2JfBwM+uNW1vLYjbpl81H9Vty2gXPOZFbqI+W7pUkPTW4mTzdLPYOEwAAAAAAALUMyRkANVqp1dBbZ8pLje3ZUHV8Paq1fx8PN70wLF6S9MuWo8rIKajW/u3t162pyisqVWyIj7o0DHZ2OC6pdXSQ7u3dSJL09MwkZeUXnbf9+4v3KLewRPFRAbq+daQjQgQAAAAAAEAtQ3IGQI02c+MR7T2WpyAfd93Tyz6bsretH6T2MUEqLjX01ZqDdhnDXspLmt3WqX6t3DemujwyIE5Nwvx0PLdQL86uvLzZgRN5+nrNAUnSxGtayGzmOQUAAAAAAMDFIzkDoMYqKrHaSo3d36ex/L3st5/KmJ5liZ+vVx9QQXGp3capTnsyTinxwElZzCbd0j7a2eG4NC93i16/pbVMJunHDUe0eEf6Odu98dtOFZca6t00VD2a1HVwlAAAAAAAAKgtSM4AqLG+XX9Ih0+eVqi/p0Z1i7XrWEOuqqfIQC+dyCvSz5uP2nWs6lK+aqZ/8zCFBXg5ORrX1z6mjsb2KEvC/f3HJOUUFFc4vvlQlmZvSZXJJP1tSHNnhAgAAAAAAIBaguQMgBqpoLhU7y/eLUma0K+JvD3suym7m8WskWcSQFNWpsgwDLuOd7mKSqz6YcMRSdLtHes7OZqa44lBzRQb4qO0nAK9Mnu77XHDMPSPOWVf39guSi0jA5wVIgAAAAAAAGoBkjMAaqSvVh9Qek6hooK8NbyzY5IPd3SuLy93s7an5mj1vkyHjHkpcgqK9X/zdigzr0hh/p7q2yzU2SHVGN4eFr1+SxuZTNI36w9p+a5jkqQlOzO0Zn+mPNzMemJQMydHCQAAAAAAgJrOzdkBADVFSalVO9NP6UILJgK93VU/2McxQV2h8otK9OHSvZLKNnL3dLPvqplyQT4eurl9tL5ec1BTVu5Xt8YhDhm3qnILSzRtVYo+Xb5P2afLSnLd3aOh3Czk4S9G54bBGtUtVlNXpWjij1s155Feem3uDknS3d1jFRXk7eQIAQAAAAAAUNORnAGqIKegWLd/slrbU3Oq1P7hAXF6/Oqmdo7qyvXDhiPKzCtSTLCPbmof5dCx7+4Rq6/XHNSC7ek6eCJfMSHOT8TlF5Xoi4QD+mTZXp3ML0vKNA711aMDm+q61hFOjq5m+suQZlq0I12HMk/r5o9WaU9GrgK93fVg3ybODg0AAAAAAAC1AMkZ4AJKSq2aMH2jtqfmyMvdrCBvj0rbGjKUnlOo9xbtVr0AL93ZJcaBkV4ZrFZDU1bul1SWKHH0qpAmYf7q3TRUy3cd09RVKZp0fUuHjv9Hp4tK9fWaA/p42V4dzy2SJDWs66tHB8bputaRsphNToutpvPxcNP/3dRad362RnsyciWV7W0U6OPu5MgAAAAAAABQG5CcAS7g5V+3a/muY/J2t+i7+7spPirwvO3fWrBL7y3arWdnJSki0Ev9moc5KNIrw7Jdx7TvWJ78Pd10q5M2uh/TI1bLdx3Tt+sP6bGr4+Tv5dgb9rmFJfrP2oP6ZPk+HTtVKEmKCfbRIwPiNKxtJGXMqkn3JnV1Z5cYTV9zUFFB3hrZrYGzQwIAAAAAAEAtQXIGOI8vVx/Q1FUpkqS3b29zwcSMJD02ME5Hs07r+8TDGj99g765t5taRV/4PFTN52dWzQzvXF9+ns75EdY7LlSNQn2171ievk88rLt7NHTIuBmnCjR1ZYq+Wn1AOQUlkqToOt56uH+cbmwfJXeSMtXu2aEtFRnopb7NwuTl7pi9jQAAAAAAAFD7kZwBKvH77uN6/udkSdJTg5tpSHzV9u4wmUx69aZWSs8p0Irdx3X31HWa+WB31Q92/t4kNd3OtFNasfu4zCbprm6xTovDbDbp7h4N9exPSZq6KkV3dYu1awmxvcdy9e/l+/TjhiMqKrVKkhrV9dW9vRvppvbR8nAjKWMv3h4WTegf5+wwAAAAAAAAUMtwRw84h73HcvXg14kqtRq6qV2UHuzb+KLOd7eY9eGI9moREaDjuYUaNWWtsvKL7BSt6ziUma/cwhK79V++18yQ+HpOT3bd3D5KAV5uOnAiX0t2ZNhljPUpmRr3xXoNfGuZ/rPukIpKrerQoI4+GdlBCx/vo+GdY0jMAAAAAAAAADUQd/WA/3Eyr0hjp65TTkGJOjSoo1dvbiWT6eJXRfh7uWvq3Z0UGeilfcfyNO6L9SooLrVDxK5hfnKa+ryxRL3+b7G+SEhRyZkVHtXlRG6hftx4RJI0xkFlxM7Hx8NNd3SOkfTfUmvVZeWe47r5o1W65eMELdiWLkm6umW4vr+/m354oLsGX1VPZjuu1AEAAAAAAABgXyRngD8oKrHqga8TlXIiX9F1vPXJyA7ydLv0fSbCA7w0dUxn+Xu5aV3KST3x3WZZrUY1RuwaUrNP6y8/bJHVkE7mF2vSrGRd8+4KLd1ZfStKvl5zUEUlVrWJDlSHBnWqrd/LcVf3snJmq/ae0I60nGrpc09Gru76fK0SD5yUh8WsOzrX18LH++jfd3VUx9jgahkDAAAAAAAAgHORnAHOMAxDz/2cpNX7MuXrYdHkUZ1U18/zsvttGu6vT0Z2kLvFpF+3pOrVudurIVrXUWo19Mh/Nikrv1itowP10rCrFOzrod0ZuRo9ZZ1GT1mrPRmnLmuMwpJSfbn6gCRpTM+Gl7SSyR6igrw1+KpwSdKU31Oqpc8vE1JUajXUpWGwfv9bP716U2s1DvWrlr4BAAAAAAAAuAaSM8AZk3/frxlrD8lskt6/s52a1fOvtr67N66rN29tI0n694r9mlrNZbCc6YMle7R2f1lC673h7TSyW6yWPNlX43o1lLvFpKU7j2nwOyv03Kwkncy7tH13Zm9O1bFThQoP8NS1rSKq+QouT3mJtZmbjuhEbuFl9ZVbWKIfNpSVbnuof5zC/L0uOz4AAAAAAAAArofkDCBp8Y50vTKnbEXL369tof7Nw6t9jGFto/SXIc0kSS/M3qZlu45V+xiOtj4lU+8s3CVJevnGeMXW9ZUkBXq76+mhLbXgsT4a1DJcpVZD0xIOqM8bS/TZin0qKqn6fjSGYdj2dLmrW6zcLa71Y6tDgzpqHR2oohKrZqw9eFl9zdxwWLmFJWoU6qseTUKqKUIAAAAAAAAArsa17nICTrDvWK4enrFJhiHd0bm+xva032bzD/RprDs6x8gwpIk/bFFuYYndxrK37PxiPfKfTbIa0k3tonRju+iz2sTW9dWnd3XU9HFd1CIiQDkFJXr51+0a/mmCsvKrtopmzf5MJR/NkZe7WSO6xFT3ZVw2k8mku3vESpK+SDhwUYmnPzIMQ18klJVuu6trA5cp3QYAAAAAAACg+pGcwRWtoLhUD369QbmFJercMFgvDou3601xk8mkZ69rofrB3jqaXaA3f9tpt7HsyTAM/e3HLTqSdVqxIT568Yb487bv3riuZj/UU6/d1EqB3u7acDBLt32SoLTsgguO9fnvZatmbm4frSAfj2qJv7oNbRWpUH9PZZwq1Nyk1EvqY/W+TO3OyJWPh0U3dTg70QUAAAAAAACg9iA5A5d0uqhU7yzcpSkr92v/8Ty7jfPCL8nakXZKdf089K872jmkZJaPh5tevbG1JGlaQooSD5y0+5jV7T/rDmluUprczCa9d0c7+Xm6XfAci9mk4Z1j9N393VQvwEu70nN180ertO9YbqXnHDiRpwXb0yVJd/ew34qmy+XhZtZdXRtIkj5cslelVuOi+/giIUWSdGO7KAV4uVdneAAAAAAAAABcDMkZuBzDMPT3mVv1zsLdeuGXber35lL1eWOJnpuVpCU7MnS6qLRaxvlp4xHNWHtIJpP07vB2Cgtw3ObrPePq6pYO0TIM6W8/bLnkUljOsDv9lF74JVmS9JchzdQ6Ouiizm8a7q/vH+imRnV9dSTrtG75OEFbD2efs+2UlSkyDKlvs1A1CfO73NDt6q5usQr0dtfO9FP6bv2hizo3Nfu05m9Lt/UDAAAAAAAAoHYjOQOX8+XqA5q58YgsZpM6NwyWu8WkAyfyNS3hgO6euk5tXpyvkZPXaPLv+7UnI1eGcfGrFPZk5OrvM7dKkh7uH6ceTepW92Vc0NPXtlBdPw/tzsjVR0v3Onz8S1FQXKqHZmxUQbFVveLq6p6ejS6pn+g6Pvru/m5qFRWozLwiDf80Qav2HK/QJqeg2JbkGOPCq2bKBfq46+EBcZKkfy7YpbyL2E9oxpqDKrUa6tIwWM3q+dsrRAAAAAAAAAAuguQMXErigZN6afY2SdLEa5rr2/u6aeOkQfp0ZAfd2SVGUUHeKiqxasXu43pp9jYNfGuZxk5brxO5hVUe43RRqcZ/vUH5RaXq0STEdkPd0er4eui566+SJP1ryW7tTj/llDguxj/mbLeVgfvnbW1kNl/6/jwhfp6acW9XdW8coryiUo2esk5zt/53v5Zv1x1SXlGp4sL81CvO8cmzSzGyawM1CPHRsVOF+nT5viqdU1Ri1fS1ZUkoVs0AAAAAAAAAVwaSM3AZx3MLNf7rDSouNXRtq3oa27NstYSfp5sGXVVP/7ixlX7/az8tfLy3nhnaQj2b1JW7xaTFOzJ0zbsrzlp5UZlJs5K0M/2UQv099c7t7WS5jATD5bqudYQGNA9Tcamhv/6wRdZL2KvEUeYnp+mLhAOSpH/e1lZh/pdfBs7P001T7u6ka+LrqajUqgenb9D0NQdVUmrVlJUpkqQxPRvKZHLe9+hieLiZ9dchzSVJny7fp/ScggueMzcpVcdzCxUe4KlBV4XbO0QAAAAAAAAALoDkDFxCSalVD03fqLScAjUO9dXrt7Q55w15k8mkJmH+uqdXI311Txf98lBPNQnzU8apQo2YvEb/nL9TJaWV79/yfeJhfZd4WGaT9N7wdgr197TnZV2QyWTSSzfEy9fDog0Hs/TVmgNOjacyqdmn9ZcftkiS7u3dSH2ahlZb355uFv3rzva6o3OMDEP6+8ytuu/LRB3JOq06Pu66sV1UtY3lCNfE11P7mCCdLi7VW/N3XbD9l2cSXnd2biB3Cz+SAQAAAAAAgCsBdwLhEt6cv0sJ+07I18OiT0Z2kJ+nW5XOa14vQL9M6Kk7OteXYUjvL96jO/69WkeyTp/Vdlf6KT3zU9k+M48NbKpujUOq9RouVWSQt/56Tdlqi/+bu0NHzxG7M50qKNaYqeuVlV+sVlGBenJQs2ofw2I26R83xmtCvyaSpEU7MiRJI7o0kJe7pdrHsyeTyaSnh7aUJH2beEjbU3MqbZt8NFvrD5yUm9mkOzrXd1SIAAAAAAAAAJyM5Aycbl5Smj5etleS9PotbdQk7OI2RPf2sOjVm1rr/Tvayd/TTetSTurad1fot+Q0W5u8whI9+PUG20b2488kAVzFn7s0UIcGdZRXVKpnf0qSYbhGebPCklLd/1WitqfmqK6fhz64s7083OzzY8NkMunJwc006bqyxIaHm1kjuzWwy1j21qFBHQ1tHSHDKNunpzLlq2aGxNdTWMDll4kDAAAAAAAAUDOQnIFT7TuWqye/2yxJGtuzoYa2jrjkvq5vE6lfH+6lNvWDlH26WPd9majnZiWpoLgs4bEnI1fhAZ565/a2l7WRvT2YzSa9dlMreVjMWrQjQ7O3pDo7JFmthp78botW7ilb0TT17s6KCfGx+7hjejbUd/d30zf3dlV4DU5Y/HVwc7lbTFqx+7iW7Tp21vHs/GL9tOmIJGlU91gHRwcAAAAAAADAmUjOwGnyi0p0/1eJyi0sUefYYP3tTGmvyxET4qPv7uum+3o3kiRNSzig/m8u1Y8bj8hskt6/o71C/Jy7z0xl4sL9bSt6nv85WSfzipwazz/mbNcvm4/KzWzSxyM7KD4q0GFjd4oNVruYOg4bzx5iQnw0qlusJOkfv25XqbXiaqjvEg+poNiq5vX81bFBzb5WAAAAAAAAABeH5AycwjAM/e2HrdqVnqtQf0/968521bYZuoebWROvbaFpYzorxNdDR7MLJElPDGqmzg2Dq2UMe3mgb2M1DffTibwivXKeclj29tmKffrs9/2SpDduba1ecaFOi6Umm9C/iQK93bUz/ZS+Tzxke9xqNfTl6rKSZnd1i5XJ5ForuQAAAAAAAADYF8kZOMXUVSn6efNRWcwmfXBne7vst9GnaajmPtJLN7WL0pgeDfVAn8bVPkZ183Az69WbWstkkr5PPKwVu88uh2VvszYd0cu/liWG/nZNc93YLtrhMdQWQT4eeqh/2WqoN+fvUl5hiSRp+e5jOnAiX/5ebrqhXaQzQwQAAAAAAADgBCRn4HDzklL1ypmb/3+/toVdV7OEBXjprdvbatL1LV1un5nKdGhQx1YO66/fb1H26eJL7quoxKpX5+7U9/vMWrQ9Q7lnkgOVWbnnuG0PoLt7xNrKw+HSjezWQDHBPjp2qlCfLt8nSfoioWzVzK0d6svHw82Z4QEAAAAAAABwAu4KwmEOZebrhV+2aeH2dEnS0NYRGtMj1rlBuainBjfT0p0ZSjmRr0mzkvTu8HaX1M8rv27TtIQDksxaMX2T3MwmtW9QR73j6qpXXKjiowJlOZO0Sj6arfu+TFRxqaGhrSP07NCWlNuqBp5uFv3tmuZ68OsN+nT5PvWKq6slOzMklSVuAAAAAAAAAFx5SM7A7opKrPr3in16f/FuFRRb5WY2aVzvRnpkQBw3/yvh6+mmt25vq1s/TtCsTUfVv3mYhrWNuqg+ftp45ExiRupQ16rjVj8dyMzX2v2ZWrs/U2/O36U6Pu7q0aSuujQK0XuLdiu3sERdGwXrrdva1JiVRjXBNfH11D4mSBsOZunuKetkGFLvpqFqWNfX2aEBAAAAAAAAcAKSM7CrVXuO69lZSdp7LE+S1LVRsF4aFq+4cH8nR+b62sfU0UP9m+idhbv1zE9J6tCgjqLr+FTp3B1pOfrbj1skSQ/2aaRmRbt07bU9lZpTrOW7j2nF7mNateeETuYXa/aWVM3ekipJal7PX5/e1VGebha7XdeVyGQy6emhLXXzR6t06kxpubu6smoGAAAAAAAAuFKRnIFdZOQU6JU52zVr01FJUl0/Tz0ztIWGtY1ktcxFmNCviZbtOqaNB7P0xLebNX1cV1sZssrkFBTr/i8TVVBsVa+4unq4f2P9Nm+XJCkmxEd/DmmgP3dtoOJSqzYfytLy3ce1fNcxmUzSRyM6KMDL3RGXdsXp0KCOhraK0K9bUxUV5K1+zcOcHRIAAAAAAAAAJyE5g2pVUmrVl6sP6K35u3SqsERmkzSyawM9PqiZAr256X+x3CxmvXN7W13z7gqt2Z+pf6/Yp/v7NK60vdVq6IlvNyvlRL6igrz17vB2lSZz3C1mdYwNVsfYYD1+dVN7XQL+YNL1LSWTdGuH6Asm2QAAAAAAAADUXmZnB4Da5VhuoV6ft1OnCkvUJjpQs8b31AvD4knMXIYGIb56/vqrJEn/nL9TSUeyK2378fK9WrAtXR4Wsz4c0V7Bvh6OChNVEB7gpQ/ubK++zVg1AwAAAAAAAFzJWDmDahUR6K2J1zaX2WTSHZ1jWB1QTW7tGK1FO9L1W3K6Hv1mk2Y/1FNe7hX3hVm557je/G2nJOn5P12lNvWDnBApAAAAAAAAAOBCWDmDandXt1j9uWsDEjPVyGQy6dWbWivU31N7MnL12twdFY4fzTqth2dslNUoK5l1R+f6TooUAAAAAAAAAHAhJGeAGiLY10Nv3tpGkjR1VYqW7syQJBWWlOrBrzfoRF6RrooM0Es3xMtkIjEGAAAAAAAAAK6K5AxQg/RpGqrR3WMlSU99v0WZeUV6efZ2bTqUpUBvd300osNZ5c4AAAAAAAAAAK6FPWeAGuZv1zTXyj3HtTsjV7d9kqA9GbkymaR3bm+rmBAfZ4cHAAAAAAAAALgAVs4ANYyXu0XvDG8rd4tJezJyJUkP9Y9Tv+ZhTo4MAAAAAAAAAFAVNTI5s3z5cl1//fWKjIyUyWTSTz/9VOG4YRiaNGmSIiIi5O3trYEDB2r37t0V2mRmZmrEiBEKCAhQUFCQxo4dq9zcXAdeBXDprooM1F+HNJck9W8epkcGxDk5IgAAAAAAAABAVdXI5ExeXp7atGmjDz744JzHX3/9db333nv6+OOPtWbNGvn6+mrw4MEqKCiwtRkxYoSSk5O1YMECzZ49W8uXL9e9997rqEsALts9vRpp+VP99NldHWUxm5wdDgAAAAAAAACgimrknjPXXHONrrnmmnMeMwxD77zzjp555hkNGzZMkvTFF18oPDxcP/30k4YPH67t27dr3rx5WrdunTp27ChJev/993XttdfqzTffVGRkpMOuBbgc7DEDAAAAAAAAADVPjUzOnM/+/fuVlpamgQMH2h4LDAxUly5dlJCQoOHDhyshIUFBQUG2xIwkDRw4UGazWWvWrNGNN954zr4LCwtVWFho+zonJ0eSVFxcrOLiYjtdEXB5yl+bvEYB+2GeAY7BXAPsj3kG2B/zDLA/5hlgf8yzylX1Oal1yZm0tDRJUnh4eIXHw8PDbcfS0tIUFlZx83Q3NzcFBwfb2pzLq6++qhdeeOGsx+fPny8fH1YwwLUtWLDA2SEAtR7zDHAM5hpgf8wzwP6YZ4D9Mc8A+2OenS0/P79K7WpdcsaeJk6cqMcff9z2dU5OjurXr69BgwYpICDAiZEBlSsuLtaCBQt09dVXy93d3dnhALUS8wxwDOYaYH/MM8D+mGeA/THPAPtjnlWuvOLWhdS65Ey9evUkSenp6YqIiLA9np6errZt29raZGRkVDivpKREmZmZtvPPxdPTU56enmc97u7uzgsQLo/XKWB/zDPAMZhrgP0xzwD7Y54B9sc8A+yPeXa2qj4fZjvH4XANGzZUvXr1tGjRIttjOTk5WrNmjbp16yZJ6tatm7KyspSYmGhrs3jxYlmtVnXp0sXhMQMAAAAAAAAAgCtHjVw5k5ubqz179ti+3r9/vzZt2qTg4GDFxMTo0Ucf1csvv6y4uDg1bNhQzz77rCIjI3XDDTdIklq0aKEhQ4Zo3Lhx+vjjj1VcXKwJEyZo+PDhioyMdNJVAQAAAAAAAACAK0GNTM6sX79e/fr1s31dvg/MqFGjNHXqVP3lL39RXl6e7r33XmVlZalnz56aN2+evLy8bOd8/fXXmjBhggYMGCCz2aybb75Z7733nsOvBQAAAAAAAAAAXFlqZHKmb9++Mgyj0uMmk0kvvviiXnzxxUrbBAcHa/r06fYIDwAAAAAAAAAAoFK1bs8ZAAAAAAAAAAAAV0ZyBgAAAAAAAAAAwIFIzgAAAAAAAAAAADgQyRkAAAAAAAAAAAAHIjkDAAAAAAAAAADgQCRnAAAAAAAAAAAAHIjkDAAAAAAAAAAAgAORnAEAAAAAAAAAAHAgkjMAAAAAAAAAAAAORHIGAAAAAAAAAADAgUjOAAAAAAAAAAAAOBDJGQAAAAAAAAAAAAciOQMAAAAAAAAAAOBAbs4OoCYzDEOSlJOT4+RIgMoVFxcrPz9fOTk5cnd3d3Y4QK3EPAMcg7kG2B/zDLA/5hlgf8wzwP6YZ5UrzxeU5w8qQ3LmMpw6dUqSVL9+fSdHAgAAAAAAAAAAXMWpU6cUGBhY6XGTcaH0DSpltVp19OhR+fv7y2QyOTsc4JxycnJUv359HTp0SAEBAc4OB6iVmGeAYzDXAPtjngH2xzwD7I95Btgf86xyhmHo1KlTioyMlNlc+c4yrJy5DGazWdHR0c4OA6iSgIAAflACdsY8AxyDuQbYH/MMsD/mGWB/zDPA/phn53a+FTPlKk/bAAAAAAAAAAAAoNqRnAEAAAAAAAAAAHAgkjNALefp6annnntOnp6ezg4FqLWYZ4BjMNcA+2OeAfbHPAPsj3kG2B/z7PKZDMMwnB0EAAAAAAAAAADAlYKVMwAAAAAAAAAAAA5EcgYAAAAAAAAAAMCBSM4AAAAAAAAAAAA4EMkZAAAAAAAAAAAAByI5A9QAy5cv1/XXX6/IyEiZTCb99NNPFY6np6dr9OjRioyMlI+Pj4YMGaLdu3dXaNO3b1+ZTKYKH/fff3+FNgcPHtTQoUPl4+OjsLAwPfXUUyopKbH35QEuwRHzbPPmzbrjjjtUv359eXt7q0WLFnr33XcdcXmAy3DUe1q5EydOKDo6WiaTSVlZWXa6KsC1OHKeTZ06Va1bt5aXl5fCwsI0fvx4e14a4DIcNc/WrVunAQMGKCgoSHXq1NHgwYO1efNme18e4BKqY55JUkJCgvr37y9fX18FBASod+/eOn36tO14ZmamRowYoYCAAAUFBWns2LHKzc219+UBLsER8ywlJUVjx45Vw4YN5e3trcaNG+u5555TUVGRIy7RpZGcAWqAvLw8tWnTRh988MFZxwzD0A033KB9+/Zp1qxZ2rhxoxo0aKCBAwcqLy+vQttx48YpNTXV9vH666/bjpWWlmro0KEqKirSqlWrNG3aNE2dOlWTJk2y+/UBrsAR8ywxMVFhYWH66quvlJycrKeffloTJ07Uv/71L7tfH+AqHDHX/mjs2LFq3bq1Xa4FcFWOmmdvvfWWnn76af3tb39TcnKyFi5cqMGDB9v12gBX4Yh5lpubqyFDhigmJkZr1qzR77//Ln9/fw0ePFjFxcV2v0bA2apjniUkJGjIkCEaNGiQ1q5dq3Xr1mnChAkym/97S3TEiBFKTk7WggULNHv2bC1fvlz33nuvQ64RcDZHzLMdO3bIarXqk08+UXJyst5++219/PHH+vvf/+6w63RZBoAaRZIxc+ZM29c7d+40JBlJSUm2x0pLS43Q0FDj3//+t+2xPn36GI888kil/c6ZM8cwm81GWlqa7bGPPvrICAgIMAoLC6v1GgBXZ695di4PPvig0a9fv8sNGaiR7D3XPvzwQ6NPnz7GokWLDEnGyZMnqzF6oGaw1zzLzMw0vL29jYULF9ojbKBGsdc8W7dunSHJOHjwoO2xLVu2GJKM3bt3V+s1AK7uUudZly5djGeeeabSfrdt22ZIMtatW2d7bO7cuYbJZDKOHDlSvRcBuDh7zbNzef31142GDRtedsw1HStngBqusLBQkuTl5WV7zGw2y9PTU7///nuFtl9//bXq1q2r+Ph4TZw4Ufn5+bZjCQkJatWqlcLDw22PDR48WDk5OUpOTrbzVQCurbrm2blkZ2crODi4+oMGaqDqnGvbtm3Tiy++qC+++KLCf0YCV7rqmmcLFiyQ1WrVkSNH1KJFC0VHR+u2227ToUOHHHMhgAurrnnWrFkzhYSEaPLkySoqKtLp06c1efJktWjRQrGxsQ65FsBVVWWeZWRkaM2aNQoLC1P37t0VHh6uPn36VJiHCQkJCgoKUseOHW2PDRw4UGazWWvWrHHQ1QCuqbrm2blwL6QMf6kCNVzz5s0VExOjiRMn6uTJkyoqKtL//d//6fDhw0pNTbW1u/POO/XVV19pyZIlmjhxor788kv9+c9/th1PS0urkJiRZPs6LS3NMRcDuKjqmmf/a9WqVfrmm29YMg+cUV1zrbCwUHfccYfeeOMNxcTEOONSAJdVXfNs3759slqt+sc//qF33nlH33//vTIzM3X11VdTPxxXvOqaZ/7+/lq6dKm++uoreXt7y8/PT/PmzdPcuXPl5ubmjEsDXEZV5tm+ffskSc8//7zGjRunefPmqX379howYIBtz4y0tDSFhYVV6NvNzU3BwcHcC8EVr7rm2f/as2eP3n//fd13330OuxZXxbs5UMO5u7vrxx9/1NixYxUcHCyLxaKBAwfqmmuukWEYtnZ/vPnbqlUrRUREaMCAAdq7d68aN27sjNCBGsMe8ywpKUnDhg3Tc889p0GDBjnsWgBXVl1zbeLEiWrRosV5k6PAlaq65pnValVxcbHee+892/vYjBkzVK9ePS1ZsoS9Z3BFq655dvr0aY0dO1Y9evTQjBkzVFpaqjfffFNDhw7VunXr5O3t7YzLA1xCVeaZ1WqVJN133326++67JUnt2rXTokWL9Pnnn+vVV191WvxATWCPeXbkyBENGTJEt956q8aNG+fYC3JBrJwBaoEOHTpo06ZNysrKUmpqqubNm6cTJ06oUaNGlZ7TpUsXSWXZakmqV6+e0tPTK7Qp/7pevXp2ihyoOapjnpXbtm2bBgwYoHvvvVfPPPOMXeMGaprqmGuLFy/Wd999Jzc3N7m5uWnAgAGSpLp16+q5556z/0UALq465llERIQkqWXLlrY2oaGhqlu3rg4ePGjH6IGaoTrm2fTp05WSkqIpU6aoU6dO6tq1q6ZPn679+/dr1qxZDrkOwJVdaJ6d671Kklq0aGF7r6pXr54yMjIqHC8pKVFmZib3QgBVzzwrd/ToUfXr10/du3fXp59+6pgLcHEkZ4BaJDAwUKGhodq9e7fWr1+vYcOGVdp206ZNkv77Q7Rbt27aunVrhV9KFixYoICAgLN+wAJXssuZZ5KUnJysfv36adSoUXrllVfsHS5QY13OXPvhhx+0efNmbdq0SZs2bdJnn30mSVqxYoXGjx9v99iBmuJy5lmPHj0kSTt37rS1yczM1PHjx9WgQQP7BQ3UMJczz/Lz82U2m2UymWxtyr8u/09lAJXPs9jYWEVGRlZ4r5KkXbt22d6runXrpqysLCUmJtqOL168WFar1ZYwBXB580wqWzHTt29fdejQQVOmTGFf0DMoawbUALm5uRX+837//v3atGmTgoODFRMTo++++06hoaGKiYnR1q1b9cgjj+iGG26wlZjYu3evpk+frmuvvVYhISHasmWLHnvsMfXu3VutW7eWJA0aNEgtW7bUyJEj9frrrystLU3PPPOMxo8fL09PT6dcN+BIjphnSUlJ6t+/vwYPHqzHH3/cVsPYYrEoNDTU8RcNOIEj5tr/lhE8fvy4pLL/3goKCnLMhQJO5Ih51rRpUw0bNkyPPPKIPv30UwUEBGjixIlq3ry5+vXr55TrBhzJEfPs6quv1lNPPaXx48froYcektVq1WuvvSY3NzfmGa4IlzvPTCaTnnrqKT333HNq06aN2rZtq2nTpmnHjh36/vvvJZX9fjhkyBCNGzdOH3/8sYqLizVhwgQNHz5ckZGRTrluwJEcMc/KEzMNGjTQm2++qWPHjtnGu+JXqBkAXN6SJUsMSWd9jBo1yjAMw3j33XeN6Ohow93d3YiJiTGeeeYZo7Cw0Hb+wYMHjd69exvBwcGGp6en0aRJE+Opp54ysrOzK4yTkpJiXHPNNYa3t7dRt25d44knnjCKi4sdeamA0zhinj333HPnHKNBgwYOvlrAeRz1nnauMU+ePGnnqwNcg6PmWXZ2tjFmzBgjKCjICA4ONm688Ubj4MGDjrxUwGkcNc/mz59v9OjRwwgMDDTq1Klj9O/f30hISHDkpQJOc7nzrNyrr75qREdHGz4+Pka3bt2MFStWVDh+4sQJ44477jD8/PyMgIAA4+677zZOnTrliEsEnM4R82zKlCnnHIPUhGGYDOMPu9EBAAAAAAAAAADArijuBgAAAAAAAAAA4EAkZwAAAAAAAAAAAByI5AwAAAAAAAAAAIADkZwBAAAAAAAAAABwIJIzAAAAAAAAAAAADkRyBgAAAAAAAAAAwIFIzgAAAAAAAAAAADgQyRkAAAAAAAAAAAAHIjkDAAAAQFOnTpXJZJLJZFJKSoqzw0EN17dvX9vr6Y8fl2v06NHn7JfXLAAAAGoakjMAAABADZaSknLOm9UX+wEAAAAAcBySMwAAAADwB+UJq+eff97ZodR4HTt21NatW20f51K+GiY2NvaC/b3yyiu2vl5++eVqjhYAAABwHDdnBwAAAADg0kVFRVV601uSWrVqJansJvmUKVMqbRcfH6/Ro0dXd3i4wvn6+io+Pr7a+ouKilJUVJQkaf369dXWLwAAAOBoJGcAAACAGszd3b1KN7+r+yY5AAAAAODSUdYMAAAAAAAAAADAgUjOAAAAANDUqVNte62kpKScdbxv374ymUzq27evJGnPnj26//771ahRI3l7eys2NlZjx47VgQMHKpyXlJSku+++W40aNZKXl5fq16+vBx54QBkZGVWK66efftKtt96qmJgYeXl5KSgoSB07dtQLL7ygkydPnvfcXbt26aGHHlJ8fLz8/f3l4eGhyMhItW3bVmPGjNE333yjwsJCW/vY2FiZTCbb1y+88ILtOSn/+N/Sb6mpqfrwww91yy23KC4uTr6+vvL09FRUVJSGDRumb775RlartdIYly5daut76dKlMgxDkydPVs+ePRUSEqKAgAB17txZX375ZYXzioqK9PHHH6tr164KDg6Wv7+/evTooW+//bbSsVJSUmxjTZ06VZL03XffaeDAgQoLC5O3t7eaN2+uiRMnKisr67zPbXV4/vnnZTKZNG3aNEnSgQMHznq+//j9AAAAAGoTypoBAAAAuCgLFy7UTTfdpFOnTtkeO3DggD7//HPNnj1by5YtU/PmzTVjxgyNHj1aRUVFtnaHDx/Wxx9/rLlz52rVqlWKjIw85xgnT57ULbfcosWLF1d4vLCwUImJiUpMTNSHH36oWbNmqWvXrmed/9133+nPf/5zhbGlsmRKamqqNm/erClTpmjr1q2XXO6ttLRU0dHR50y+HD16VD///LN+/vlnTZ48WT/++KP8/PzO219xcbGGDRumX375pcLj69at01133aX169fr3Xff1cmTJ3XDDTdo+fLlFdqtWrVKq1at0p49e/T3v//9gvGPHTtWn3/+eYXHdu7cqddee01ffPGFFi1apObNm1+wHwAAAAAXj5UzAAAAAKrs6NGjuu222xQUFKT3339fa9as0YoVK/Too4/KZDIpIyND99xzjy2h0LhxY3322Wdau3atlixZopEjR0oqS+Y8/vjj5xyjsLBQAwcO1OLFi2WxWDRy5EjNmDFDq1ev1ooVK/TKK68oJCREGRkZuvbaa89arZOenq67775bRUVFCgsL04svvqj58+drw4YNWrlypaZNm6YxY8YoODi4wnnz58/X1q1bbV8/8MAD2rp1a4WPV155xXbcMAxJUv/+/fXGG29o3rx5SkxM1NKlS/X555+rW7dukqQFCxZo/PjxF3xun332Wf3yyy8aMWKEfv31VyUmJmrGjBlq1qyZJOm9997TwoULNXr0aK1atUoPPPCA5s+fr8TERE2ePNmW6Jo0aZKSk5PPO9aHH36ozz//XJ07d9aMGTO0fv16zZkzR7fddpuksu/z4MGDKyTgqtuDDz6orVu3atiwYZKkyMjIs57vP34/AAAAgFrFAAAAAFBrSTIkGX369DlvuylTptja7t+//6zjffr0sR2Pi4szMjIyzmrz5JNP2tqEhoYa3bt3N/Ly8s5qd+uttxqSDDc3t3P28/e//92QZAQFBRnr168/Z7wpKSlGRESEIcm48847KxybPHmyLY6tW7dWes35+flGfn7+WY+Xn/vcc89Veq5hGIbVajV279593jaTJk0yJBkmk8nYtWvXWceXLFliG0+S8c4775zVJjU11fD397c9ryaTyZg5c+ZZ7TZv3myYzWZDkvHwww+fdXz//v0Vxrr22muN4uLis9q9+OKLtjZPPfXUea+vMuWvlwu97gzDMEaNGmVIMho0aHBRY1zoNQsAAAC4MlbOAAAAALgo7733nkJDQ896/MEHH7R9fvz4cX322Wfy8fE5q90DDzwgSSopKVFCQkKFY7m5ufrggw8kSS+99JI6dOhwzhgaNGigZ599VlJZCbO8vDzbsbS0NElSnTp1zluyzNvbW97e3pUevxCTyaQmTZqct82kSZNUt25dGYahn3/++bxtu3TpokceeeSsx+vVq6cbb7xRknTs2DHddtttuuGGG85q17p1a/Xs2VOStGLFivOO5enpqX//+99yczu70vXTTz9te94mT558Vmk4AAAAAJeP5AwAAACAKgsKCtLgwYPPeaxhw4by9/eXVJYoaNGixTnbtWnTxvb5vn37KhxbtmyZsrOzJUm33HLLeWPp3bu3pLK9WhITE22PR0RESCrbt2bWrFnn7aM6Wa1WHT16VDt37lRSUpKSkpK0fft2RUdHS5I2b9583vOHDx9e6bE/PmdVafe/z+v/GjRoUKX7/ZjNZo0aNUqSlJmZqQ0bNpy3LwAAAAAX7+x/kwIAAACASsTFxclkMlV6PCgoSKdOnVLTpk3P26bc/+5psn79etvn5UmWqihfLSNJf/rTnxQUFKSsrCzdeOON6tu3r66//nr17t1bbdu2lcViqXK/F2IYhr7++mtNnjxZa9as0enTpytte/z48fP2VdXnrCrtLrRXTKdOnc57vHPnzrbPt27dqq5du563PQAAAICLQ3IGAAAAQJWdq0zZH5nN5gu2K28jSaWlpRWOZWRkXFJc+fn5ts9DQkL0888/64477tCRI0e0ZMkSLVmyRJIUEBCgAQMGaMyYMbruuusuaaxyBQUFuummmzR37twqtT9f4kaq+nNWlXZWq/W8Y4WFhZ33eHh4uO3zzMzM87YFAAAAcPFIzgAAAABwGX9M1mzYsEHu7u5VOq+8dFi5Xr16ac+ePfrhhx80Z84cLV++XIcPH1ZOTo5mzpypmTNnavDgwfrxxx8vmHCqzCuvvGJLzPTp00fjx49X+/btVa9ePXl7e9sSJb1799aKFStkGMYljWMP51v9BAAAAMD+SM4AAAAAcBkhISG2z0NDQ89KulwMLy8vjRgxQiNGjJAk7d+/X7/++qvef/997dq1S7/99puefvppvf322xfdt2EY+uyzzySVJYIWL15cYXXLH7niypP09PQqHw8ODrZ3OAAAAMAV59x/PQAAAACAE7Rr1872+cqVK6u174YNG2rChAlat26dLenz7bffXlJfmZmZtn1ubr311koTM7m5udq5c+elBWxH69atq/Lx+Ph4u8bCKh4AAABciUjOAAAAAHAZAwcOtJUZe++99+xSCiwgIECdOnWSJB0/fvys415eXpKkwsLCSvsoKSmxfZ6Xl1dpu88++6xCW1cxf/58paamnvOY1WrVtGnTJEl16tRR+/bt7RpLVZ5vAAAAoLYhOQMAAADAZQQFBWnChAmSpFWrVumxxx477+b26enptvJi5X777bdKEw+SlJ2drbVr10oqW03zvyIiIiRJe/furbSP0NBQBQUFSZJmzJhxzsTCunXr9Oyzz1bahzMVFhbqvvvuq7DHT7nXXntNW7dulSSNGTNGnp6edo2l/PnOyMjQqVOn7DoWAAAA4CrYcwYAAACAS3nxxRe1bNkyrVmzRu+++66WLl2qcePGqW3btvL19dXJkyeVnJyshQsXau7cuWrVqpXuuece2/kzZszQ9ddfr6uvvlqDBg1SfHy8goODderUKSUlJelf//qXjhw5Ikm6//77zxq/e/fu2r9/v37++Wd98skn6tGjh211R0BAgMLCwmQ2mzVixAh98MEH2rJli3r27KnHH39ccXFxys7O1pw5c/Thhx/Kz89PkZGR2rVrl2OevCrq2LGjfvnlF/Xo0UOPPfaY4uLilJGRoWnTpuk///mPJCk6OtohyaXu3btLKluxc//99+uhhx5S3bp1bcebNGli9xgAAAAARyM5AwAAAMCleHp6asGCBRo9erR+/PFHbd682baa5lwCAgLOeqy4uFhz5szRnDlzKj3v/vvv18MPP3zW408++aS+//57FRYWnpW8GTVqlKZOnSpJeuWVV7Ry5Upt2rRJ69ev15133lmhbXBwsH744QdNmjTJ5ZIz48eP17JlyzR16lQNHz78rOMRERH67bffFBgYaPdY+vfvr65du2r16tWaPn26pk+fXuG4PUrbAQAAAM5GWTMAAAAALsff318//PCDVqxYoXvuuUfNmjWTv7+/3NzcFBwcrE6dOmn8+PGaM2eOFixYUOHct99+W1999ZXGjBmjjh07KioqSh4eHvL29lbTpk01atQorVixQh999JHM5rP/JGrbtq0SEhJ0xx13KCYmptKyXoGBgVq5cqVeeukltWrVSl5eXvLz81OLFi305JNPavPmzerdu7ddnp/qMGXKFE2fPl19+/ZVSEiIPD091bRpU/3lL39RcnKyWrZs6ZA4zGaz5s+fr2eeeUZt2rSRn5+fTCaTQ8YGAAAAnMVk8G9IAAAAAFDrpaSk2PbYmTJlikaPHm23sfr27atly5apT58+Wrp0qV3GmDp1qu6++25J0v79+xUbG2uXcQAAAAB7oKwZAAAAAMAu8vLylJSUZPs6Pj7+svo7cuSITp48afscAAAAqKlIzgAAAAAA7GL9+vVq1aqV7evLLdzw9NNPa9q0aZcbFgAAAOB07DkDAAAAAAAAAADgQCRnAAAAAADVaunSpTIM46yPyzV16tRz9st+MwAAAKhpSM4AAAAAAAAAAAA4kMmojn9fAgAAAAAAAAAAQJWwcgYAAAAAAAAAAMCBSM4AAAAAAAAAAAA4EMkZAAAAAAAAAAAAByI5AwAAAAAAAAAA4EAkZwAAAAAAAAAAAByI5AwAAAAAAAAAAIADkZwBAAAAAAAAAABwIJIzAAAAAAAAAAAADvT/rFp4ur8/pFYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 2000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = pd.concat([\n",
    "    Y_df,\n",
    "    Y_hat_df_ray,\n",
    "    Y_hat_df_optuna,\n",
    "]).reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (20, 7))\n",
    "plt.plot(plot_df['ds'], plot_df['y'], label='y')\n",
    "plt.plot(plot_df['ds'], plot_df['AutoNHITS'], label='Ray')\n",
    "plt.plot(Y_hat_df_optuna['ds'], Y_hat_df_optuna['AutoNHITS'], label='Optuna')\n",
    "ax.set_title('AirPassengers Forecast', fontsize=22)\n",
    "ax.set_ylabel('Monthly Passengers', fontsize=20)\n",
    "ax.set_xlabel('Timestamp [t]', fontsize=20)\n",
    "ax.legend(prop={'size': 15})\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc455db2-e5d8-4caa-8de6-4cb46492ca9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
